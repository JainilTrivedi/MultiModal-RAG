{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNQfyoPLnbYd",
        "outputId": "3375e664-acfd-41c8-c14d-c65526d62be9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bqsgkqqah7OU",
        "outputId": "dfcf2ec6-b7e7-41b3-9013-9ae2bcfe0e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "Successfully installed tokenizers-0.21.0 transformers-4.47.0\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting arxiv\n",
            "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.35.76-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.76 (from boto3)\n",
            "  Downloading botocore-1.35.76-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.76->boto3) (2.8.2)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.76->boto3) (1.16.0)\n",
            "Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\n",
            "Downloading boto3-1.35.76-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.76-py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=3bbbb70a297c9647cb3cd053dece6e3ae046759b5ca26311ac83d2ca787b7ac5\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, jmespath, feedparser, botocore, arxiv, s3transfer, boto3\n",
            "Successfully installed arxiv-2.1.3 boto3-1.35.76 botocore-1.35.76 feedparser-6.0.11 jmespath-1.0.1 s3transfer-0.10.4 sgmllib3k-1.0.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain_nvidia_ai_endpoints\n",
            "  Downloading langchain_nvidia_ai_endpoints-0.3.5-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain)\n",
            "  Downloading langchain_core-0.3.22-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.54.5)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pillow<11.0.0,>=10.0.0 (from langchain_nvidia_ai_endpoints)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.10-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.10-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.11-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_nvidia_ai_endpoints-0.3.5-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.22-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.7/409.7 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, pillow, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, langchain-core, langchain_openai, langchain_nvidia_ai_endpoints, langchain, langchain-community\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.21\n",
            "    Uninstalling langchain-core-0.3.21:\n",
            "      Successfully uninstalled langchain-core-0.3.21\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.9\n",
            "    Uninstalling langchain-0.3.9:\n",
            "      Successfully uninstalled langchain-0.3.9\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.10 langchain-community-0.3.10 langchain-core-0.3.22 langchain_nvidia_ai_endpoints-0.3.5 langchain_openai-0.2.11 marshmallow-3.23.1 mypy-extensions-1.0.0 pillow-10.4.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "c5b33a7a82a94c13b0a1fd68afa41b56"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install faiss-gpu\n",
        "!pip install --upgrade transformers\n",
        "!pip install pymupdf\n",
        "!pip install pypdf\n",
        "!pip install PyPDF2\n",
        "!pip install arxiv boto3 requests\n",
        "!pip install langchain beautifulsoup4 langchain-community langchain_openai langchain_nvidia_ai_endpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjvNzCEoh761",
        "outputId": "314dda67-d48d-43c7-d379-a63dd15baef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import torch\n",
        "from langchain.vectorstores import FAISS\n",
        "import faiss\n",
        "import arxiv\n",
        "import boto3\n",
        "import requests\n",
        "import os\n",
        "\n",
        "from botocore.exceptions import ClientError\n",
        "from google.colab import userdata\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(\"Device:\", device)\n",
        "if device == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up environment."
      ],
      "metadata": {
        "id": "13noZMTUgqUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AWS_ACCESS_KEY =  userdata.get('AWS_ACCESS_KEY')\n",
        "AWS_SECRET_KEY = userdata.get('AWS_SECRET_KEY')\n",
        "\n",
        "# print(AWS_ACCESS_KEY)"
      ],
      "metadata": {
        "id": "P_FM8Yxt-mSc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aws_region = 'us-west-2'\n",
        "\n",
        "s3 = boto3.client('s3',region_name='us-east-2', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY )\n",
        "dynamodb = boto3.resource('dynamodb',region_name='us-east-2', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n",
        "table = dynamodb.Table('paper_store')"
      ],
      "metadata": {
        "id": "IgJYkwX_-pup"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetching Required Paper from Dynamodb"
      ],
      "metadata": {
        "id": "gfAeyvxUgk4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input an index in fetch_and_download_pdfs to download a pdf of the research paper.\n",
        "download_directory = '/content/drive/MyDrive'\n",
        "os.makedirs(download_directory, exist_ok=True)\n",
        "\n",
        "\n",
        "def generate_presigned_url(bucket_name, key, expiration=3600):\n",
        "\n",
        "    try:\n",
        "        url = s3.generate_presigned_url(\n",
        "            'get_object',\n",
        "            Params={'Bucket': bucket_name, 'Key': key},\n",
        "            ExpiresIn=expiration\n",
        "        )\n",
        "        return url\n",
        "    except ClientError as e:\n",
        "        print(f\"Error generating presigned URL: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_and_download_pdfs(table_name,idx):\n",
        "\n",
        "   try:\n",
        "        response = table.scan()\n",
        "        items = response.get('Items', [])\n",
        "\n",
        "        print(f\"Fetched required documents from table '{table_name}'. Starting download...\\n\")\n",
        "\n",
        "        # for item in items:\n",
        "        item=items[idx]\n",
        "        document_id = item.get('DocumentID')\n",
        "        s3_url = item.get('S3URL')\n",
        "        metadata = item.get('Metadata', {})\n",
        "\n",
        "        # Parse bucket name and key from the S3 URL\n",
        "        if not s3_url:\n",
        "            print(f\"Skipping item {document_id}: No S3URL found.\")\n",
        "\n",
        "\n",
        "        try:\n",
        "\n",
        "            bucket_name, key = s3_url.split('.s3.')[0].split('//')[1], '/'.join(s3_url.split('/')[3:])\n",
        "\n",
        "\n",
        "            presigned_url = generate_presigned_url(bucket_name, key)\n",
        "            if not presigned_url:\n",
        "                print(f\"Failed to generate presigned URL for {document_id}. Skipping.\")\n",
        "\n",
        "\n",
        "            # print(f\"Downloading {presigned_url} for DocumentID: {document_id}...\")\n",
        "            response = requests.get(presigned_url)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            file_name = metadata.get('FileName', f\"{document_id}.pdf\")\n",
        "            local_path = os.path.join(download_directory, file_name)\n",
        "            with open(local_path, 'wb') as file:\n",
        "                file.write(response.content)\n",
        "\n",
        "            print(f\"Downloaded and saved: {local_path}\")\n",
        "            return local_path\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading {s3_url}: {e}\")\n",
        "        # break                    # remove this break to run in loops.\n",
        "        print(\"\\nDownloaded.\")\n",
        "\n",
        "   except ClientError as e:\n",
        "        print(f\"Error fetching items from table: {e.response['Error']['Message']}\")\n",
        "\n",
        "index=input(\"Enter the index of the paper you want to access\")\n",
        "index=int(index)\n",
        "pdf_path=fetch_and_download_pdfs(\"paper_store\",index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EToi7c2e-JCX",
        "outputId": "d5402713-d3da-46fd-daae-aa7879838cc1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the index of the paper you want to access59\n",
            "Fetched required documents from table 'paper_store'. Starting download...\n",
            "\n",
            "Downloaded and saved: /content/drive/MyDrive/2402.11194v2.Evaluating_LLMs__Mathematical_Reasoning_in_Financial_Document_Question_Answering.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2yVx02qD_BBD",
        "outputId": "40901220-e83b-400f-b1c7-45174e503cb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/2402.11194v2.Evaluating_LLMs__Mathematical_Reasoning_in_Financial_Document_Question_Answering.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Caption + Text Baseline"
      ],
      "metadata": {
        "id": "9ZxQjTP-ghNE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe6ZqAhmyOfw",
        "outputId": "388485d8-e1e5-48cd-9094-533b1416a14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'base64_image': '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', 'text': 'Evaluating LLMs’ Mathematical Reasoning in Financial Document Question Answering Pragya Srivastava∗†, Manuj Malik‡, Vivek Gupta§, Tanuja Ganu†, Dan Roth§ † Microsoft Research, India ‡ Singapore Management University § University of Pennsylvania {t-pragyasri, taganu}@microsoft.com, manujm@smu.edu.sg, {gvivek,danroth}@seas.upenn.edu Abstract Large Language Models (LLMs), excel in nat- ural language understanding, but their capabil- ity for complex mathematical reasoning with an amalgamation of structured tables and un- structured text is uncertain. This study ex- plores LLMs’ mathematical reasoning on four financial tabular question-answering datasets: TATQA, FinQA, ConvFinQA, and Multihiertt. Through extensive experiments with various models and prompting techniques, we assess how LLMs adapt to complex'}, {'base64_image': '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', 'text': '(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of\\nreasoning steps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex\\nreasoning.\\n(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\n'}, {'base64_image': '/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCADIAMgDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiigAooooAKKKKAKjXRRiv2a5bH8Sjg/rVDWNYbTbWKVYTmQMQshOSRjCgDuc/kDS3Gvm2uHh/sfVZdhx5kVuGVvcHPIpmpeIGs7CC6W0dDKrER3ClXBGAFwM8nP5A1Ti0rkRkm7XGwaxdAxLeQxxO84jZd5G0FN3U8Eg8HFQP4kdbSF/sx81tu9iT5eTvyFbODynY85qxBrV1mJby3iid5/LZdxG0FN3U8Eg8HFRf8JFM9rD5VlvnYAvniMffzh+hxs6575qSyKy8Q3V5f29slrHIJCN7RyE+Wu0Ek8kd+OecV0UreUm4JI/snJqhouqf2pA8uIlAwAin5hx1I7A9varl7d/YrYzfZ57jBA2QJub8s0nsJuyEiuPMkCfZ7hM/xMMD+dYEHiG8ubnZFaoYUKCV8udhZsbcd2A9O4NatnrJvLlYP7L1GDdn95PCFUfU5rMg8SXlzc7IrSIxIU81xuOws33cAcsB6dwaUHdbii01oPbxGxhyLSWNzKUzKrKoXzdnJOOcc4qC08S3d1PaxR2kcjTsoZUkOUBAJJ7dCcf7pq0PEUksQEVhN5rSlQHjYLgSbOSQMHHOKs6Jq7aqshZIYygAKK+Wz3P8Au54BHXBqijSmbyomcJJJj+FOSarxXhllVDaXaZ/idcAfXmpb26+xWklwLee42Y/dQJuduccCs208Qm7u44P7F1eDeceZNbhUX6ndxUt2djaFNyg5JX+Znv4reKa4t5bPZMnmGLdJhZAobaPXJK4p7+JpRaRyGxkikZuRLkAD95gZOPm+Qce/fFI/i1o57i3lsgk0fmGLc+FkChtuPclcVL/wkdxLbRsmnOszEkpLlVA/edWOAD+7GfTPtVGIyy8Q3V5fwWyW0ciucyPHIT5a7c5PUd+OeRXRxMWhRj1Kgms7R9T/ALUtZJcRKBgBFPzDjqw7Z6j2rQg/494/9wfyoAkooooAKKKKACikbO07euOK89nvr8eFWEdxe+f9oU73MoYHyhuGQM/63cAOmcD7tAHodFVIofMTe4bcSesjDv7U4W6nPDdf+erUAWaKr/Zl9G/7+tR9mX0b/v61AEm2btImO2UP+NJtm/56R/8Afs/40z7Mvo3/AH9aj7Mvo3/f1qAH7Jv+ekf/AH7P+NGybGPMj/79n/GmfZl9G/7+tR9mX0b/AL+tQA8JMOkkf/fs/wCNG2b/AJ6R/wDfB/xqNbZSo4b/AL+tS/Zl9G/7+tQA/bN/z0j/AO+D/jRsm/56R/8Afs/40z7Mvo3/AH9aj7Mvo3/f1qAH7Zv+ekf/AHwf8aNkw6SR/wDfs/40z7Mvo3/f1qPsy+jf9/WoAk2z/wDPSP8A74P+NG2f/npH/wB8H/GoZIY442d8qqjJJlbilSBHRWXJUjIIlbmi/QCTZKerx/8Afs/40bJv+ekf/fs/40z7Mvo3/f1qPsy+jf8Af1qAHlJsECSMZ/6Zn/GnouyNVznaAKh+zL6N/wB/Wo+zL6N/39agCxRVf7Mvo3/f1qRrdQOjf9/WoAs0VVlgCRMw3AgZB81qKALVFFZP/CR2B0qTUUFw9vE2H2wMWUY3btuM42kHPoRQBpQ/cP8AvN/M09eh+ppkP+rP+838zRFKkoYo4YBiDjsaLgSUUUUAFFFFABRRRQAi/dFLSL90UtABRUcs8cWAzfMeijkn8KhaWZlLHbbxjq8nJ/LoPxqXJIVyw8iRrudgq+pNQ+fJL/qIjj+/JwPy6ms7+1NNWQ+Q0t/OP+eCGUj8R8o/MVL9o1i5/wBTZwWif3rl97f98rx/49U81/8AgE86exYmt4zA73cxZQpLFjtVR6//AK6VP9GjVoz5lsQCMHJUeo9RVC60F9Rs5oNR1K6mWRCpSLESD8AOfxJogE3h+3jgffcabGoVZQMyQgD+ID7y+45Hf1qbWd7W8ybtO7VkbKsrqGUgqeQRS1VUbVE9oVkicbiqnIYHup/zmp45FlTchyP5e1aJ9GaJj6KKKoYUjfdpaRvu0AMuP+PeT/dNFFx/x7yf7pooAewDKVPQjFYFn4dmg057KW8SSN5ImYrEVJWPYoHU9VjAPuT9K6CigCKJF2H5R99v/QjUUdhaqGxEMlic5Oamh+4f95v5mnIQQcEHBPSk4p7oVkV/sKD7kkqfRyf55o+zTL924B/34wf5Yon1Kxtf+Pi8t4v9+QCqv/CQae3EDy3B/wCmEDyfqBiofIupLlFdS1suV/ggf6Er/jR5jr9+zb6owNVf7Uu5P+PfR7tveVkjH6tn9KDJrkv3bextx/tytIfyAH86L9mw5l0uWvtMA+/HIn+9Gacs9o3SWP8A76qn9h1ST/XavsHpb26r+rbqa/h+3nUi6ur25BGCJLggfkuBRefQV5dELLrek28KO11C28ZUK4O6q39oXN5/x66fcMh6HHlL/wB9Pz+S1b0bQrDRbOOC1hGVBzKwBduc8nFadJRnJe8/uBKbXvOxjR6fqUn37i3s1PUW8fmOfq7/APxNSpoFhuD3CPdv/eunMn6HgfgK1KKpQih8keoxYY0QIiKqjoAMAUvlr/dFOoqyxjIu0/KOlKI1x90UrfdP0pR0oAyZNPlsJGn0xFKMcyWZOFb3Q/wt+h9utS28sF8rT2h2yodskTjBB/uuOx9/5itGqN5pwuJBcwSG3vFGFmUZyP7rD+Jfb8sVDjbYhxtsWInjlBGza6/eQ9RUnlr/AHRWZFdma4W2u0+y6goOwg5WQeqH+Ieo6j9avxTFm8uQbJQOnZh6iiMu41K5J5a/3RSMi4+6KfSN92rKIp0UQScD7pop1x/x7yf7pooAexIUkDJA6Vwx8S36eHln+1LLKbhN8qmNCsZgErAZBXhsoMj0HXmu6qD7FaGMx/ZodhOSvljBOd2cfXn60AFu5aHcEbBZjzj1NYun+FbC1ScTLNdebO8uJXOBk9MA4P1rdh+4f95v5mnr0P1NS4xk7tEyhGTu0VINOsbX/UWEMR9UjUGrWT/cb9KdRTSS2GklsN3H+436Ubj/AHG/SnUUxjdx/uN+lG4/3G/SnUUAMVjtHyN+lLuP9xv0pV+6KWgBu4/3G/Sjcf7jfpTqRmVFLMQFAySTwKAE3H+436VFc3cNnA01y6xRL1d2AA/Ws86tNfEx6RCJh0N1JkQr9O7/AIce9S22jxpOt1eSteXa8rJKPlT/AHF6L/P3q+W3xEc1/hKF/Nqmt6fcQabG1lFJGVF3PlXPH8K9R9Tj2FXNEnmFitldF3vbRVjmJOd/HDg9w3X8x2q9dXUNrCzSMMgE7QeTVK8jeWODVLJS1xEudnTzYzyUPv3HoR7mne6tayJtaXNe7NLcf7jfpRuP9xv0pltcxXdtHcQtujkGVP8AnvUtZmu5Wu7WG9gMNxCWXOQc4KnsQc5B9xWa802ngRalultQf3d6MBkPbzMdP97p64rbpCAykEAg8EGplG5LjfVFaO4ZCqTDO77kgxh/8DU7Mdv3G/SsqSym01WNnGZ7I/fsyeU94yf/AEHp6YqWLUoRaiZZTLbk7Q+PmQ/3WHXP61Cny/EJStoy7Ox8iT5D90+lFLOc27n/AGaK1LMe41q8tvEIs1snurNgu+WBCDbE4A3E8ODnPy8gdRjmr/8AbOm/ZRci+gMBk8oSBwQX/u/WsWS8z42GnC7YoT55QW8h2v5RUIZPuAbRux1zUMeg6nHokloYIPtBdDDJHdMnlMsSxK+QuTwu7HvjmgDqofuH/eb+Zp69D9TUUKfuzlmJ3Nnn3NZEN1p0HmJ/bCwsZGOJJFXv6N1+tNK+gndK9tDdorJW/gP3NXs5P96Rf6NUq3ueklvJ/wBc7gf1p8rJ50aNFUhdr/FHMPdSG/kaeLu37ysv+/lf50rMrmRaoqNGjk+5Lu+jZp2z/ab86QxV+6KWsy71eys1RfNaaZxlIYTuZh6+gHucCqPl32q83TSJbn/l2tnIB/35eM/RfzNWoPdkOaWi1ZeuNYTz2tbCJr26U4ZYzhIz/tv0X6cn2qFtN88ibXLlJgDlbZflgU/Tq5/3vyFW7exaGFYYyltCvCxQDAH4/wD1qnS0hjbcqkv/AHmOT+ZoulsLlcviGi4ZgFt4GKjgM3yKP6/pR5E0n+unIH92L5R+fX+VT7P9pvzo2f7TfnU3Lt3I1t4YkYJGoyOeMk/X1qMj7IS6j9weXUfw+49vWn3MsdtbSTSuwRRk806FknhSVGYo6hhk9qV9R8jtczmI0q+85T/oF243+kUp6N/ut0Pvg9zWtVGa3jSN4Zl32coKsp6Lnt9D+lQ6fJJbztplzI7SRruhkY8yx+v+8Oh/A96t6q5mnZ2NSim7P9pvzo2f7TfnUGg6sHxDo9zdWzzaTIsF+xUMxOFkUEfeGMEjsevatzZ/tN+dIycfeb86mUVJWZMoqSsxs2RauCcnbziiknX9xJy33T3oqijnRJaHx2YZYbU3IG+KRb1RIAYwDuhzluhwccA11Fc5NcxP4riSS+cvDKVjswIxz5JbzM43lcEj0zVWTxbNa+GpdQuUtVuBIixgsVjIeNZRkk9QrH6le2cUAdTD9w/7zfzNVH0m0fLpEkcmSdwUHP1B61ZhcbD1+83Y+prN0LxFZa9FdPaiRfs87Qurrzkd8DsaTavY0jGfK5R2W49rW0i4vdOtdv8Az2WEFfx44/l71L/YukSAN/ZtkwPIPkIc/pV7cD2b/vk1VNv5TF7RjETyUKkofw7fhT5pLqRywlurEJ8O6K3XSrL8IF/wph8NaKf+Ybbj6LirUd8oYR3CNDITgA9G+h7/AM6s7x6N/wB8mqVSXch0ordGQfCmh5yNPQH/AGWYfyNK/hjTGjKItzHkY+S6lGP/AB6tbePRv++TRvHo3/fJp+0n3F7KHZGRoHhuy0LTo7aJRK6/emdRuY5rZpiuNo4b/vk0u8ejf98mlKTk7scYqKtEdRTd49G/75NQS3qIxjjVpZv7iDkfX0qS0m9iz0qobtpSUtEEh6GQ8IPx7/hTfIe4+a7Ylf8AnigO38fX+XtVoFVAAUgDoAppasrSPmV/sSMC9yfPfBHzj5R9B2oh/wBElEB4hf8A1X+ye6/1FWGcbTw3T+6aZMiTwmNg3PQgHIPYii3YOdvSWxKQCCCMg9Qay760YxoiPseNt9rMf+Wb/wB0/wCyen0P0q5bXBcNHKD50fDYU8+hHsamfY6FWUlSMEFTVRlbUznDoyCwvRfW3mbDHKpKSxHrG46g/wCPcEGrVYV0X0q8F8odoiAs4wcug6N/vL+q57gVtJKkiK6EsrDIIGQRTkuq2JjK+j3H0jfdpN49G/75NIzjb0b/AL5NSWJcf8e8n+6aKbO48iTg/dPY0UAc+b8nxwtght5HIMrOjbpI4hHjy2AXKgvhgSQD9a1otC0yG3kt0s4xDICGQ5IOfr/kAAdKrW3h2Cx1ttRsp5YVlMjT22d0bs5BLDPKsSATg4Pp3rXMiAZLrjOM57+lADYfuH/eb+ZrPutGhmb7RaEWd6hYpPEo5yckMP4gT1B/Q81oQ/cP+838zT16H6mk0nuVGcou6M2y1RmuBY6hELe+wSoBykwH8UZ7+46j9a06rXtjb6hbmC5j3LncpBwysOjKRyCPUVnJfXOjusGqP5tqTtjvsYx6CUdj/tdD7d1e25pyqprDft/l/kbEkaSoUkUMp6gjIqt5M9tzbt5kf/PKQ9Po39DVsHIyKKdjNSa0IIbqOZinKSjrG4ww/wAfwqeopreKdQJFzjkEcEfQ9qgLXFoCWzPCOp6Oo/kaNh2Uti2v3RUc1xFbqDI2CeFUclvoO9VLe7lv4Fe0Xy4j/wAtZBz+A/xqzDaxwkvy8h6yOcsf8+lF77A48rtL7iPbc3X3ybeI/wAIPzn6nt+FTxQxwJsiQKvt3qSiiwnJvQKKKKZIjfdP0pR0pG+6fpSjpQBXuY2BWeIZlTt/fXuP8KmjkWWNZEOVYZFOqof9EuM/8sJW5/2H/wAD/P60ti17ysWZI1ljKOMqaxrF30i/GmTn/RZiWtJOwPUx/wBR+I7Ctuq99ZRX9o9vLkA4KspwyMOQwPYg81cX0exjKN9VuWKRvu1n6ZfSStJZXeFvrfAkxwJF7Ovsf0ORWg33aTVnYpNNXQy4/wCPeT/dNFFx/wAe8n+6aKQx7AlSAcHHBrh49Lu18J3entpU6yylfKVUjbDiNVZuTgbnVju64bPBruaKAIYA/lctzubt7mnqGwfm7+lJD9w/7zfzNPXofqaAEw3979KR4/MRkfDKwwVZQQRT6KAMM213oXzWYkudO/ithzJAPWP1X/Z7dvStS1uYr22S4tp1licfKy/56+1WKybrTJoLl77SmWK5Y5lhbiK4+v8Adb/aH45qbW2NuZVPi0ffv6/5/f3NTDf3v0o2sf4v0qpp+pw34dNrQ3MXE1vJw8Z9/UehHBq7TTuZSi4uzIoohHEqJhVA4AUAU/Df3v0pV+6KWmIbhv736UYb+9+lOooAbhv736UYb+9+lOooAYwbafm7elKA2PvfpSt90/SlHSgBuG/vfpTZIvNjZHOVYYIIqSigCrbtIrtbyOS6DKsR99fX6+v/ANerGG/vfpUdzCZFDxkCVDlCf5H2NOgmE8QcAg9GU9VPcUl2KeuqM7VrCaXy720P+m22SmOPMX+JD9e3vip7G9W/tFlR8EgEjH+fp7EYq9XMa/Iug79Q83ybWZx5jDrHIf4gB1Ddx6gH1rWK5/d6mE3ye/06nQzhvIk+b+E9qKWY7rViDkFc59aKzNSQkKpJ6DmsFPEkkmhz6kthjyGBeJpgD5ZQOCDjklWX5fU4z3rfIyMHpWGPC9qlottHd3qIsqyjEgPK4Cg5BBACqB/ujvzQBrwuuw/MPvN39zTldOfmXr60kP3D/vN/M09eh+poATen95fzo3p/eX86dRQA3en95fzo3p/eX86dRQBn6hp0F8UmSYwXcX+quIyNyex9VPcHiobPVnW4Wx1NUhuz/q3U/u5x6oex9VPI9xzWtVa/sYdRspLWdQVccHHKnsw9weRUtdUaxmmuWe35f12Jlddo+YfnS70/vL+dc3o+g6zo2lW9rBra3BjByLm33Kcknghgw/Emr327Wrb/AI+dIjuFHV7O4BP/AHy+3+ZoUtNUVKiuZqEk19352Nben95fzo3p/eX86yR4l05CFuzPYt6XcLRj/vojb+tacFzb3UfmW88Uyf3o3DD8xTTT2M5U5x1kh+9P7y/nRvT+8v506imQMZ02n5l6etKHTH3l/Olb7p+lKOlADd6f3l/Ojen95fzp1FADd6f3l/OqsrLbTfaFYeW2BKAeno3+Pt9KuUhAIIIyDQxp2E3p/eX86r31rZ6hatb3cUU8JIJR+RkHIogP2eX7M33DzET6f3fw/lVlvu0J9QlHo9iKdk+zuAy/d9aKdcf8e8n+6aKBElFI2dp29ccVxNrdyp4bczzagsiXUDhm83fnMfmA9yu/zOOnXtQB2cP3D/vN/M09eh+pqKHfsP3fvt/M09d/P3etAD6Kb8/+zR8/+zQA6im/P/s0fP8A7NADqKb8/wDs0fP/ALNACr90UtMXftH3aX5/9mgBSARgjINZs/h7SbiTzGsYkl/56w5jf/vpcGtH5/8AZo+f/ZpNJ7lRnKGsXYyf7GvLf/jy1q8jH9y42zr/AOPDd/49R5viC2/1ltY3q+sMjQt/3y2R/wCPVrfP/s0fP/s0uXsX7Zv4kn8v1VmYd34og0+zmn1HT9QtREhZt0O9T7BlJX8yKdB4v0Oe3imW9wJEDANG2RkZ54rWniE8EkU0cckbqVZGGQw9CKdHH5USRxoiooCqqjAAHQCi0r7lc9Fx1i7+T0/JmX/wlWi/8/o/79v/AIUf8JTo3/P5/wCQn/wrW+f/AGaPn/2aLS7i5qP8r+9f5GT/AMJTo3/P2f8Avy//AMTR/wAJTo//AD9N/wB+JP8A4mtb5/8AZo+f/ZotLuHNR/lf3r/IxJ/EejTx7ftcisDlWFvJlT2P3arXXjnRrLT2uLiWUshCuiQPnJOOMgDHeuk+f/ZrM1mEG2Mr2qXK5UPCy7g4zkZHseRSlzJXTNKToSkoyi7eq/yNCZg1q7DkFciimzb/ALM+QB8vSirOUnooooAgXz0yBHGRuJBLkdTn0qGzvHvIWlhjQqJHQ7mZTlWIPBXPUGrtVNOs3soZUefzi8zyg7AuNzFsfhk0ATbrj/nlF/38P/xNG64/55Rf9/D/APE1LRQBFuuP+eUX/fw//E0brj/nlF/38P8A8TUtFAEW64/55Rf9/D/8TSNJOqljFHgDJw5P/stTU2RWaNlR9jEEBsZwfWgCpZXj3tqk8MaFCSMMzKQQSCCCuQQQRzVjdcf88ov+/h/+JrKsr2x0jy9GmvPMu4URmJjIL+YzAMe2SwOTnryetar3MEZw88a9/mcCgA3XH/PKL/v4f/iaN1x/zyi/7+H/AOJqKHULWdJWWdAIpDE+442sG24P4jj1qY3EKq7GaMKh2sSwwp9D6UAJuuP+eUX/AH8P/wATRuuP+eUX/fw//E1Qk1+xSKWQedII7g222KJnZ5AMkKBycYOfoatwahaXKkw3EbYdoyM4O5fvDB7jFABPNNFBJI0KEKpJCszH8AFyfwpLe5kubaOeFYnikUMrCQ8g/wDAaWaSK5gaGG4g3zIwTdhwex4BGR680afZjT9Ot7NXLiGNYwxGM4GOlAEm64/55Rf9/D/8TRuuP+eUX/fw/wDxNS0UARbrj/nlF/38P/xNG64/55Rf9/D/APE1LRQBFuuP+eUX/fw//E1F9oeTzFT7OxRtrgTfdPoeODVqsi68OWF9c3Nxc+ZJJOoQnIAVQQQoAHqM5OT70AWPtn2m5nsU8ozxoryKHJ2q2cH7uP4Tx/jRUenaHbaZfT3NvJN++iSMxu5KjbnBA7cH9KKANOiiigAooooAKKKKACiiigAooooA5fXvC0+raqt5DcRxcJG24EkxgPuH/fRQj/dNVB4Onu3afUUsHmZgdoUuFGGGASP9pfyoooAqTeBr6ZHDvZ8OWIjdkNwG3Z8xtpwV3ccH8K2LnwzIdBFlBHZvKLqS4ZZgfLl3F/vnBJIDg5x1UfWiigBsvhh08NPpsUVtNM07TCR5GhIYk4kDINwccc/UZrLu/Bl7hpSYZiizHMbFGkZju3kbeWJO0jIyAOe1FFAF/Q/Dd7YajaXrR2UACt50cJJCgrgIqleOfmLAjksMHrXW0UUAFFFFABRRRQAUUUUAFFFFAH//2Q==', 'text': '(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of\\nreasoning steps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex\\nreasoning.\\n(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\n'}, {'base64_image': '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', 'text': '(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of\\nreasoning steps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex\\nreasoning.\\n(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\n'}, {'base64_image': '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', 'text': '(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of\\nreasoning steps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex\\nreasoning.\\n(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\n'}, {'base64_image': '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', 'text': '(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of\\nreasoning steps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex\\nreasoning.\\n(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\n'}, {'base64_image': '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', 'text': '(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of\\nreasoning steps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex\\nreasoning.\\n(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\n'}, {'base64_image': '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', 'text': '(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of\\nreasoning steps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex\\nreasoning.\\n(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\n'}, {'base64_image': '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', 'text': '(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of\\nreasoning steps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex\\nreasoning.\\n(a) TATQA\\n(b) Multihiertt\\n(c) FinQA\\n(d) ConvFinQA\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\n'}, {'base64_image': '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', 'text': 'Figure 4: Accuracy of different arithmetic operations across different orders of magnitude\\n'}, {'base64_image': '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', 'text': 'Figure 5: Sample distribution of examples in numerical reasoning on tabular datasets partitioned by the number of reasoning\\nsteps involved. Clockwise (from top-left) : FinQA, ConvFinQA, TATQA, Multihiertt.\\n'}, {'base64_image': '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', 'text': 'Figure 6: Sample distribution of Numerical & Tabular Reasoning Datasets partitioned by Question Concept Category types.\\nClockwise (from top-left): FinQA, ConvFinQA, Multihiertt, TATQA\\nFigure 7: Sample distribution of Multihiertt & FinQA datasets partitioned by number of rows in the supporting table.\\n'}, {'base64_image': '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', 'text': 'Figure 6: Sample distribution of Numerical & Tabular Reasoning Datasets partitioned by Question Concept Category types.\\nClockwise (from top-left): FinQA, ConvFinQA, Multihiertt, TATQA\\nFigure 7: Sample distribution of Multihiertt & FinQA datasets partitioned by number of rows in the supporting table.\\n'}, {'base64_image': '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', 'text': 'Figure 8: Sample distribution of Multihiertt Dataset partitioned by depth of hierarchy of the gold evidence\\n'}, {'base64_image': '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', 'text': 'Figure 9: Sample Distribution of Multihiertt partitioned by the percentage of empty cells in the supporting table\\n'}, {'base64_image': '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', 'text': 'Figure 16: This illustration demonstrates how the \"depth of hierarchy\" is determined for each supporting piece of evidence. The depth of hierarchy corresponds to the number of levels or tiers of information structure within the table. The top level (1) encompasses the table itself, which contains information about the results of operations in a firm’s Advice & Wealth Management segment. The second level (2) includes columns specifying the years (2009, 2008, Change), creating a substructure within the table. The third level (3) involves the column \"(in millions, except percentages),\" and the fourth level (4) encompasses the rows under categories like'}, {'base64_image': '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', 'text': 'Figure 16: This illustration demonstrates how the \"depth of hierarchy\" is determined for each supporting piece of evidence. The depth of hierarchy corresponds to the number of levels or tiers of information structure within the table. The top level (1) encompasses the table itself, which contains information about the results of operations in a firm’s Advice & Wealth Management segment. The second level (2) includes columns specifying the years (2009, 2008, Change), creating a substructure within the table. The third level (3) involves the column \"(in millions, except percentages),\" and the fourth level (4) encompasses the rows under categories like'}]\n"
          ]
        }
      ],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "import fitz\n",
        "from PIL import Image\n",
        "from dotenv import load_dotenv\n",
        "import io\n",
        "import base64\n",
        "\n",
        "def extract_images_and_text(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    images_and_text = []\n",
        "\n",
        "    for page in doc:\n",
        "        text = page.get_text()\n",
        "        image_list = page.get_images(full=True)\n",
        "\n",
        "        for img_index, img in enumerate(image_list):\n",
        "            xref = img[0]\n",
        "            base_image = doc.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            image=image.resize((200,200))\n",
        "            buffered = io.BytesIO()\n",
        "            image.save(buffered, format=\"jpeg\")\n",
        "\n",
        "            img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "\n",
        "            words = text.split()\n",
        "            text_before_image = \" \".join(words[:100]) if len(words) > 100 else text\n",
        "\n",
        "            images_and_text.append({\n",
        "                \"base64_image\": img_base64,\n",
        "                \"text\": text_before_image\n",
        "            })\n",
        "\n",
        "    return images_and_text\n",
        "\n",
        "# Usage\n",
        "# pdf_path = \"/content/drive/MyDrive/eedp.pdf\"\n",
        "images = extract_images_and_text(pdf_path)\n",
        "print(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IoTqEkRaujrz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "74579a4f-56ee-4a6f-afd0-67cce7cb1e75"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0bd378a95441>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ],
      "source": [
        "if len(images)>0:\n",
        "\n",
        "  print(images[0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dUkAbN3ch0fW"
      },
      "outputs": [],
      "source": [
        "import requests, base64,os\n",
        "os.environ['NVIDIA_API_KEY']=userdata.get('NVIDIA_API_KEY')\n",
        "\n",
        "def caption(image):\n",
        "    invoke_url = \"https://ai.api.nvidia.com/v1/gr/meta/llama-3.2-90b-vision-instruct/chat/completions\"\n",
        "    stream = True\n",
        "\n",
        "    # with open(\"image.png\", \"rb\") as f:\n",
        "      # image_b64 = base64.b64encode(f.read()).decode()\n",
        "\n",
        "    assert len(image) < 180_000, \\\n",
        "      \"To upload larger images, use the assets API (see docs)\"\n",
        "\n",
        "\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {os.environ['NVIDIA_API_KEY']}\",\n",
        "      \"Accept\": \"text/event-stream\" if stream else \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "      \"model\": 'meta/llama-3.2-90b-vision-instruct',\n",
        "      \"messages\": [\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": f'What is in this image? <img src=\"data:image/png;base64,{image}\" />'\n",
        "        }\n",
        "      ],\n",
        "      \"max_tokens\": 1024,\n",
        "      \"temperature\": 1.00,\n",
        "      \"top_p\": 1.00,\n",
        "      \"stream\": stream\n",
        "    }\n",
        "\n",
        "    response = requests.post(invoke_url, headers=headers, json=payload)\n",
        "\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZoM5jmqMcOWy"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def output_caption(response):\n",
        "  output = \"\"\n",
        "  for line in response.iter_lines():\n",
        "      if line:\n",
        "          decoded_line = line.decode(\"utf-8\")\n",
        "          if decoded_line.startswith(\"data: \"):\n",
        "              try:\n",
        "                  json_data = json.loads(decoded_line[len(\"data: \"):])\n",
        "                  if 'choices' in json_data:\n",
        "                      data = json_data['choices']\n",
        "                      if 'delta' in data[0] and 'content' in data[0]['delta']:\n",
        "                          content = data[0]['delta']['content']\n",
        "                          output += content\n",
        "              except json.JSONDecodeError as e:\n",
        "                  pass\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BzBzFV-cevsb"
      },
      "outputs": [],
      "source": [
        "for i in images:\n",
        "  response=caption(i[\"base64_image\"])\n",
        "  while(response.status_code==500):\n",
        "    response=caption(i[\"base64_image\"])\n",
        "  response=output_caption(response)\n",
        "  i['text']+=response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Y6xIKkA-cUB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa560a5-9778-4075-f764-e4e688eb2041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(a) Hierarchical Complexity (b) Empty Cells Figure 7: Sample distribution of Multihiertt Dataset partitioned by (a) hierarchical complexity of the gold evidence. (b) the percentage of empty cells in the supporting table. Specifically, for models with a context length exceeding the input length, we standardized k to 4. For instance, we allocated 2 shots for models like LLaMA and MammoTH due to their constrained context length. However, for other models capable of accommodating larger contexts, we increased the number of shots to 4. Additionally, we used a tempera- ture of 0 and topp = 1 for our experiments. 2. ModelsThe image displays a pie chart with six sections, each representing a different percentage. The chart is divided into six equal parts, with each section labeled with a number from 1 to 6 in the key on the right side of the chart. The percentages are represented by different colors, ranging from dark orange (29.795%) to light blue (7.736%). The background of the chart is white, providing a clean and simple visual representation of the data.\n"
          ]
        }
      ],
      "source": [
        "if len(images)>0:\n",
        "\n",
        "  print(images[2]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "frrC1RkPoqMg"
      },
      "outputs": [],
      "source": [
        "# pdf_path = \"/content/drive/MyDrive/eedp.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoCuYdNyodwI",
        "outputId": "93aab2df-719f-430e-b48d-e2c1003e150e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 0}, page_content='Evaluating LLMs’ Mathematical Reasoning in Financial Document\\nQuestion Answering\\nPragya Srivastava#∗, Manuj Malik ‡, Vivek Gupta §†, Tanuja Ganu #, Dan Roth §\\n#Microsoft Research, ‡Singapore Management University, §University of Pennsylvania\\n{t-pragyasri, taganu}@microsoft.com, manujm@smu.edu.sg, {gvivek,danroth}@seas.upenn.edu\\nAbstract\\nLarge Language Models (LLMs), excel in\\nnatural language understanding, but their ca-\\npability for complex mathematical reasoning\\nwith a hybrid of structured tables and unstruc-\\ntured text remain uncertain. This study ex-\\nplores LLMs’ mathematical reasoning on four\\nfinancial tabular question-answering datasets:\\nTATQA, FinQA, ConvFinQA, and Multihiertt.\\nThrough extensive experiments with various\\nmodels and prompting techniques, we assess\\nhow LLMs adapt to complex tables and math-\\nematical tasks. We focus on sensitivity to\\ntable complexity and performance variations\\nwith an increasing number of arithmetic rea-\\nsoning steps. The results provide insights\\ninto LLMs’ capabilities and limitations in han-\\ndling complex mathematical scenarios for semi-\\nstructured tables. Ultimately, we introduce a\\nnovel prompting technique EEDP tailored to\\nsemi-structured documents, matching or outper-\\nforming baselines performance while providing\\na nuanced understanding of LLMs abilities.\\n1 Introduction\\nIn the constantly evolving realm of artificial in-\\ntelligence, Large Language Models (LLMs) have\\nrisen as cutting-edge tools for natural language un-\\nderstanding. They excel in a wide array of NLP\\ntasks, including machine translation (MT), text\\nsummarization, question answering, and code gen-\\neration. One specific area where LLMs’ mathe-\\nmatical reasoning abilities come under scrutiny is\\nthe domain of numerical reasoning tasks. Past re-\\nsearch has delved into the potential of language\\nmodels for mathematical reasoning tasks, as seen\\nin studies such as in Amini et al. (2019); Upadhyay\\nand Chang (2017); Patel et al. (2021); Cobbe et al.\\n(2021). These investigations provide a means to\\nevaluate the performance of language models when\\n∗Work done during internship at Microsoft Research\\n† Primary Mentor and Corresponding Author\\nThe Goldman Sachs Group Incorporation\\nNotes to Consolidated Financial Statements\\nThe table below presents a summary of Level\\n3 financial assets.\\nFinancial Asset Dec. 2017\\nCash Instruments $15,395\\nDerivatives $3,802\\nOther Financial Instruments $4\\nQ: What was the total value of Level 3 finan-\\ncial assets for Goldman Sachs in December\\n2017?\\nA: $15,395 + $3,802 + $4 = $19,201\\nFigure 1: An example of a semi-structured financial docu-\\nment question answering.\\nit comes to solving mathematical problems, rang-\\ning from straightforward math word problems to\\nmore complex ones.\\nHowever, the problem becomes significantly\\nmore challenging when we encounter a hybrid of\\nstructured such as semi-structured tables and un-\\nstructured text, as shown in example in figure 1.\\nSuch tables are common in documents such as\\ninvoices, health records, and financial reports in\\ncorporate settings. In the financial domain, these\\ntables present numerical data in a structured for-\\nmat, including income statements, balance sheets,\\ncash flow statements, shareholder equity data, and\\nannual reports. The majority of NLP models are\\nprimarily trained to handle raw unstructured tex-\\ntual data, which limits their ability to reason over\\nsemi-structured data, such as tables, or more in-\\ntricate hybrids of tables and text, as seen in Chen\\net al. (2020b); Aly et al. (2021); Chen et al. (2020a,\\n2021a). Tables, especially these with intricate rela-\\ntionships and dependencies, often necessitate multi-\\nhop reasoning, connecting information across mul-\\ntiple steps, as shown in Gupta et al. (2020).\\nNLP models may encounter difficulties in per-\\nforming such multi-step reasoning, particularly\\nwhen dealing with complex mathematical opera-'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 1}, page_content='tions involving tables, as highlighted in Li et al.\\n(2022). Previous research such as Chen (2023),\\nexemplified these issues and demonstrated LLM\\ncapacity to process and reason with semi-structured\\ntables. However, these studies are somewhat con-\\nstrained and don’t explicitly explore the models’\\nmathematical reasoning abilities. This is particu-\\nlarly evident in data/tasks that involve a substantial\\nnumber of arithmetic reasoning steps, operate on\\nextreme orders of magnitude, or deal with intricate\\ntables where extracting the relevant information for\\na query becomes challenging.\\nMoreover, when handling domain-specific docu-\\nments, such as those in finance, a language model\\nmust not only have the necessary domain knowl-\\nedge to craft the right approach for task-solving but\\nalso the capability to manipulate structured data,\\nsuch as tables. Therefore, in this study, we aim\\nto fill this gap by providing both qualitative and\\nquantitative analyses of LLM’s ability to reason\\non mathematical content on four finance datasets\\ni.e. FinQA (Chen et al., 2021b), TATQA (Zhu\\net al., 2021), ConvFinQA (Chen et al., 2022b), and\\nMultihiertt (Zhao et al., 2022). These datasets fea-\\nture questions demanding intricate numerical rea-\\nsoning, combining semi-structured tables and text.\\nEach dataset provides pre-annotated executable pro-\\ngrams for precise answer retrieval. Our goal is to\\nillustrate how model performance varies as the nu-\\nmerical complexity of the underlying data and the\\nintricacy of the mathematical reasoning steps re-\\nquired to solve a query increase. Building upon\\nthese observations, we propose a novel approach\\ntermed (Elicit −→Extract −→Decompose −→\\nPredict) EEDP, designed to deconstruct model re-\\nsponses into discrete components. This innovative\\nmethod offers a deeper, more transparent insight\\ninto the numerical limitations of the model when\\ntackling these tasks. Our contributions are as fol-\\nlows:\\n1. We conduct a comprehensive robust evalu-\\nation of state-of-the-art Large Language Models\\n(LLMs) for tabular (hybrid) question answering,\\nwith a specific focus on mathematical reasoning\\ntasks, using public financial tabular datasets to es-\\ntablish a thorough performance benchmark.\\n2. Our analysis is thorough and multifaceted,\\nencompassing both qualitative and quantitative as-\\npects across several dimensions. We aim to provide\\nnuanced insights into the strengths and limitations\\nof LLMs in tabular (hybrid) question answering,\\nespecially in scenarios involving mathematical rea-\\nsoning.\\n3. Building upon qualitative analysis, we in-\\ntroduce a novel and improved prompting method\\ncalled EEDP. Our novel approach not only en-\\nhances our understanding of model weaknesses\\nbut also substantially enhances model performance\\ncompared to existing prompting methods across\\nmultiple models types.\\nOur metadata dataset and source code are avail-\\nable at https://vgupta123.github.io/eedp.\\n2 Metadata Annotations\\nWe annotated four tabular datasets: FinQA,\\nTATQA, ConvFinQA, and Multihiertt with meta\\ninformation related to a.) reasoning steps, b.) ques-\\ntion category, c.) table length, d.) hierarchical\\ncomplexity e.) missing information. 1 Below, we\\nprovide detailed information about these meta-data\\nannotations:\\n1. Number of Reasoning Steps: Including the\\ncount of arithmetic operations in questions is cru-\\ncial. More operations reflect increased complexity\\nin reasoning, and their interdependence offers in-\\nsights into the models’ proficiency. This annotation,\\napplied across all four datasets, reveals their ability\\nin handling intricate arithmetic tasks. Refer to Fig-\\nure 8 in Appendix A.4 for distribution of questions\\nbased on the number of reasoning steps involved.\\n2. Question Categorization: In numerical rea-\\nsoning, grasping the evolution from fundamental\\narithmetic to advanced operations is crucial, mark-\\ning a shift in cognitive complexity. As questions\\nadvance, they typically involve more intricate com-\\nbinations of operations and linguistic nuances. Our'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 1}, page_content='ing a shift in cognitive complexity. As questions\\nadvance, they typically involve more intricate com-\\nbinations of operations and linguistic nuances. Our\\nresearch identify both the capabilities and limita-\\ntions of LLMs in understanding these concepts.\\nWe establish 12 mathematical concept categories\\n(Table 1) with corresponding definitions, annotat-\\ning each question. The dataset coverage across\\nthese categories is shown in Figure 9 in Appendix\\nA.4. Notably, categories like DIVISION and RATIO\\nshare similarities but differ in focus: DIVISION\\ninvolves the division operator, while RATIO en-\\ncompasses ratios, fractions, and inverse problems.\\nCHANGE IN RATIO questions add complexity with\\nquantity changes requiring subtraction. Addition-\\nally, we omit NEED-IN-DOMAIN-INFO due\\n1One author annotated the data, and the other checked for\\naccuracy; we took stringent measures to minimize errors.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 2}, page_content='Concepts Definition\\nSUM Questions that require only the knowledge\\nof addition.\\nDIFFERENCE Questions that require only the knowledge\\nof subtraction.\\nPRODUCT Questions that require only the knowledge\\nof multiplication.\\nDIVISION Questions that require only the knowledge\\nof division.\\nRATIO Questions that require knowing fractional\\nforms, e.g., percentages, ratios.\\nCHANGE\\nRATIO\\nQuestions involving the difference be-\\ntween two fractional forms, e.g., percent-\\nage changes, difference in ratios.\\nRANGE Questions requiring knowledge of the min-\\nimum and maximum of data observations.\\nCOMPARE Questions necessitating a comparison\\nbetween mathematical quantities (e.g.,\\ngreater than, less than).\\nAVERAGE Questions needing knowledge of the aver-\\nage, used to calculate the central tendency\\nof a group of data points.\\nIN-\\nDOMAIN -\\nINFO\\nQuestions that require implicit knowledge\\nto understand domain-specific mathemati-\\ncal formulations (e.g., return on investment\\n(RoI), cost of goods sold (COGS), amorti-\\nzation rate, etc.).\\nTIME Questions explicitly involving mathemati-\\ncal operators for time-spans not in the table\\nor context.\\nCOUNTING Questions requiring the counting of ele-\\nments in a set or group of data points.\\nTable 1: Mathematical concept categories and definitions for\\nstudying LLM concept comprehension abilities.\\nto domain-specific knowledge focus and TIME\\nquestions due to limited sample size.\\n3. Table Length: Evaluating performance with\\nlarger supporting tables is crucial. Larger tables\\ncomplicate multi-hop reasoning tasks by increas-\\ning the amount of information, making it harder\\nto identify relevant evidence. We prioritize these\\nannotations for datasets like FinQA and Multihiertt,\\nwhere questions mainly use tables as supporting ev-\\nidence. Therefore, these annotations are confined\\nto these datasets. In Multihiertt, when multiple ta-\\nbles support evidence, we consider the one with the\\nhighest row count i.e. maximum table length. The\\ndataset distribution for Multihiertt and FinQA w.r.t\\ntable length (number of rows) is shown in Figure 6\\nin Appendix A.4.\\n4. Hierarchical Complexity: In hierarchical ta-\\nbles, such as those in Multihiertt, evaluating model\\nperformance concerning the growing hierarchical\\ncomplexity in cells with critical information be-\\ncomes paramount. To tackle this, we annotate each\\nexample in Multihiertt with the hierarchy depth\\nof cells containing relevant information. For table\\nwith multiple relevant cells, we consider the cell\\nwith the highest hierarchical depth for our analysis.\\nOur approach to estimating hierarchy depth is illus-\\ntrated in Figure 10. Figure 7(a) in Appendix A.4\\nillustrate how we calculate hierarchical complexity\\nfor examples with multiple relevant rows at various\\nhierarchical depths.\\n5. Missing Information: Interpreting a table be-\\ncomes challenging as the number of empty cells\\nincreases. Empty cells indicate missing or unde-\\nfined information, leading to potential gaps in un-\\nderstanding.\\nAssessing empty cell proportions is crucial to\\nquantify data ambiguity. More empty cells sug-\\ngest higher uncertainty, which can hinder models’\\nability to derive meaningful insights and impact rea-\\nsoning accuracy. In Multihiertt, where tables are\\nhierarchical in nature and empty cells occur quite\\nfrequently, we annotate examples with the empty\\ncells percentage, contributing to our understanding\\nof data ambiguity. For distribution of missing infor-\\nmation (empty cells proportions) across datasets,\\nrefer to Figure 7 (b) in Appendix A.4.\\nAnnotation Splits. We prioritized complex nu-\\nmerical questions in our selection criteria, bal-\\nancing this with resource constraints such as the\\nLLM context length limits. We also took into ac-\\ncount tables with deeper hierarchies in Multihiertt\\nand multi-turn conversations in ConvFinQA. For\\nTATQA, we utilized 45% of the development set by\\nfiltering out examples involving simple span selec-\\ntion. In the case of Multihiertt, we included 68% of'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 2}, page_content='TATQA, we utilized 45% of the development set by\\nfiltering out examples involving simple span selec-\\ntion. In the case of Multihiertt, we included 68% of\\nthe test set by excluding examples where the table\\nlength exceeds 40. For FinQA and ConvFinQA,\\nwe employed the complete test and development\\nsets, respectively.\\n3 Experimental Results\\nIn this study, we choose to experiment with LLMs\\nsuch as GPT-3.5-Turbo, GPT-4, PaLM-540B,\\nMistral-7B-Instruct2, Llama-2-13B3 and\\nMAmmoTH-13B4. These LLMs are at the cutting\\nedge for both open-source and closed models\\napplications. Models like MAmmoTH-13B are\\nspecifically fine-tuned during pre-training to excel\\nin mathematical reasoning tasks. For more detail\\nabout the the model choices refer to Appendix A.2.\\n2https://huggingface.co/mistralai/Mistral-7B-Instruct-\\nv0.1\\n3https://huggingface.co/meta-llama/Llama-2-13b-chat-hf\\n4https://huggingface.co/TIGER-Lab/MAmmoTH-13B'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 3}, page_content='LLMs Prompting Methods: For an instruction-\\ntuned LLM, it’s assumed that we give the model a\\ntask-specific instruction I accompanied with a few\\n(usually k ∈ {2, 4}) demonstrations DT of a task\\nT. We experiment with the following prompting\\ntechniques:\\n(a.) Direct: In this setup, we explicitly in-\\nstruct the models to abstain from providing ex-\\nplanations and just return the final answer to the\\nposed question. For this scenario, DT contains\\n{(pi, qi, ai)}k\\ni=1 where p is the premise (table-text),\\nq is the question, and a is the ground-truth answer.\\n(b.) CoT: Moving forward, we experiment with\\nthe chain-of-thoughts prompting strategy where\\nwe instruct the model to output the explanation to\\nthe answer derived by it. Here, our DT contains\\n{(pi, qi, ei)}k\\ni=1 where p is the premise which in-\\ncludes the table and the associated text, q is the\\nquestion and e is the explanation of the answer.\\n(c.) PoT: In this case, the expected response\\nis a code derivation of the answer. Here, DT con-\\ntains {(pi, qi, ci)}k\\ni=1 where p is the premise which\\nincludes the table and the associated text, q is the\\nquestion and c is the code-derivation of the answer.\\n(d.) Decomposers: (Ye et al., 2023) proposed\\nto address the challenge of handling large tables\\nby decomposing them into more manageable sub-\\ntables. Similarly, complex questions are handled\\nby breaking them down into simpler subquestions.\\nDecomposition proves effective with SQL tables,\\nfacilitating the removal of distracting details while\\nretaining all supporting evidence. Questions are\\nfirst parsed to break them down into simpler, more\\nmanageable subquestions. The model then ad-\\ndresses each subquestion independently before\\ncomposing the answers to arrive at the final so-\\nlution. In this case, our demonstration set DT con-\\ntains {(p\\n′\\ni, ⟨q1, q2, ..., qn⟩, ai)}k\\ni=1 where p\\n′\\nis the\\npremise obtained by the irrelevant information re-\\nmoval to the question from the original premise\\np and ⟨q1, q2, ..., qn⟩ are the subquestions whose\\nanswers lead to the final answer.\\nEEDP Prompting Strategy: We propose a\\nnovel prompting strategy: Elicit −→Extract −→\\nDecompose −→Predict. Figure 4 show an illustra-\\ntion of our EEDP approach. Below are the detail\\nof each EEDP step:\\n1. Elicit: We prompt the model explicitly to first\\nelicit relevant domain knowledge for answer-\\ning a given query.\\n2. Extract: Conditioned on the table, question\\nand the elicited domain knowledge, the model\\nextracts supporting evidences to answer a\\ngiven question.\\n3. Decompose: We instruct the LLM to break\\na complex mathematical reasoning task into\\nmultiple atomic operations and compose the\\noperations to arrive at the final answer.\\n4. Predict: The model finally returns the derived\\nanswer in the above steps.\\nFigure 11 shows a example for EEDP strategy\\nwith one shot.\\nResults and Analysis. Table 2 shows a compar-\\nison in performance between different prompting\\nstrategies. Despite being a single prompt, EEDP\\ndemonstrates comparable or superior performance\\ncompared to PoT. Notably, we outperform PoT\\nsignificantly for PaLM-2-540B and LLAMA-2-13B\\nacross most datasets. Moreover, while PoT relies\\non external tools for executing mathematical pro-\\ngrams/code to obtain answers, EEDP exclusively\\nutilizes LLM for all tasks, including evidence ex-\\ntraction, operation identification, and execution,\\nensuring precision throughout the process.\\nAs shown in Table 2, the Decomposers prompt-\\ning strategy exhibits a much poorer performance\\ncompared to other strategies. The reason behind\\nthis was statistically found to be the inaccurate for-\\nmation of subtables from the main table, leading to\\ninformation loss as described in the previous para-\\ngraph. The performance of EEDP either surpasses\\nor matches very closely with that of PoT. The num-\\nber of shots was adjusted depending on the context\\nlength of the model.\\nWe can see that MAmmoTH-13B model, which is\\nfine-tuned on the MathInstruct dataset (Yue et al.,\\n2024) containing Instruction-Response pairs where'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 3}, page_content='length of the model.\\nWe can see that MAmmoTH-13B model, which is\\nfine-tuned on the MathInstruct dataset (Yue et al.,\\n2024) containing Instruction-Response pairs where\\nthe responses are a hybrid of CoT and PoT ratio-\\nnales, fails to perform well with the EEDP method-\\nology. We argue that this is due to two potential\\nreasons: (a.) Reduction of the number of shots\\nto adjust the context length as the EEDP response\\nis longer than that of the other methods, and (b.)\\nFinetuning may contribute to suboptimal perfor-\\nmance due to its alignment with a particular style\\nand format of responses, potentially limiting the\\nmodel’s adaptability and generalization to other\\ndiverse contexts.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 4}, page_content='Dataset Model Direct CoT PoT EEDP Decomposers\\nGPT-4 55.81 86.91 89.99 88.67 47.46\\nGPT-3.5-Turbo 31.38 77.57 82.11 79.73 28.53\\nTATQA PaLM 2-540B 44.66 62.93 61.60 81.51 57.94\\nLlama 2-13B 3.36 35.95 34.16 40.95 25.93\\nMAmmoTH-13B 19.11 56.25 10.02 4.37 22.89\\nMistral-7B 10.92 59.14 16.53 56.06 7.24\\nGPT-4 65.12 72.38 75.26 76.05 44.93\\nGPT-3.5-Turbo 40.47 59.18 68.97 61.88 32.33\\nFinQA PaLM 2-540B 30.33 34.79 30.41 61.95 46.38\\nLlama 2-13B 1.80 25.34 12.97 30.47 11.91\\nMAmmoTH-13B 22.83 35.32 15.86 35.05 17.65\\nMistral-7B 26.11 34.23 10.56 34.86 12.34\\nGPT-4 63.10 71.19 78.81 77.91 18.76\\nGPT-3.5-Turbo 37.62 48.33 61.19 61.75 10.50\\nConvFinQA PaLM 2-540B 20.19 38.00 40.14 63.42 22.32\\nLlama 2-13B 3.80 29.45 29.92 39.42 10.35\\nMAmmoTH-13B 21.61 46.08 8.78 32.77 7.83\\nMistral-7B 12.35 48.45 14.48 36.57 11.16\\nGPT-4 41.35 55.13 67.23 70.32 36.86\\nGPT-3.5-Turbo 25.88 42.33 52.18 49.65 20.61\\nMultihiertt PaLM 2-540B 14.20 20.67 36.52 37.97 20.19\\nLlama 2-13B 1.54 30.66 18.12 24.15 16.86\\nMAmmoTH-13B 10.12 18.56 6.57 18.36 11.87\\nMistral-7B 14.909 22.92 14.94 10.97 11.63\\nTable 2: Comparison of performance of different models tested against a variety of prompting strategies\\nEEDP’s Computational Efficiency EEDP func-\\ntions as a unified single-prompt method, minimiz-\\ning computational complexity. Unlike methods like\\nPoT, which rely on external tools, EEDP operates\\nindependently. When assessing computational cost,\\nwe consider API calls and token generation. Since\\nEEDP uses a single-step prompting approach, only\\none API call is needed per query, making its com-\\nputational cost comparable to methods like CoT.\\nFor inference with open-source models, we used\\nhardware with an A40 40GB GPU. Processing one\\ndataset per model using the vLLM library took\\napproximately 10 hours.\\n4 Where do LLMs fail?\\nThrough manual inspection, we rigorously evaluate\\nthe EEDP responses against the meta-annotations\\nfrom section 2 as ground-truth benchmarks for ex-\\ntraction and model reasoning accuracy. The rea-\\nsoning programs represent sequences of arithmetic\\noperations necessary to derive the final answer, uti-\\nlizing values extracted from supporting evidence as\\noperands. To assess calculation accuracy, we manu-\\nally identify the model’s instantiation and precision\\nerrors. Our EEDP prompt ensures that the model\\npredominantly outputs responses in the expected\\nformat, with exceptions being rare. However, since\\nwe manually analyze all outputs, we do not penal-\\nize the model for format deviations but rather for\\nincorrect outputs. Penalties are applied only when\\nthe model makes errors in extraction, reasoning,\\nand/or calculation. Below, we categorize the EEDP\\nresponse errors in detail based on their origins:\\nDataset Error Type Per.(%)\\nFinQA\\nExtraction E1 10.38\\nE2 25\\nReasoning R1 25\\nR2 15.57\\nCalculation C1/C2 24.06\\nConvFinQA\\nExtraction E1 8.45\\nE2 14.08\\nReasoning R1 19.72\\nR2 36.62\\nCalculation C1/C2 21.13\\nTATQA\\nExtraction E1 13.79\\nE2 31.03\\nReasoning R1 22.41\\nR2 5.17\\nCalculation C1/C2 27.59\\nMultihiertt\\nExtraction E1 20.5\\nE2 31.5\\nReasoning R1 15.5\\nR2 12\\nCalculation C1/C2 20.5\\nTable 3: Error Analysis on Various Datasets. In this table,\\nExtraction.E1: Missing Evidences, Extraction.E2: Wrong\\nEvidences, Reasoning.R1: Insufficient Domain Knowledge,\\nReasoning.R2: Question Misinterpretation, Calculation: In-\\nstantiation (C1) and Precision errors (C2)\\n1. Incorrect Extraction: This category encom-\\npasses errors where the model faces difficulties'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 5}, page_content='in accurately identifying and extracting the perti-\\nnent information necessary for effective problem-\\nsolving. These errors point to challenges in retriev-\\ning precise information. These errors can further\\nbe subdivided into two categories\\n• Missing/Incomplete Evidences (E1): The\\nmodel fails to extract all the necessary evi-\\ndences which serve as ingredients to derive\\nthe final answer.\\n• Wrong Evidences (E2): The model extracts\\nwrong values for variables as supporting evi-\\ndences from the premise.\\n2. Incorrect Reasoning: Errors in reasoning oc-\\ncur when the model struggles to formulate an appro-\\npriate and contextually relevant approach to tackle\\na given problem. Possible reasons include a lack of\\ndomain knowledge or an inaccurate interpretation\\nof the posed question. Consequently, this error type\\ncan arise from two sources.\\n• Deficit in Domain Knowledge (R1): These\\nerrors occur when the model attempts to de-\\nrive an answer to the posed question using a\\nwrong formula for domain-specific measures,\\nfor eg. COGS, ROI etc.\\n• Question Misinterpretation (R2): These\\nerrors occur when the model interprets the\\nquestion differently and provides responses\\nthat are not aligned with the intended query.\\nOverall, the model’s outputs lack grounding\\nin the original question posed to it.\\n3. Incorrect Calculation: This variety of errors\\ninclude those where the model commits mistakes\\ndue to calculation mistakes. This can be of two\\ntypes as described below.\\n• Incorrect Instantiation (C1): These include\\ncases if the model extracts the right evidences,\\nuses the right derivation formula but instanti-\\nates the variables incorrectly with the values\\nresulting in an incorrect answer.\\n• Precision Error (C2): Language models em-\\nploy mathematical algorithms for arithmetic\\noperations, but their results may not always\\nbe perfectly accurate due to insufficient data\\npattern coverage or introduced biases during\\ntraining. Consequently, they can sometimes\\ngenerate outputs with slight inaccuracies or\\ndeviations from correct results. We show a\\ndetailed analysis in A.1.\\nAnalysis: The above categorization provides a\\nnuanced understanding of the diverse challenges\\nand shortcomings exhibited in different facets of\\nmathematical reasoning. We observe that in a lot of\\ncases, the error propagates because of a deficiency\\nin domain knowledge. It is critical for both evi-\\ndence extraction and reasoning. Despite possessing\\ngeneral domain knowledge owing to the massive\\namount of data these models have been pre-trained\\nupon, these models may require explicit prompts\\nto elicit the specific domain knowledge needed for\\na particular question. Furthermore, errors can arise\\ndue to the models’ limited proficiency in multi-step\\nreasoning, especially in tackling questions involv-\\ning multiple arithmetic operations in a sequence.\\nWe give a quantitative measure of each type of\\nerrors for each of the 4 datasets we consider for\\nour study in Table 3. We also provide examples\\ncorresponding to each error category in figures 12,\\n13, 14, 15, 16 and 17. Statistically, we find that\\nreasoning errors contribute a significant chunk to\\nthe total number of errors. In case of complex hier-\\narchical tables like that in Multihiertt, the model is\\nfound to struggle with extracting the right support-\\ning evidences from the premise for a given question.\\nCalculation errors can be taken care of if a third-\\nparty calculation tool (an external agent) is chained\\nto the language model.\\n5 Analysis on Reasoning Annotations\\nWe analyse model performance on the basis of fine-\\ngrained annotations as described in the section 4.\\n1. Performance vs Number of Reasoning Steps.\\nWe investigate model performance with increasing\\nmathematical reasoning steps, as shown in Figure 2.\\nThis analysis provides insights into models’ ability\\nto handle varying task complexities. As expected,\\nperformance decreases with more reasoning steps,\\nindicating LLMs’ challenges in retrieving informa-\\ntion and reasoning as complexity grows.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 5}, page_content='to handle varying task complexities. As expected,\\nperformance decreases with more reasoning steps,\\nindicating LLMs’ challenges in retrieving informa-\\ntion and reasoning as complexity grows.\\nAnomalies are observed in ConvFinQA, where\\naccuracy improves after greater than or equal to\\ntwo reasoning steps, potentially due to questions\\nreferring to answers of prior conversation turns.\\nAnomalies like these warrant further investigation\\nbeyond this study’s scope.\\n2. Performance across Question Types. We\\nanalyze the performance trends across different\\nquestion categories, as defined in Table 1, to assess\\nthe models’ understanding of various mathematical'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 6}, page_content='1 2 3 >=4\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1 2 3 >=40.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n1 2 3 >=4\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n1 2 3 >=4\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\nGPT-3.5-Turbo+EEDP PaLM-2-540B+EEDPGPT-4+PoT GPT-3.5-Turbo+PoT GPT-4+EEDP\\nPaLM-2-540B+PoT\\nNumber of Steps Number of Steps\\nAccuracyAccuracy\\nTATQA FinQA\\nConvFinQA Multihiertt\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of reasoning\\nsteps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex reasoning.\\nand financial concepts. Figure 3 shows that EEDP\\nconsistently performs better than or as well as PoT\\nacross all datasets. The improvement is particu-\\nlarly pronounced for PaLM-2-540B in all question\\ncategories.\\n3. Performance across Arithmetic Operations.\\nFigure 5 in Appendix A.1 shows that for relatively\\nsimpler arithmetic operations like addition and sub-\\ntraction, the effect of order of magnitude of the\\noperands is less profound as compared to harder\\narithmetic operations such as multiplication and\\ndivision. We observe the trend in the performance\\naccuracy with the growing and diminishing orders\\nof magnitude. We also observe bigger and more\\ncapable models such as GPT-4, GPT-3.5-TURBO\\nand PaLM 2-540B perform much better on simpler\\naddition, subtraction task in comparison to multi-\\nplication, division task. For more details on refer\\nto the Appendix A.1.\\n6 Other Related Works\\n6.1 LLMs on Mathematical Reasoning\\nPre-trained Language Models (PLMs) excel in\\nNLP tasks (Devlin et al., 2019; Zhuang et al., 2021)\\nby leveraging extensive textual corpora to acquire\\nworld knowledge (Guu et al., 2020). Expanding\\nPLMs for math-related tasks has been challeng-\\ning due to their non-specific training. Recent at-\\ntempts include MWP-BERT and Minerva (Liang\\net al., 2022; Lewkowycz et al., 2022), but curating\\nhigh-quality math data remains difficult. To bridge\\nthe gap, researchers fine-tune PLMs for specific\\nmath tasks. Notable works, like Bhaskara, Self-\\nsampler, Aristo, FinQANet, TAGOP, MT2Net, and\\nothers (Mishra et al., 2022; Ni et al., 2022; Clark\\net al., 2021; Chen et al., 2021b; Zhu et al., 2021;\\nZhao et al., 2022; Cao and Xiao, 2022; Welleck\\net al., 2022), employ PLMs such as GPT-Neo and\\nRoBERTa for math problem-solving.\\n6.2 Tabular Question Answering\\nHandling diverse input formats in question answer-\\ning, including structured tables and visual data,\\nposes challenges for language models. HybridQA\\n(Chen et al., 2020b) introduces questions requir-\\ning reasoning over tables and text. MultimodalQA\\n(Talmor et al., 2021) adds visual inference. Our fo-\\ncus is on multi-hop question answering over tables\\nand text. TAPAS (Herzig et al., 2020) tackles table-'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 7}, page_content='CHANGE RA\\nTIO\\nCOUNTINGAVERAGE DIFF SUM RATIO\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nCOMP\\nARE\\nSUM PRODUCTDOMAIN INFODIVISIONDIFF RATIO CHANGE RA\\nTIO\\nAVERAGE0.2\\n0.4\\n0.6\\n0.8\\n1\\nDIVISION CHANGE RA\\nTIO\\nAVERAGE SUM RATIO DIFF0.2\\n0.4\\n0.6\\n0.8\\n1\\nAVERAGE CHANGE RA\\nTIO\\nSUM RATIO DIFF0.2\\n0.4\\n0.6\\n0.8\\n1\\nGPT-3.5-Turbo+EEDP GPT-3.5-Turbo+PoT GPT-4+EEDP GPT-4+PoT PaLM-2-540B+EEDP\\nPaLM-2-540B+PoT\\nQuestion Type Question Type\\nAccuracyAccuracy\\nTATQA FinQA\\nConvFinQA Multihiertt\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\nbased questions without logical forms, while Tapex\\n(Liu et al., 2022) empowers generative models with\\ntable reasoning.\\nModels like FinQANet, TagOP, and MT2Net\\n(Chen et al., 2021b; Zhu et al., 2021; Zhao et al.,\\n2022) employ a retriever module to extract sup-\\nporting facts from input financial reports, followed\\nby a reasoning module to derive the final answer.\\nRetrieving relevant evidence and conducting rea-\\nsoning both demand domain-specific knowledge,\\nsuch as understanding financial transactions, iden-\\ntifying revenue trends, and interpreting complex\\ninvestment statements. Thus, reliance on an exter-\\nnal knowledge base becomes crucial for addressing\\nthe challenges of domain-specific multi-hop ques-\\ntion answering.\\n6.3 Prompt Engineering\\nIn-context Learning (ICL) equips Language Mod-\\nels (LLMs) with task examples and queries, en-\\nabling them to perform target tasks without updat-\\ning model parameters (Brown et al., 2020; OpenAI,\\n2023). They excel in mathematical reasoning with\\nfew-shot prompts but struggle with more complex\\ntasks. Methods like chain-of-thoughts (CoT) (Wei\\net al., 2022) have improved LLM performance by\\nguiding them through intermediate reasoning steps.\\nEnhancing multi-step reasoning involves two main\\napproaches: improving in-context examples and\\nobtaining better reasoning steps. Some focus on\\nstable in-context example selection (Fu et al., 2023;\\nRubin et al., 2022; Lu et al., 2023). Others adopt a\\nmodular approach, using off-the-shelf tools (Schick\\net al., 2023), program of thoughts (PoT) (Chen\\net al., 2022a), or decomposition strategies (Zhou\\net al., 2023; Dua et al., 2022; Khot et al., 2023).\\nOur task requires complex multi-step reason-\\ning across diverse information sources. LLMs, as\\ndemonstrated by (Chen, 2023), can reason over\\nstructured tables without explicit encoding. They\\nalso serve as versatile decomposers, breaking down\\nextensive evidence and complex questions (Ye\\net al., 2023).'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 8}, page_content='7 Key Takeaways\\nOur Contributions. Our study aimed to delve\\ninto the mathematical reasoning abilities of LLMs\\nwithin the context of financial documents where\\nmodels are tasked with complex hybrid (table-text)\\nquestion answering. This presents a significant\\nchallenge, requiring models not only to provide ac-\\ncurate numerical analysis but also to retrieve right\\nsupporting evidence tailored to specific question\\nrequirement. Moreover, it necessitates the extrac-\\ntion of necessary knowledge from the model’s pre-\\ntrained parameters to address queries.\\nFirstly, we meticulously annotate popular finan-\\ncial datasets, such as FinQA, ConvFinQA, TATQA,\\nand Multihiertt, with detailed meta-information.\\nThis includes specifying mathematical operations,\\ntypes of reasoning involved, table dimensions,\\nquestion types, and the depth of table hierarchy.\\nFurthermore, we conduct a manual error analy-\\nsis to quantify error types across multiple LLMs.\\nThese detailed annotations are invaluable for an-\\nalyzing various dimensions where LLM models\\nencounter challenges. This, in turn, aids in the de-\\nvelopment of better prompting techniques such as\\nEEDP, aimed at enhancing LLMs’ mathematical\\nreasoning abilities. The resulting improvement in\\nperformance with EEDP across multiples datasets\\nserves as compelling evidence of the effectiveness\\nof this approach.\\nWhat did we learn? Our analysis revealed that\\nLLMs can accurately handle addition and subtrac-\\ntion tasks e.g. modle perform fairly when calcu-\\nlating total expenses or profits, but struggle with\\nmultiplication and division e.g. model performs\\npoorly with questions requiring reasoning oper-\\nations involving proportions, ratios, percentages,\\nand division. Moreover, as the complexity of the\\ndata increases either through a higher absolute or-\\nder scale or more decimal numbers, model per-\\nformance degrades. Model performance also de-\\ngrades with increasing number of reasoning steps\\nand lengthy complex hierarchical table structures.\\ne.g. in complex datasets with hierarchical struc-\\ntures such as Multiheirtt, TATQA, incorrect extrac-\\ntion leads to modeling errors. Similarly, on queries\\ninvolving multiple conversational turns, such as\\nthose in ConvFinQA, model perform poorly due\\nto reasoning failures, like misinterpreting multiple\\nqueries longer context. Across all models, incor-\\nrect reasoning and incorrect extraction consistently\\nemerge as common sources of errors. For smaller\\nmodels, even straightforward calculations, result in\\nerrors due to imprecise calculations.\\nEEDP vs other methods\\n(a.) EEDP vs PoT: PoT enhances LLM infer-\\nence with the use of variable names for the support-\\ning values extracted from the premise and prompts\\nthe LLM to express their thought process in the\\nform of programs. The model output is a program\\nwhich is executed externally to derive the final an-\\nswer. EEDP proposes to decompose a complex\\nreasoning task into simple atomic steps whose so-\\nlutions can be composed to give the final answer.\\nIn PoT, they don’t make the language model do the\\ncomputation while in our case the language model\\nnot only outputs the reason but also computes the\\nfinal answer. This distinction implies that PoT may\\nhave an inherent advantage over EEDP.\\n(b.) EEDP vs Decomposers: The prompting\\nstrategy proposed by (Ye et al., 2023) was orig-\\ninally designed for querying SQL tables, they\\nuse LLMs to break down evidence and ques-\\ntions for SQL interpreters. In contrast, our ap-\\nproach addresses more complex scenarios involv-\\ning both tables and text, requiring advanced reason-\\ning skills beyond the capability of standard SQL\\ninterpreters. Pruning a non-SQL table using this\\nmethod can lead to significant information loss\\nfrom the premise which can be a potential ingredi-\\nent required to derive the final answer. Addition-\\nally, this is an expensive method as it requires 3X\\nAPI calls as opposed to other prompting methods.\\nMoreover, EEDP is a unified prompting strategy\\nwhich integrates multiple solver elements into a'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 8}, page_content='ally, this is an expensive method as it requires 3X\\nAPI calls as opposed to other prompting methods.\\nMoreover, EEDP is a unified prompting strategy\\nwhich integrates multiple solver elements into a\\nsingle unified prompt for elicitation, extraction, de-\\ncomposition and prediction.\\n8 Conclusion\\nIn conclusion, our study delved into LLMs’ mathe-\\nmatical reasoning in complex financial scenarios,\\nassessing their adaptability to mixed structured ta-\\nbles and unstructured text. Through rigorous ex-\\nperimentation, we uncovered insights into their\\nperformance and limitations, presenting a tailored\\nprompting technique that outperformed other base-\\nline methods. Our findings advance understanding\\nof LLMs’ abilities in tackling intricate mathemat-\\nical tasks within semi-structured documents, sug-\\ngesting directions for future research. Please refer\\nto appendix section A.3 for future work details.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 9}, page_content='Limitations\\nThe scope of this work is limited by the following\\nchallenges:\\nDataset Scarcity. There are not many datasets\\ndealing with numerical reasoning over semi-\\nstructured data apart from the ones from financial\\ndomain. As a future work, it would be interesting\\nto similar analysis across various domains such as\\ne-commerce, healthcare, sports and scientific tables\\nfrom research papers, uncovering new challenges\\nand insights. This expansion will enhance the appli-\\ncability and impact of our research within the NLP\\ncommunity. However, creating tailored datasets for\\nthese domains presents a significant challenge.\\nFor now to ensure a comprehensive evaluation\\nof LLMs, we have integrated financial datasets that\\noffer diverse challenges. For instance, Multihiertt\\nevaluates model performance with intricate premise\\nstructures, providing insights into handling com-\\nplex data hierarchies. ConvFinQA delves into the\\nintricate chains of numerical reasoning within con-\\nversational question answering contexts, offering a\\nunique perspective on dynamic data interpretation.\\nMoreover, FinQA and TAT-QA encompass a wide\\narray of reasoning types, with a significant por-\\ntion requiring domain-specific knowledge, thereby\\nbroadening the evaluation spectrum.\\nFactors Isolation. It is essential to acknowledge\\nthat there may be multiple factors influencing the\\nperformance of large language models while deal-\\ning with numerical reasoning over semi-structured\\ndata. In our analysis, we have focused on specific\\nfactors and trends, but it is important to recognize\\nthat the overall performance is affected by a mul-\\ntitude of variables. Marginalizing i.e. observing\\nthe trend along one while keeping the rest as con-\\nstants or isolating a single factor is challenging and\\ncannot be done with real-world data. Additionally,\\nfuture investigations may benefit from simulating\\ncontrolled scenarios on synthetic and counterfac-\\ntual datasets to gain deeper insights into the impact\\nof individual factors on model performance.\\nModeling Improvement. We emphasize our\\nanalysis on prominent models such as GPT-4,\\nGPT-3.5-TURBO, and PaLM 2-540B due to their\\nsubstantial size and capabilities. Notably, other\\nopen-sourced large language models like LLaMA\\n2-13B, MAmmoTH-13B and Mistral-7B-Instruct\\ndid not exhibit satisfactory performance in numeri-\\ncal reasoning over semi-structured data. For more\\ndetail about the the model choices refer to Ap-\\npendix A.2. This accentuates the need for explor-\\ning computationally feasible and cheaper models\\nthat can deliver remarkable performance in tasks\\ninvolving numerical reasoning over heterogeneous\\nsources of information. Future experiments with\\nample computational resources may involve explor-\\ning larger open-source models like OLMo, Mixtral,\\nand DBRX, which have been recently released.\\nEthics Statement\\nWe, the authors of this work, affirm that our work\\ncomplies with the highest ethical standards in re-\\nsearch and publication. In conducting this research,\\nwe have considered and addressed various ethi-\\ncal considerations to ensure the responsible and\\nfair use of computational linguistics methodologies.\\nWe provide detailed information to facilitate the re-\\nproducibility of our results. This includes sharing\\ncode, datasets (in our case, we deal with publicly\\navailable datasets and comply to the ethical stan-\\ndards mentioned by the authors of the respective\\nworks.), and other relevant resources to enable the\\nresearch community to validate and build upon our\\nwork. The claims in the paper match the experi-\\nmentation results, however, with black-box large\\nlanguage models, a certain degree of stochastic-\\nity is expected which we attempt to minimize by\\nkeeping a fixed temperature. We describe in the\\nfullest details the annotations, dataset splits, mod-\\nels used and prompting methods tried, ensuring\\nreproducibility of our work.\\nAcknowledgements\\nResearch was sponsored by the Army Research\\nOffice and was accomplished under Grant Number'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 9}, page_content='els used and prompting methods tried, ensuring\\nreproducibility of our work.\\nAcknowledgements\\nResearch was sponsored by the Army Research\\nOffice and was accomplished under Grant Number\\nW911NF-20-1-0080. The views and conclusions\\ncontained in this document are those of the au-\\nthors and should not be interpreted as representing\\nthe official policies, either expressed or implied,\\nof the Army Research Office or the U.S. Gov-\\nernment. The U.S. Government is authorized to\\nreproduce and distribute reprints for Government\\npurposes notwithstanding any copyright notation\\nherein. This work was partially funded by ONR\\nContract N00014-19-1-2620. Lastly, we extend\\nour appreciation to the reviewing team for their\\ninsightful comments.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 10}, page_content='References\\nRami Aly, Zhijiang Guo, Michael Sejr Schlichtkrull,\\nJames Thorne, Andreas Vlachos, Christos\\nChristodoulopoulos, Oana Cocarascu, and Arpit\\nMittal. 2021. The fact extraction and VERification\\nover unstructured and structured information\\n(FEVEROUS) shared task. In Proceedings of the\\nFourth Workshop on Fact Extraction and VERifica-\\ntion (FEVER) , pages 1–13, Dominican Republic.\\nAssociation for Computational Linguistics.\\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik\\nKoncel-Kedziorski, Yejin Choi, and Hannaneh Ha-\\njishirzi. 2019. MathQA: Towards interpretable math\\nword problem solving with operation-based for-\\nmalisms. In Proceedings of the 2019 Conference\\nof the North American Chapter of the Association for\\nComputational Linguistics: Human Language Tech-\\nnologies, Volume 1 (Long and Short Papers), pages\\n2357–2367, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\\nGretchen Krueger, Tom Henighan, Rewon Child,\\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\\nClark, Christopher Berner, Sam McCandlish, Alec\\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\\nLanguage models are few-shot learners. In Ad-\\nvances in Neural Information Processing Systems ,\\nvolume 33, pages 1877–1901. Curran Associates,\\nInc.\\nJie Cao and Jing Xiao. 2022. An augmented benchmark\\ndataset for geometric question answering through\\ndual parallel text encoding. In Proceedings of the\\n29th International Conference on Computational Lin-\\nguistics, pages 1511–1520, Gyeongju, Republic of\\nKorea. International Committee on Computational\\nLinguistics.\\nWenhu Chen. 2023. Large language models are few(1)-\\nshot table reasoners. In Findings of the Associa-\\ntion for Computational Linguistics: EACL 2023 ,\\npages 1120–1130, Dubrovnik, Croatia. Association\\nfor Computational Linguistics.\\nWenhu Chen, Xueguang Ma, Xinyi Wang, and\\nWilliam W. Cohen. 2022a. Program of thoughts\\nprompting: Disentangling computation from reason-\\ning for numerical reasoning tasks. arXiv preprint\\narXiv:2211.12588.\\nWenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai\\nZhang, Hong Wang, Shiyang Li, Xiyou Zhou, and\\nWilliam Yang Wang. 2020a. Tabfact : A large-scale\\ndataset for table-based fact verification. In Inter-\\nnational Conference on Learning Representations\\n(ICLR), Addis Ababa, Ethiopia.\\nWenhu Chen, Ming wei Chang, Eva Schlinger, William\\nWang, and William Cohen. 2021a. Open question\\nanswering over tables and text. Proceedings of ICLR\\n2021.\\nWenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong,\\nHong Wang, and William Yang Wang. 2020b. Hy-\\nbridQA: A dataset of multi-hop question answering\\nover tabular and textual data. In Findings of the Asso-\\nciation for Computational Linguistics: EMNLP 2020,\\npages 1026–1036, Online. Association for Computa-\\ntional Linguistics.\\nZhiyu Chen, Wenhu Chen, Charese Smiley, Sameena\\nShah, Iana Borova, Dylan Langdon, Reema Moussa,\\nMatt Beane, Ting-Hao Huang, Bryan Routledge, and\\nWilliam Yang Wang. 2021b. FinQA: A dataset of nu-\\nmerical reasoning over financial data. In Proceedings\\nof the 2021 Conference on Empirical Methods in Nat-\\nural Language Processing, pages 3697–3711, Online\\nand Punta Cana, Dominican Republic. Association\\nfor Computational Linguistics.\\nZhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang\\nMa, Sameena Shah, and William Yang Wang. 2022b.\\nConvFinQA: Exploring the chain of numerical rea-\\nsoning in conversational finance question answering.\\nIn Proceedings of the 2022 Conference on Empiri-\\ncal Methods in Natural Language Processing, pages\\n6279–6292, Abu Dhabi, United Arab Emirates. As-\\nsociation for Computational Linguistics.\\nPeter Clark, Oren Etzioni, Daniel Khashabi, Tushar\\nKhot, Bhavana Dalvi Mishra, Kyle Richardson,\\nAshish Sabharwal, Carissa Schoenick, Oyvind'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 10}, page_content='sociation for Computational Linguistics.\\nPeter Clark, Oren Etzioni, Daniel Khashabi, Tushar\\nKhot, Bhavana Dalvi Mishra, Kyle Richardson,\\nAshish Sabharwal, Carissa Schoenick, Oyvind\\nTafjord, Niket Tandon, Sumithra Bhakthavatsalam,\\nDirk Groeneveld, Michal Guerquin, and Michael\\nSchmitz. 2021. From ’f’ to ’a’ on the n.y. regents\\nscience exams: An overview of the aristo project.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian,\\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro\\nNakano, Christopher Hesse, and John Schulman.\\n2021. Training verifiers to solve math word prob-\\nlems. arXiv preprint arXiv:2110.14168.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\\nKristina Toutanova. 2019. BERT: Pre-training of\\ndeep bidirectional transformers for language under-\\nstanding. In Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association for\\nComputational Linguistics: Human Language Tech-\\nnologies, Volume 1 (Long and Short Papers), pages\\n4171–4186, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\nDheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt\\nGardner. 2022. Successive prompting for decom-\\nposing complex questions. In Proceedings of the\\n2022 Conference on Empirical Methods in Natu-\\nral Language Processing , pages 1251–1265, Abu\\nDhabi, United Arab Emirates. Association for Com-\\nputational Linguistics.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 11}, page_content='Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and\\nTushar Khot. 2023. Complexity-based prompting for\\nmulti-step reasoning.\\nVivek Gupta, Maitrey Mehta, Pegah Nokhiz, and Vivek\\nSrikumar. 2020. INFOTABS: Inference on tables\\nas semi-structured data. In Proceedings of the 58th\\nAnnual Meeting of the Association for Computational\\nLinguistics, pages 2309–2324, Online. Association\\nfor Computational Linguistics.\\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\\npat, and Ming-Wei Chang. 2020. Realm: Retrieval-\\naugmented language model pre-training. In Proceed-\\nings of the 37th International Conference on Machine\\nLearning, ICML’20. JMLR.org.\\nJonathan Herzig, Pawel Krzysztof Nowak, Thomas\\nMüller, Francesco Piccinno, and Julian Eisenschlos.\\n2020. TaPas: Weakly supervised table parsing via\\npre-training. In Proceedings of the 58th Annual Meet-\\ning of the Association for Computational Linguistics,\\npages 4320–4333, Online. Association for Computa-\\ntional Linguistics.\\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao\\nFu, Kyle Richardson, Peter Clark, and Ashish Sab-\\nharwal. 2023. Decomposed prompting: A modular\\napproach for solving complex tasks. In The Eleventh\\nInternational Conference on Learning Representa-\\ntions.\\nAitor Lewkowycz, Anders Andreassen, David Dohan,\\nEthan Dyer, Henryk Michalewski, Vinay Ramasesh,\\nAmbrose Slone, Cem Anil, Imanol Schlag, Theo\\nGutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy\\nGur-Ari, and Vedant Misra. 2022. Solving quantita-\\ntive reasoning problems with language models. In\\nAdvances in Neural Information Processing Systems,\\nvolume 35, pages 3843–3857. Curran Associates,\\nInc.\\nChenying Li, Wenbo Ye, and Yilun Zhao. 2022. Fin-\\nMath: Injecting a tree-structured solver for question\\nanswering over financial reports. In Proceedings of\\nthe Thirteenth Language Resources and Evaluation\\nConference, pages 6147–6152, Marseille, France. Eu-\\nropean Language Resources Association.\\nZhenwen Liang, Jipeng Zhang, Lei Wang, Wei Qin,\\nYunshi Lan, Jie Shao, and Xiangliang Zhang. 2022.\\nMWP-BERT: Numeracy-augmented pre-training for\\nmath word problem solving. In Findings of the Asso-\\nciation for Computational Linguistics: NAACL 2022,\\npages 997–1009, Seattle, United States. Association\\nfor Computational Linguistics.\\nQian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi\\nLin, Weizhu Chen, and Jian-Guang Lou. 2022.\\nTAPEX: Table pre-training via learning a neural SQL\\nexecutor. In International Conference on Learning\\nRepresentations.\\nPan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu,\\nSong-Chun Zhu, Tanmay Rajpurohit, Peter Clark,\\nand Ashwin Kalyan. 2023. Dynamic prompt learning\\nvia policy gradient for semi-structured mathematical\\nreasoning. In International Conference on Learning\\nRepresentations (ICLR).\\nSwaroop Mishra, Matthew Finlayson, Pan Lu, Leonard\\nTang, Sean Welleck, Chitta Baral, Tanmay Rajpuro-\\nhit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark,\\nand Ashwin Kalyan. 2022. LILA: A unified bench-\\nmark for mathematical reasoning. In Proceedings of\\nthe 2022 Conference on Empirical Methods in Nat-\\nural Language Processing, pages 5807–5832, Abu\\nDhabi, United Arab Emirates. Association for Com-\\nputational Linguistics.\\nAnsong Ni, Jeevana Priya Inala, Chenglong Wang, Alex\\nPolozov, Christopher Meek, Dragomir Radev, and\\nJianfeng Gao. 2022. Learning math reasoning from\\nself-sampled correct and partially-correct solutions.\\nIn The Eleventh International Conference on Learn-\\ning Representations.\\nOpenAI. 2023. Gpt-4 technical report.\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal.\\n2021. Are NLP models really able to solve simple\\nmath word problems? In Proceedings of the 2021\\nConference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human\\nLanguage Technologies, pages 2080–2094, Online.\\nAssociation for Computational Linguistics.\\nOhad Rubin, Jonathan Herzig, and Jonathan Berant.\\n2022. Learning to retrieve prompts for in-context\\nlearning. In Proceedings of the 2022 Conference of\\nthe North American Chapter of the Association for'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 11}, page_content='2022. Learning to retrieve prompts for in-context\\nlearning. In Proceedings of the 2022 Conference of\\nthe North American Chapter of the Association for\\nComputational Linguistics: Human Language Tech-\\nnologies, pages 2655–2671, Seattle, United States.\\nAssociation for Computational Linguistics.\\nTimo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta\\nRaileanu, Maria Lomeli, Luke Zettlemoyer, Nicola\\nCancedda, and Thomas Scialom. 2023. Toolformer:\\nLanguage models can teach themselves to use tools.\\narXiv preprint arXiv:2302.04761.\\nAlon Talmor, Ori Yoran, Amnon Catav, Dan Lahav,\\nYizhong Wang, Akari Asai, Gabriel Ilharco, Han-\\nnaneh Hajishirzi, and Jonathan Berant. 2021. Mul-\\ntimodalqa: Complex question answering over text,\\ntables and images.\\nShyam Upadhyay and Ming-Wei Chang. 2017. An-\\nnotating derivations: A new evaluation strategy and\\ndataset for algebra word problems. In Proceedings\\nof the 15th Conference of the European Chapter of\\nthe Association for Computational Linguistics: Vol-\\nume 1, Long Papers, pages 494–504, Valencia, Spain.\\nAssociation for Computational Linguistics.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\\nBosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,\\nand Denny Zhou. 2022. Chain-of-thought prompt-\\ning elicits reasoning in large language models. In\\nAdvances in Neural Information Processing Systems,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 12}, page_content='volume 35, pages 24824–24837. Curran Associates,\\nInc.\\nSean Welleck, Jiacheng Liu, Ximing Lu, Hannaneh\\nHajishirzi, and Yejin Choi. 2022. Naturalprover:\\nGrounded mathematical proof generation with lan-\\nguage models. In Advances in Neural Information\\nProcessing Systems.\\nYunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei\\nHuang, and Yongbin Li. 2023. Large language mod-\\nels are versatile decomposers: Decomposing evi-\\ndence and questions for table-based reasoning. In\\nProceedings of the 46th International ACM SIGIR\\nConference on Research and Development in Infor-\\nmation Retrieval, SIGIR ’23, page 174–184, New\\nYork, NY , USA. Association for Computing Machin-\\nery.\\nXiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wen-\\nhao Huang, Huan Sun, Yu Su, and Wenhu Chen.\\n2024. MAmmoTH: Building math generalist models\\nthrough hybrid instruction tuning. In The Twelfth In-\\nternational Conference on Learning Representations.\\nYilun Zhao, Yunxiang Li, Chenying Li, and Rui Zhang.\\n2022. MultiHiertt: Numerical reasoning over multi\\nhierarchical tabular and textual data. In Proceedings\\nof the 60th Annual Meeting of the Association for\\nComputational Linguistics (Volume 1: Long Papers),\\npages 6588–6600, Dublin, Ireland. Association for\\nComputational Linguistics.\\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei,\\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\\nClaire Cui, Olivier Bousquet, Quoc Le, and Ed Chi.\\n2023. Least-to-most prompting enables complex rea-\\nsoning in large language models.\\nFengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao\\nWang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-\\nSeng Chua. 2021. TAT-QA: A question answering\\nbenchmark on a hybrid of tabular and textual con-\\ntent in finance. In Proceedings of the 59th Annual\\nMeeting of the Association for Computational Lin-\\nguistics and the 11th International Joint Conference\\non Natural Language Processing (Volume 1: Long\\nPapers), pages 3277–3287, Online. Association for\\nComputational Linguistics.\\nLiu Zhuang, Lin Wayne, Shi Ya, and Zhao Jun. 2021. A\\nrobustly optimized BERT pre-training approach with\\npost-training. In Proceedings of the 20th Chinese\\nNational Conference on Computational Linguistics,\\npages 1218–1227, Huhhot, China. Chinese Informa-\\ntion Processing Society of China.\\nA Appendix\\nA.1 How proficient are LLMs in performing\\nsimple arithmetic operations?\\nTo assess the effectiveness of Large Language Mod-\\nels in handling fundamental arithmetic tasks (ad-\\ndition (+), subtraction (-), multiplication (*), and\\ndivision (/)) across operands of varying magnitudes,\\nwe generate a set of 2600 synthetic arithmetic ex-\\npressions using GPT-4. This set includes 650 prob-\\nlems for each arithmetic operation. Within each\\noperation category, we categorize tasks into groups\\nbased on a parameter denoted as τ:\\nτ = OOM( arg max\\nop\\n∥OOM(op)∥ )\\nwhere, arg maxselects the operand op with the\\ngreater absolute value of the order of magnitude,\\nand OOM represents the order of magnitude.\\nThis approach is motivated by cognitive chal-\\nlenges commonly faced by humans, as they often\\nencounter difficulties with both high and low or-\\nders of magnitude. Essentially, captures the order\\nof magnitude of the operand with the larger ab-\\nsolute value among the two. For each arithmetic\\noperation, we establish groups withτ, ranging from\\n-6 to 6. Within each group, there are 50 arithmetic\\nexpressions. This systematic grouping provides a\\ncomprehensive assessment across various difficulty\\nlevels based on operand magnitudes.\\nAnalysis. Figure 5 illustrates that for simpler\\narithmetic operations like addition and subtrac-\\ntion, the impact of the order of magnitude of the\\noperands is less significant compared to harder op-\\nerations like multiplication and division. We ob-\\nserve a trend in performance accuracy with increas-\\ning and decreasing orders of magnitude. Larger\\nmodels such as GPT-4, GPT-3.5-TURBO, and PaLM\\n2-540B perform significantly better on addition and\\nsubtraction tasks as compared to the multiplication\\nand division tasks.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 12}, page_content='models such as GPT-4, GPT-3.5-TURBO, and PaLM\\n2-540B perform significantly better on addition and\\nsubtraction tasks as compared to the multiplication\\nand division tasks.\\nA.2 Model Selection Criteria\\nOur model selection process was guided primarily\\nby resource constraints and the timeframe of our\\nresearch endeavor. We aimed to identify models\\nthat represented the state-of-the-art (SOTA), such\\nas GPT-4, or those with a specific focus on mathe-\\nmatical reasoning, such as MAmmoTH, aligning with\\nthe parameters of our project. Here’s a breakdown:\\n1. Resource and Budget Constraints: Given\\nour limited computing resources and budget,\\nwe meticulously selected models that could\\nprovide valuable insights within the confines\\nof our project. Incorporating additional mod-\\nels would have been impractical given our\\nresource limitations.\\nThe number of shots, indicated by shots = k,\\nwas tailored to the context length of the model.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 13}, page_content='Figure 4: Our EEDP Approach (a.) Instructions, and (b.) Demonstration.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 14}, page_content='0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\n1.1\\n−6 −4 −2 0 2 4 60\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\n1.1\\n−6 −4 −2 0 2 4 6\\nGPT-3.5-Turbo GPT-4 MAmmoTH-13B Mistral-7B PaLM-2-540B\\nOrder of Magnitude Order of Magnitude\\nAccuracyAccuracy\\nAddition Division\\nMultiplication Subtraction\\nFigure 5: Accuracy of different arithmetic operations across different orders of magnitude.\\nFigure 6: Sample distribution of Multihiertt & FinQA datasets partitioned by number of rows in the supporting table.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 15}, page_content='(a) Hierarchical Complexity\\n (b) Empty Cells\\nFigure 7: Sample distribution of Multihiertt Dataset partitioned by (a) hierarchical complexity of the gold evidence.\\n(b) the percentage of empty cells in the supporting table.\\nSpecifically, for models with a context length\\nexceeding the input length, we standardized\\nk to 4. For instance, we allocated 2 shots\\nfor models like LLaMA and MammoTH due\\nto their constrained context length. However,\\nfor other models capable of accommodating\\nlarger contexts, we increased the number of\\nshots to 4. Additionally, we used a tempera-\\nture of 0 and topp = 1 for our experiments.\\n2. Models with Mathematical Capabilities:\\nWe prioritized models renowned for their\\nadvanced mathematical prowess, such as\\nMAmmoTH, alongside state-of-the-art Large\\nLanguage Models (LLMs) like GPT-4. Our\\ngoal was to gain deeper insights into the math-\\nematical reasoning capabilities of cutting-\\nedge models within the context of financial\\ndocuments.\\n3. Better Prompting Approaches: Rather than\\nfocusing solely on model diversity, we con-\\ncentrated on exploring a variety of prompting\\nmethods, particularly those aimed at enhanc-\\ning mathematical reasoning. We believed this\\napproach would yield more valuable insights\\ninto the performance of both LLMs and their\\nassociated prompting techniques in real-world\\nfinancial tasks.\\n4. Excluding Underperforming Models:\\nWhile we experimented with various models,\\nsuch as Falcon-7B-Instruct and MPT-7B-\\nInstruct, we found them to underperform\\nsignificantly compared to models like LLaMA\\nand Mistral. Consequently, we excluded them\\nfrom detailed analysis. Future experiments\\nwith ample computational resources may\\ninvolve exploring additional open-source\\nmodels like OLMo, Mixtral, and DBRX,\\nwhich have been recently released.\\nA.3 Other Modeling Techniques\\nBased on our research and the results obtained\\nfrom our proposed method ’EEDP’, we do have\\nseveral insights that could guide future model de-\\nvelopment:\\n1. Domain-Specific Pre-training: Our method\\n\"EEDP\" suggests that LLMs could benefit\\nfrom pre-training that focuses on extracting\\ndomain-specific knowledge. In the context of\\nfinancial documents, for instance, this could\\ninvolve training models on a corpus of finan-\\ncial texts, thereby enabling them to better un-\\nderstand and reason about financial concepts\\nand terminology.\\n2. Knowledge Elicitation: The elicitation step\\nin \"EEDP\" indicates the potential for design-\\ning LLMs that can elicit or extract relevant\\ninformation from a given context more effec-\\ntively. This could involve developing mod-\\nels that are better at identifying and focusing\\non key pieces of information in a document,\\nwhich is crucial for accurately answering ques-\\ntions about the document.\\n3. Modular Modeling: Our research introduce\\na novel approach to the reasoning process,\\nwherein it’s broken down into modular steps.\\nIn this methodology, Large Language Models'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 16}, page_content='(LLMs) handle different aspects of a task in\\ndistinct stages. This division potentially en-\\nhances the overall accuracy and efficiency of\\nthe model.\\nFor instance, the model might begin by elic-\\niting domain-specific knowledge, then pro-\\nceed to extract relevant information from the\\npremise. Following this, it engages in reason-\\ning about this information to answer a ques-\\ntion and finally derives the answer, using the\\noutput from the preceding reasoning steps as\\na reference point.\\nBy potentially training individual expert mod-\\nels to handle each specific stage, we could\\noptimize performance for each distinct task.\\nThis modular approach allows for specialized\\nprocessing of each step, thereby improving\\nthe overall performance and interpretability of\\nthe final output.\\n4. Hierarchical Structure Understanding:\\nRepresenting the input structure of the table\\nin a better format to the LLM could be benefi-\\ncial. One can also explore introducing special\\npositional encodings, similar to those used in\\nTAPAS, to serve as row and column IDs for\\neach cell. This approach would differ from\\ntraditional positional encodings, which are de-\\nsigned to capture the inherently linear struc-\\nture of textual data. TThis integration would\\nfacilitate the extraction of relvant information\\nfrom the table correctly, considering its struc-\\nture more effectively, avoiding information ex-\\ntraction errors. Another idea could be convert-\\ning the premise containing the complex table\\nand text into a common representation such\\nas a knowledge graph. Furthermore, models\\nspecifically tuned to answer to human queries\\nover complex documents in multiple conversa-\\ntional turns (like that in ConvFinQA) should\\nalso be considered, as it’s a challenge for lan-\\nguage model’s to backtrack to their decisions\\nthat were made previously in the conversation.\\nA.4 Metadata Annotations Dataset Coverage\\nFigure 6 displays the dataset distribution for Mul-\\ntihiertt and FinQA based on table length (number\\nof rows). Figure 7 (a) shows how we calculate hi-\\nerarchical complexity for examples with multiple\\nrelevant rows at various hierarchical depths. For\\nthe distribution of missing information (empty cell\\nproportions) across datasets, refer to Figure 7 (b).\\nFigure 8 for the distribution of questions by rea-\\nsoning steps. We define 12 mathematical concept\\ncategories, see Table 1) and annotate each ques-\\ntion accordingly. The dataset coverage for these\\ncategories is shown in Figure 9. Our method for\\nestimating hierarchy depth is shown in Figure 10.\\nFigure 11 shows a example for EEDP strategy with\\none shot. Figure 11 shows a example for EEDP\\nstrategy with one shot.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 17}, page_content='Figure 8: Sample distribution of examples in numerical reasoning on tabular datasets partitioned by the number of reasoning\\nsteps involved. Clockwise (from top-left) : FinQA, ConvFinQA, TATQA, Multihiertt.\\nFigure 9: Sample distribution of Numerical & Tabular Reasoning Datasets partitioned by Question Concept Category types.\\nClockwise (from top-left): FinQA, ConvFinQA, Multihiertt, TATQA.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 18}, page_content='Years Ended December 31, 2009 2008\\n(in millions, except percentages)\\nRevenues\\nManagement and financial advice fees $1,234 $1,339\\nDistribution fees $1,733 $1,912\\nNet investment income $297 $-43\\nOther revenues $85 $80\\nTotal revenues $3,349 $3,288\\nBanking and deposit interest expense $133 $178\\nTotal net revenues $3,216 $3,110\\nExpenses\\nDistribution expenses $1,968 $2,121\\nGeneral and administrative expense $1,282 $1,138\\nTotal expenses $3,250 $3,259\\nPretax loss $-34 $-149\\nQuestion: What will Distribution fees reach in 2010 if it continues to grow at its current rate? (in millions)?\\nGold Evidences:\\n• Table shows Distribution fees of Years Ended December 31, 2009 (in millions, except percentages) is\\n$1,733 .\\n• Table shows Distribution fees of Years Ended December 31, 2008 (in millions, except percentages) is\\n$1,912 .\\nHierarchical Complexity: max(4, 4) = 4\\nFigure 10: This illustration demonstrates how the \"hierarchical complexity\" is determined for each supporting piece of evidence.\\nThe hierarchical complexity corresponds to the number of levels or tiers of information structure within the table. The top\\nlevel (1) encompasses the table itself, which contains information about the results of operations in a firm’s Advice & Wealth\\nManagement segment. The second level (2) includes columns specifying the years (2009, 2008), creating a substructure within\\nthe table. The third level (3) involves the column \"(in millions, except percentages),\" and the fourth level (4) encompasses the\\nrows under categories like \"Revenues,\" \"Distribution fees,\" \"Net investment income,\" and so on. To locate specific values like\\n\"$1733\" and \"$1912\", a retriever module needs to navigate through these four levels.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 19}, page_content='Instruction: Please carefully analyze the provided information, perform necessary numerical calculations, and\\nprovide accurate answers to the given question using the provided data. Take into account the pre-text, table, and\\npost-text when formulating your response.\\nWhen performing numerical calculations, ensure you gather the required information and follow a step-by-step\\napproach.\\n1. Elicit the most relevant domain fact or knowledge that might be useful for you to extract the right operands and\\nforming the right approach to the problem.\\n2. Translate table data into sentences and identify gold evidence for answering the question.\\n3. Define a sequence of atomic operations (Add, Subtract, Divide, Multiply, Greater, Min, Max, Exp) which take\\ninto account only two operands at a time. Divide a complex task into a sequence of atomic operations defined\\nabove.\\n4. Finally, conclude as: The final answer is <answer>.\\nDemonstration: “Effective Income Tax Rate”: A reconciliation of the United States federal statutory income tax rate\\nto our effective income tax rate is as follows: In 2019 and 2018 we had pre-tax losses of $19,573 and $25,403,\\nrespectively, which are available for carry forward to offset future taxable income.\\nYear Ended Year Ended\\nDecember 31, 2018 December 31, 2019\\nUnited States federal statutory rate 21.00% 21.00%\\nEffective income tax rate 1.99% -0.01%\\nQuestion: What was the 2019 percentage change in pre-tax losses?\\nResponse #:\\nDomain Knowledge: Pre-tax losses, or operating losses, refer to financial losses that a company incurs before\\nconsidering the effects of income taxes. To find the 2019 percentage change in pre-tax losses, we need to find the\\ndifference between the new and the old value of the pre-tax losses, then divide the obtained difference by the old value\\nand multiply this value by 100.\\nGold Evidences:\\n• The pre-tax losses in 2019 are $19,573.\\n• The pre-tax losses in 2018 are $25,403.\\nSteps:\\n1. Subtract 25403 from 19573.\\n• Response 1: 19573 - 25403 = -5830\\n2. Divide #1 by 25403.\\n• Response 2: −5830\\n25403 = −0.2295\\n3. Multiply #2 by 100.\\n• Response 3: −0.2295 × 100 =−22.95\\nThe final answer is -22.95%.\\nFigure 11: A Template for our proposed prompting strategy, EEDP with 1-shot demonstration.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 20}, page_content='Regulatory capital, assets, and risk-based capital ratios for JPMorgan Chase and its significant IDI\\nsubsidiaries under Basel III Standardized Transitional and Basel III Advanced Transitional at December\\n31, 2017, and 2016.\\nBasel III Standardized Transitional Basel III Advanced Transitional\\n(in millions) Dec 31, 2017 Dec 31, 2016 Dec 31, 2017 Dec 31, 2016\\nRegulatory capital\\nCET1 capital $184,375 $179,319 $184,375 $179,319\\nTier 1 capital(a) $184,375 $179,341 $184,375 $179,341\\nTotal capital $195,839 $191,662 $189,419 $184,637\\nAssets\\nCapital ratios(c)\\nCET1 13.8% 13.7% (e) 15.0%\\nTier 1(a) 13.8% 13.7% (e) 15.0%\\nTotal 14.7% 14.6% (e) 15.4%\\nTier 1 leverage(d) 8.7% 8.6% 8.7%\\nQuestion: What is the sum of CET1 capital, Tier 1 capital, and Total capital in 2017? (in million)\\nResponse #:\\nDomain Knowledge: In banking, CET1 capital, Tier 1 capital, and Total capital are used to measure a bank’s\\nfinancial health and stability. CET1 (Common Equity Tier 1) capital consists mainly of common shares and retained\\nearnings. Tier 1 capital is the core capital mainly comprising shareholders’ equity and disclosed reserves. Total capital\\nincludes both Tier 1 capital and Tier 2 capital, which consists of hybrid capital instruments and subordinated debt.\\nGold Evidences:\\n• Table shows JPMorgan Chase Bank, N.A. Basel III Standardized Transitional CET1 capital on Dec 31, 2017 as\\n$184,375 million.\\n• Table shows JPMorgan Chase Bank, N.A. Basel III Standardized Transitional Tier 1 capital on Dec 31, 2017 as\\n$184,375 million.\\n• Table shows JPMorgan Chase Bank, N.A. Basel III Standardized Transitional Total capital on Dec 31, 2017 as\\n$195,839 million.\\nSteps:\\n1. Add CET1 capital and Tier 1 capital.\\n• Response 1: $184,375 + $184,375 = $368,750\\n2. Add #1 and Total capital.\\n• Response 2: #1 + $195,839 = $564,589\\nThe final answer is $564,589 million.\\nGround-Truth Steps: $184,375 + $184,375 + $195,839 + $184,375 + $184,375 + $189,419 = $1,122,758\\nReason: The model missed adding JPMorgan Chase Bank, N.A. Basel III Advanced Transitional CET1 capital\\n($184,375), Tier 1 ($184,375), and Total Capital ($189,419) in 2017.\\nFigure 12: Error due to missing evidences'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 21}, page_content='Year Life/Fin. Gen. Rtd. Fin. Asset Total\\nIns. Ins. Services Services Mngmt\\n2006\\nFixed Maturities:\\nBonds available for sale $67,994 $288,018 $1,357 $29,500 — $386,869\\nBonds held to maturity $21,437 — — — — $21,437\\nBond trading securities $1 $10,835 — — — $10,836\\nEquity Securities:\\nCommon stocks $4,245 $8,705 — $226 $80 $13,256\\nPreferred stocks $1,884 $650 $5 — — $2,539\\nOther Assets:\\nMortgage and other loans $17 $21,043 $2,398 $4,884 $76 $28,418\\nFlight equipment — — $39,875 — — $39,875\\nTotal Invested Assets $116,059 $428,825 $185,404 $68,280 $3,373 $801,941\\nQuestion: What is the proportion of Asset Management to the total Mortgage and other loans receivable, net of\\nallowance in 2006?\\nResponse #:\\nDomain Knowledge: Proportion refers to the relationship between two quantities, where one quantity is considered\\nin relation to the other. To find the proportion of Asset Management to the total Mortgage and other loans receivable,\\nnet of allowance in 2006, we need to divide the value of Asset Management by the total value of Mortgage and other\\nloans receivable, net of allowance in 2006.\\nGold Evidences:\\n• Table shows Asset Management of Total invested assets in 2006 is $68,280.\\n• Table shows Mortgage and other loans receivable, net of allowance (in millions) in 2006 is $28,418.\\nSteps:\\n1. Divide Asset Management by the total Mortgage and other loans receivable, net of allowance in 2006.\\n• Response 1: 68280\\n28418 = 2.4024\\nThe final answer is 2.4024.\\nGround-truth steps: 4884.0\\n28418.0 = 0.172\\nReason: Asset Management in 2006 is taken as $68,280.0 by the model instead of $4,884.0 due to error in the\\nextraction of the ground-truth.\\nFigure 13: Error due to wrong evidences'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 22}, page_content='2013 2014 2015 2016 2017\\nMasco $138.48 $155.26 $200.79 $227.08 $318.46\\nS&P 500 Index $132.04 $149.89 $151.94 $169.82 $206.49\\nS&P Industrials Index $140.18 $153.73 $149.83 $177.65 $214.55\\nS&P Consumer Durables & Apparel Index $135.84 $148.31 $147.23 $138.82 $164.39\\nQuestion: What was the difference in percentage cumulative total shareholder return on Masco common stock versus\\nthe S&P 500 Index for the five-year period ended 2017?\\nResponse #:\\nDomain Knowledge: Cumulative total shareholder return is a measure of the overall performance of a stock over a\\ngiven period of time. It includes the change in the stock’s price as well as any dividends paid to shareholders during\\nthat time.\\nGold Evidences:\\n• The cumulative total shareholder return for Masco in 2017 is $318.46.\\n• The cumulative total shareholder return for the S&P 500 Index in 2017 is $206.49.\\nSteps:\\n1. Divide the cumulative total shareholder return for Masco in 2017 (318.46) by the cumulative total shareholder\\nreturn for the S&P 500 index in 2017 (206.49)\\n• Response 1: 318.46 / 206.49 = 1.5422\\n2. Subtract 1 from the quotient obtained in #1\\n• Response 2: 1.5422 - 1 = 0.5422\\n3. Multiply the value obtained in #2 with 100 to find the percentage difference\\n• Response 3: 0.5422 * 100 = 54.22\\nThe final answer is 54.22%.\\nGround-truth steps: [((318.46 - 100.0)/100.0)*100.0 - ((206.49 - 100.0)/100.0)*100.0] = 111.97\\nReason: Wrong formula for return on investment\\nFigure 14: Example of an error caused due to insufficient domain knowledge'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 23}, page_content='Accr. Yield Carrying Amt. Allowance\\n(Beginning) (Beginning) (Beginning)\\nBeginning Balance $27 $920 $95\\nPurchases $1 $130 $0\\nDisposals/Payments Received $-11 $-594 $0\\nAccretion $-44 $44 $0\\nBuilds (Reductions) to the Allowance $0 $0 $-18\\nIncrease to Expected Cash Flows $-2 $19 $0\\nFX/Other $17 $-50 $0\\nBalance at December 31, 2010 $116 $469 $77\\nQuestion: What percentage did this total represent in relation to the carrying amount?\\nResponse #:\\nDomain Knowledge: To find the percentage of a value (A) in relation to another value (B), divide the first value (A)\\nby the second value (B) and multiply it by 100. To find the combined total, add the two values.\\nGold Evidences:\\n• The carrying amount of the company’s purchased distressed loan portfolio at December 31, 2010, was $392\\nmillion.\\n• The net allowance was $77 million as of December 31, 2010.\\nSteps:\\n1. Find the combined total of net allowance and the carrying amount.\\n• Response 1: 392 + 77 = 469\\n2. Calculate the percentage of net allowance in relation to the carrying amount.\\n• Response 2: 77\\n392 × 100 = 19.64\\n3. Calculate the percentage of the combined total in relation to the carrying amount.\\n• Response 3:\\n\\x00469\\n392\\n\\x01\\n× 100 = 119.64\\nThe final answer is 119.64%.\\nGround-truth steps: [(77/(392 + 77))*100] = 16.42%\\nReason: By the phrase in relation to the question expected a ratio of quantity1/quantity2 but the model returned\\nquantity2/quantity1\\nFigure 15: Example of an error caused due to question misinterpretation'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 24}, page_content='2001 2000\\nGain on Sales of Depreciable Properties $45428 $52067\\nGain on Land Sales $5080 $9165\\nImpairment Adjustment $-4800 (4800) $-540 (540)\\nTotal $45708 $60692\\nQuestion: What is the percent change in general and administrative expense from 2000 to 2001?\\nResponse #:\\nDomain Knowledge: To find the percent change between two values, we need to find the difference between the new\\nand old values, divide the difference by the old value, and multiply the result by 100.\\nGold Evidences:\\n• General and administrative expense decreased from $21.1 million in 2000 to $15.6 million for the year ended\\nDecember 31, 2001.\\nSteps:\\n1. Calculate the change in general and administrative expense by subtracting the 2001 value ($15.6 million) from\\nthe 2000 value ($21.1 million).\\n• Response 1: 21.1 - 15.6 = 5.5\\n2. Divide the difference obtained in Step 1 by the general and administrative expense in 2000 ($21.1 million).\\n• Response 2: 5.5\\n21.1 = 0.2607\\n3. Multiply the result obtained in Step 2 by 100 to get the percent change.\\n• Response 3: 0.2607 × 100 = 26.07\\nThe final answer is 26.07%.\\nGround-truth steps: [((15.6 - 21.1)/21.31)*100] = -26.07%\\nReason: Incorrect Instantiation of variables resulting in a value with a flipped sign\\nFigure 16: Example of an error caused due to incorrect instantiation of variables'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/eedp.pdf', 'page': 25}, page_content='2013 2014 2015 2016 2017\\nCME Group Inc. $164.01 $194.06 $208.95 $279.85 $370.32\\nS&P 500 $132.39 $150.51 $152.59 $170.84 $208.14\\nPeer Group $176.61 $187.48 $219.99 $249.31 $323.23\\nQuestion: What is the annualized return for s&p 500 from 2012 to 2017?\\nResponse #:\\nDomain Knowledge: The annualized return refers to the average rate of return over a given period for an investment,\\nwhich has been adjusted for compounding. To find the annualized return for the S&P 500 from 2012 to 2017, we need\\nto use the formula:\\nAnnualized return =\\n \\x12 Ending value\\nStarting value\\n\\x13 1\\nNumber of years\\n− 1\\n!\\nGold Evidences:\\n• Investment was $100 on December 31, 2012;Value of S&P 500 investment on December 31, 2017 is $208.14.\\nSteps:\\n1. Divide the ending value (208.14) by the starting value (100)\\n• Response 1: 208.14\\n100 = 2.0814\\n2. Calculate the number of years elapsed (2017 - 2012)\\n• Response 2: 2017 - 2012 = 5\\n3. Raise the value obtained in #1 to the power of (1/number of years)\\n• Response 3: (2.0814)\\n1\\n5 = 1.1606\\n4. Subtract 1 from the value obtained in #3\\n• Response 4: 1.1606 - 1 = 0.1606\\n5. Multiply the value obtained in #4 by 100 to get the annualized return in percentage\\n• Response 5: 0.1606 * 100 = 16.06\\nThe final answer is 16.06%.\\nGround-truth steps: [(208.14/100)(1/(2017 − 2012)) - 1] = 0.1577 * 100 = 15.77\\nReason: Inaccurate calculation\\nFigure 17: Example of an error caused due to imprecise calculations')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "rgLikVwRiw57"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from langchain.schema import Document\n",
        "\n",
        "all_page_content = \"\".join([doc.page_content for doc in documents])\n",
        "all_page_content += \"\\n\".join([doc['text'] for doc in images])\n",
        "\n",
        "math_expressions = re.findall(r\"\\$.*?\\$\", all_page_content)\n",
        "all_page_content+=\"\\n equations: \".join(math_expressions)\n",
        "documents = [Document(page_content=all_page_content)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hZPJuaAojTP",
        "outputId": "58fbe03c-4f97-41ea-835c-4ab0a79368c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='Evaluating LLMs’ Mathematical Reasoning in Financial Document\\nQuestion Answering\\nPragya Srivastava#∗, Manuj Malik ‡, Vivek Gupta §†, Tanuja Ganu #, Dan Roth §\\n#Microsoft Research, ‡Singapore Management University, §University of Pennsylvania\\n{t-pragyasri, taganu}@microsoft.com, manujm@smu.edu.sg, {gvivek,danroth}@seas.upenn.edu\\nAbstract\\nLarge Language Models (LLMs), excel in\\nnatural language understanding, but their ca-\\npability for complex mathematical reasoning\\nwith a hybrid of structured tables and unstruc-\\ntured text remain uncertain. This study ex-\\nplores LLMs’ mathematical reasoning on four\\nfinancial tabular question-answering datasets:\\nTATQA, FinQA, ConvFinQA, and Multihiertt.\\nThrough extensive experiments with various\\nmodels and prompting techniques, we assess\\nhow LLMs adapt to complex tables and math-\\nematical tasks. We focus on sensitivity to\\ntable complexity and performance variations\\nwith an increasing number of arithmetic rea-\\nsoning steps. The results provide insights\\ninto LLMs’ capabilities and limitations in han-\\ndling complex mathematical scenarios for semi-\\nstructured tables. Ultimately, we introduce a\\nnovel prompting technique EEDP tailored to\\nsemi-structured documents, matching or outper-\\nforming baselines performance while providing\\na nuanced understanding of LLMs abilities.\\n1 Introduction\\nIn the constantly evolving realm of artificial in-\\ntelligence, Large Language Models (LLMs) have\\nrisen as cutting-edge tools for natural language un-\\nderstanding. They excel in a wide array of NLP\\ntasks, including machine translation (MT), text\\nsummarization, question answering, and code gen-\\neration. One specific area where LLMs’ mathe-\\nmatical reasoning abilities come under scrutiny is\\nthe domain of numerical reasoning tasks. Past re-\\nsearch has delved into the potential of language\\nmodels for mathematical reasoning tasks, as seen\\nin studies such as in Amini et al. (2019); Upadhyay\\nand Chang (2017); Patel et al. (2021); Cobbe et al.\\n(2021). These investigations provide a means to\\nevaluate the performance of language models when\\n∗Work done during internship at Microsoft Research\\n† Primary Mentor and Corresponding Author\\nThe Goldman Sachs Group Incorporation\\nNotes to Consolidated Financial Statements\\nThe table below presents a summary of Level\\n3 financial assets.\\nFinancial Asset Dec. 2017\\nCash Instruments $15,395\\nDerivatives $3,802\\nOther Financial Instruments $4\\nQ: What was the total value of Level 3 finan-\\ncial assets for Goldman Sachs in December\\n2017?\\nA: $15,395 + $3,802 + $4 = $19,201\\nFigure 1: An example of a semi-structured financial docu-\\nment question answering.\\nit comes to solving mathematical problems, rang-\\ning from straightforward math word problems to\\nmore complex ones.\\nHowever, the problem becomes significantly\\nmore challenging when we encounter a hybrid of\\nstructured such as semi-structured tables and un-\\nstructured text, as shown in example in figure 1.\\nSuch tables are common in documents such as\\ninvoices, health records, and financial reports in\\ncorporate settings. In the financial domain, these\\ntables present numerical data in a structured for-\\nmat, including income statements, balance sheets,\\ncash flow statements, shareholder equity data, and\\nannual reports. The majority of NLP models are\\nprimarily trained to handle raw unstructured tex-\\ntual data, which limits their ability to reason over\\nsemi-structured data, such as tables, or more in-\\ntricate hybrids of tables and text, as seen in Chen\\net al. (2020b); Aly et al. (2021); Chen et al. (2020a,\\n2021a). Tables, especially these with intricate rela-\\ntionships and dependencies, often necessitate multi-\\nhop reasoning, connecting information across mul-\\ntiple steps, as shown in Gupta et al. (2020).\\nNLP models may encounter difficulties in per-\\nforming such multi-step reasoning, particularly\\nwhen dealing with complex mathematical opera-tions involving tables, as highlighted in Li et al.\\n(2022). Previous research such as Chen (2023),\\nexemplified these issues and demonstrated LLM\\ncapacity to process and reason with semi-structured\\ntables. However, these studies are somewhat con-\\nstrained and don’t explicitly explore the models’\\nmathematical reasoning abilities. This is particu-\\nlarly evident in data/tasks that involve a substantial\\nnumber of arithmetic reasoning steps, operate on\\nextreme orders of magnitude, or deal with intricate\\ntables where extracting the relevant information for\\na query becomes challenging.\\nMoreover, when handling domain-specific docu-\\nments, such as those in finance, a language model\\nmust not only have the necessary domain knowl-\\nedge to craft the right approach for task-solving but\\nalso the capability to manipulate structured data,\\nsuch as tables. Therefore, in this study, we aim\\nto fill this gap by providing both qualitative and\\nquantitative analyses of LLM’s ability to reason\\non mathematical content on four finance datasets\\ni.e. FinQA (Chen et al., 2021b), TATQA (Zhu\\net al., 2021), ConvFinQA (Chen et al., 2022b), and\\nMultihiertt (Zhao et al., 2022). These datasets fea-\\nture questions demanding intricate numerical rea-\\nsoning, combining semi-structured tables and text.\\nEach dataset provides pre-annotated executable pro-\\ngrams for precise answer retrieval. Our goal is to\\nillustrate how model performance varies as the nu-\\nmerical complexity of the underlying data and the\\nintricacy of the mathematical reasoning steps re-\\nquired to solve a query increase. Building upon\\nthese observations, we propose a novel approach\\ntermed (Elicit −→Extract −→Decompose −→\\nPredict) EEDP, designed to deconstruct model re-\\nsponses into discrete components. This innovative\\nmethod offers a deeper, more transparent insight\\ninto the numerical limitations of the model when\\ntackling these tasks. Our contributions are as fol-\\nlows:\\n1. We conduct a comprehensive robust evalu-\\nation of state-of-the-art Large Language Models\\n(LLMs) for tabular (hybrid) question answering,\\nwith a specific focus on mathematical reasoning\\ntasks, using public financial tabular datasets to es-\\ntablish a thorough performance benchmark.\\n2. Our analysis is thorough and multifaceted,\\nencompassing both qualitative and quantitative as-\\npects across several dimensions. We aim to provide\\nnuanced insights into the strengths and limitations\\nof LLMs in tabular (hybrid) question answering,\\nespecially in scenarios involving mathematical rea-\\nsoning.\\n3. Building upon qualitative analysis, we in-\\ntroduce a novel and improved prompting method\\ncalled EEDP. Our novel approach not only en-\\nhances our understanding of model weaknesses\\nbut also substantially enhances model performance\\ncompared to existing prompting methods across\\nmultiple models types.\\nOur metadata dataset and source code are avail-\\nable at https://vgupta123.github.io/eedp.\\n2 Metadata Annotations\\nWe annotated four tabular datasets: FinQA,\\nTATQA, ConvFinQA, and Multihiertt with meta\\ninformation related to a.) reasoning steps, b.) ques-\\ntion category, c.) table length, d.) hierarchical\\ncomplexity e.) missing information. 1 Below, we\\nprovide detailed information about these meta-data\\nannotations:\\n1. Number of Reasoning Steps: Including the\\ncount of arithmetic operations in questions is cru-\\ncial. More operations reflect increased complexity\\nin reasoning, and their interdependence offers in-\\nsights into the models’ proficiency. This annotation,\\napplied across all four datasets, reveals their ability\\nin handling intricate arithmetic tasks. Refer to Fig-\\nure 8 in Appendix A.4 for distribution of questions\\nbased on the number of reasoning steps involved.\\n2. Question Categorization: In numerical rea-\\nsoning, grasping the evolution from fundamental\\narithmetic to advanced operations is crucial, mark-\\ning a shift in cognitive complexity. As questions\\nadvance, they typically involve more intricate com-\\nbinations of operations and linguistic nuances. Ouring a shift in cognitive complexity. As questions\\nadvance, they typically involve more intricate com-\\nbinations of operations and linguistic nuances. Our\\nresearch identify both the capabilities and limita-\\ntions of LLMs in understanding these concepts.\\nWe establish 12 mathematical concept categories\\n(Table 1) with corresponding definitions, annotat-\\ning each question. The dataset coverage across\\nthese categories is shown in Figure 9 in Appendix\\nA.4. Notably, categories like DIVISION and RATIO\\nshare similarities but differ in focus: DIVISION\\ninvolves the division operator, while RATIO en-\\ncompasses ratios, fractions, and inverse problems.\\nCHANGE IN RATIO questions add complexity with\\nquantity changes requiring subtraction. Addition-\\nally, we omit NEED-IN-DOMAIN-INFO due\\n1One author annotated the data, and the other checked for\\naccuracy; we took stringent measures to minimize errors.Concepts Definition\\nSUM Questions that require only the knowledge\\nof addition.\\nDIFFERENCE Questions that require only the knowledge\\nof subtraction.\\nPRODUCT Questions that require only the knowledge\\nof multiplication.\\nDIVISION Questions that require only the knowledge\\nof division.\\nRATIO Questions that require knowing fractional\\nforms, e.g., percentages, ratios.\\nCHANGE\\nRATIO\\nQuestions involving the difference be-\\ntween two fractional forms, e.g., percent-\\nage changes, difference in ratios.\\nRANGE Questions requiring knowledge of the min-\\nimum and maximum of data observations.\\nCOMPARE Questions necessitating a comparison\\nbetween mathematical quantities (e.g.,\\ngreater than, less than).\\nAVERAGE Questions needing knowledge of the aver-\\nage, used to calculate the central tendency\\nof a group of data points.\\nIN-\\nDOMAIN -\\nINFO\\nQuestions that require implicit knowledge\\nto understand domain-specific mathemati-\\ncal formulations (e.g., return on investment\\n(RoI), cost of goods sold (COGS), amorti-\\nzation rate, etc.).\\nTIME Questions explicitly involving mathemati-\\ncal operators for time-spans not in the table\\nor context.\\nCOUNTING Questions requiring the counting of ele-\\nments in a set or group of data points.\\nTable 1: Mathematical concept categories and definitions for\\nstudying LLM concept comprehension abilities.\\nto domain-specific knowledge focus and TIME\\nquestions due to limited sample size.\\n3. Table Length: Evaluating performance with\\nlarger supporting tables is crucial. Larger tables\\ncomplicate multi-hop reasoning tasks by increas-\\ning the amount of information, making it harder\\nto identify relevant evidence. We prioritize these\\nannotations for datasets like FinQA and Multihiertt,\\nwhere questions mainly use tables as supporting ev-\\nidence. Therefore, these annotations are confined\\nto these datasets. In Multihiertt, when multiple ta-\\nbles support evidence, we consider the one with the\\nhighest row count i.e. maximum table length. The\\ndataset distribution for Multihiertt and FinQA w.r.t\\ntable length (number of rows) is shown in Figure 6\\nin Appendix A.4.\\n4. Hierarchical Complexity: In hierarchical ta-\\nbles, such as those in Multihiertt, evaluating model\\nperformance concerning the growing hierarchical\\ncomplexity in cells with critical information be-\\ncomes paramount. To tackle this, we annotate each\\nexample in Multihiertt with the hierarchy depth\\nof cells containing relevant information. For table\\nwith multiple relevant cells, we consider the cell\\nwith the highest hierarchical depth for our analysis.\\nOur approach to estimating hierarchy depth is illus-\\ntrated in Figure 10. Figure 7(a) in Appendix A.4\\nillustrate how we calculate hierarchical complexity\\nfor examples with multiple relevant rows at various\\nhierarchical depths.\\n5. Missing Information: Interpreting a table be-\\ncomes challenging as the number of empty cells\\nincreases. Empty cells indicate missing or unde-\\nfined information, leading to potential gaps in un-\\nderstanding.\\nAssessing empty cell proportions is crucial to\\nquantify data ambiguity. More empty cells sug-\\ngest higher uncertainty, which can hinder models’\\nability to derive meaningful insights and impact rea-\\nsoning accuracy. In Multihiertt, where tables are\\nhierarchical in nature and empty cells occur quite\\nfrequently, we annotate examples with the empty\\ncells percentage, contributing to our understanding\\nof data ambiguity. For distribution of missing infor-\\nmation (empty cells proportions) across datasets,\\nrefer to Figure 7 (b) in Appendix A.4.\\nAnnotation Splits. We prioritized complex nu-\\nmerical questions in our selection criteria, bal-\\nancing this with resource constraints such as the\\nLLM context length limits. We also took into ac-\\ncount tables with deeper hierarchies in Multihiertt\\nand multi-turn conversations in ConvFinQA. For\\nTATQA, we utilized 45% of the development set by\\nfiltering out examples involving simple span selec-\\ntion. In the case of Multihiertt, we included 68% ofTATQA, we utilized 45% of the development set by\\nfiltering out examples involving simple span selec-\\ntion. In the case of Multihiertt, we included 68% of\\nthe test set by excluding examples where the table\\nlength exceeds 40. For FinQA and ConvFinQA,\\nwe employed the complete test and development\\nsets, respectively.\\n3 Experimental Results\\nIn this study, we choose to experiment with LLMs\\nsuch as GPT-3.5-Turbo, GPT-4, PaLM-540B,\\nMistral-7B-Instruct2, Llama-2-13B3 and\\nMAmmoTH-13B4. These LLMs are at the cutting\\nedge for both open-source and closed models\\napplications. Models like MAmmoTH-13B are\\nspecifically fine-tuned during pre-training to excel\\nin mathematical reasoning tasks. For more detail\\nabout the the model choices refer to Appendix A.2.\\n2https://huggingface.co/mistralai/Mistral-7B-Instruct-\\nv0.1\\n3https://huggingface.co/meta-llama/Llama-2-13b-chat-hf\\n4https://huggingface.co/TIGER-Lab/MAmmoTH-13BLLMs Prompting Methods: For an instruction-\\ntuned LLM, it’s assumed that we give the model a\\ntask-specific instruction I accompanied with a few\\n(usually k ∈ {2, 4}) demonstrations DT of a task\\nT. We experiment with the following prompting\\ntechniques:\\n(a.) Direct: In this setup, we explicitly in-\\nstruct the models to abstain from providing ex-\\nplanations and just return the final answer to the\\nposed question. For this scenario, DT contains\\n{(pi, qi, ai)}k\\ni=1 where p is the premise (table-text),\\nq is the question, and a is the ground-truth answer.\\n(b.) CoT: Moving forward, we experiment with\\nthe chain-of-thoughts prompting strategy where\\nwe instruct the model to output the explanation to\\nthe answer derived by it. Here, our DT contains\\n{(pi, qi, ei)}k\\ni=1 where p is the premise which in-\\ncludes the table and the associated text, q is the\\nquestion and e is the explanation of the answer.\\n(c.) PoT: In this case, the expected response\\nis a code derivation of the answer. Here, DT con-\\ntains {(pi, qi, ci)}k\\ni=1 where p is the premise which\\nincludes the table and the associated text, q is the\\nquestion and c is the code-derivation of the answer.\\n(d.) Decomposers: (Ye et al., 2023) proposed\\nto address the challenge of handling large tables\\nby decomposing them into more manageable sub-\\ntables. Similarly, complex questions are handled\\nby breaking them down into simpler subquestions.\\nDecomposition proves effective with SQL tables,\\nfacilitating the removal of distracting details while\\nretaining all supporting evidence. Questions are\\nfirst parsed to break them down into simpler, more\\nmanageable subquestions. The model then ad-\\ndresses each subquestion independently before\\ncomposing the answers to arrive at the final so-\\nlution. In this case, our demonstration set DT con-\\ntains {(p\\n′\\ni, ⟨q1, q2, ..., qn⟩, ai)}k\\ni=1 where p\\n′\\nis the\\npremise obtained by the irrelevant information re-\\nmoval to the question from the original premise\\np and ⟨q1, q2, ..., qn⟩ are the subquestions whose\\nanswers lead to the final answer.\\nEEDP Prompting Strategy: We propose a\\nnovel prompting strategy: Elicit −→Extract −→\\nDecompose −→Predict. Figure 4 show an illustra-\\ntion of our EEDP approach. Below are the detail\\nof each EEDP step:\\n1. Elicit: We prompt the model explicitly to first\\nelicit relevant domain knowledge for answer-\\ning a given query.\\n2. Extract: Conditioned on the table, question\\nand the elicited domain knowledge, the model\\nextracts supporting evidences to answer a\\ngiven question.\\n3. Decompose: We instruct the LLM to break\\na complex mathematical reasoning task into\\nmultiple atomic operations and compose the\\noperations to arrive at the final answer.\\n4. Predict: The model finally returns the derived\\nanswer in the above steps.\\nFigure 11 shows a example for EEDP strategy\\nwith one shot.\\nResults and Analysis. Table 2 shows a compar-\\nison in performance between different prompting\\nstrategies. Despite being a single prompt, EEDP\\ndemonstrates comparable or superior performance\\ncompared to PoT. Notably, we outperform PoT\\nsignificantly for PaLM-2-540B and LLAMA-2-13B\\nacross most datasets. Moreover, while PoT relies\\non external tools for executing mathematical pro-\\ngrams/code to obtain answers, EEDP exclusively\\nutilizes LLM for all tasks, including evidence ex-\\ntraction, operation identification, and execution,\\nensuring precision throughout the process.\\nAs shown in Table 2, the Decomposers prompt-\\ning strategy exhibits a much poorer performance\\ncompared to other strategies. The reason behind\\nthis was statistically found to be the inaccurate for-\\nmation of subtables from the main table, leading to\\ninformation loss as described in the previous para-\\ngraph. The performance of EEDP either surpasses\\nor matches very closely with that of PoT. The num-\\nber of shots was adjusted depending on the context\\nlength of the model.\\nWe can see that MAmmoTH-13B model, which is\\nfine-tuned on the MathInstruct dataset (Yue et al.,\\n2024) containing Instruction-Response pairs wherelength of the model.\\nWe can see that MAmmoTH-13B model, which is\\nfine-tuned on the MathInstruct dataset (Yue et al.,\\n2024) containing Instruction-Response pairs where\\nthe responses are a hybrid of CoT and PoT ratio-\\nnales, fails to perform well with the EEDP method-\\nology. We argue that this is due to two potential\\nreasons: (a.) Reduction of the number of shots\\nto adjust the context length as the EEDP response\\nis longer than that of the other methods, and (b.)\\nFinetuning may contribute to suboptimal perfor-\\nmance due to its alignment with a particular style\\nand format of responses, potentially limiting the\\nmodel’s adaptability and generalization to other\\ndiverse contexts.Dataset Model Direct CoT PoT EEDP Decomposers\\nGPT-4 55.81 86.91 89.99 88.67 47.46\\nGPT-3.5-Turbo 31.38 77.57 82.11 79.73 28.53\\nTATQA PaLM 2-540B 44.66 62.93 61.60 81.51 57.94\\nLlama 2-13B 3.36 35.95 34.16 40.95 25.93\\nMAmmoTH-13B 19.11 56.25 10.02 4.37 22.89\\nMistral-7B 10.92 59.14 16.53 56.06 7.24\\nGPT-4 65.12 72.38 75.26 76.05 44.93\\nGPT-3.5-Turbo 40.47 59.18 68.97 61.88 32.33\\nFinQA PaLM 2-540B 30.33 34.79 30.41 61.95 46.38\\nLlama 2-13B 1.80 25.34 12.97 30.47 11.91\\nMAmmoTH-13B 22.83 35.32 15.86 35.05 17.65\\nMistral-7B 26.11 34.23 10.56 34.86 12.34\\nGPT-4 63.10 71.19 78.81 77.91 18.76\\nGPT-3.5-Turbo 37.62 48.33 61.19 61.75 10.50\\nConvFinQA PaLM 2-540B 20.19 38.00 40.14 63.42 22.32\\nLlama 2-13B 3.80 29.45 29.92 39.42 10.35\\nMAmmoTH-13B 21.61 46.08 8.78 32.77 7.83\\nMistral-7B 12.35 48.45 14.48 36.57 11.16\\nGPT-4 41.35 55.13 67.23 70.32 36.86\\nGPT-3.5-Turbo 25.88 42.33 52.18 49.65 20.61\\nMultihiertt PaLM 2-540B 14.20 20.67 36.52 37.97 20.19\\nLlama 2-13B 1.54 30.66 18.12 24.15 16.86\\nMAmmoTH-13B 10.12 18.56 6.57 18.36 11.87\\nMistral-7B 14.909 22.92 14.94 10.97 11.63\\nTable 2: Comparison of performance of different models tested against a variety of prompting strategies\\nEEDP’s Computational Efficiency EEDP func-\\ntions as a unified single-prompt method, minimiz-\\ning computational complexity. Unlike methods like\\nPoT, which rely on external tools, EEDP operates\\nindependently. When assessing computational cost,\\nwe consider API calls and token generation. Since\\nEEDP uses a single-step prompting approach, only\\none API call is needed per query, making its com-\\nputational cost comparable to methods like CoT.\\nFor inference with open-source models, we used\\nhardware with an A40 40GB GPU. Processing one\\ndataset per model using the vLLM library took\\napproximately 10 hours.\\n4 Where do LLMs fail?\\nThrough manual inspection, we rigorously evaluate\\nthe EEDP responses against the meta-annotations\\nfrom section 2 as ground-truth benchmarks for ex-\\ntraction and model reasoning accuracy. The rea-\\nsoning programs represent sequences of arithmetic\\noperations necessary to derive the final answer, uti-\\nlizing values extracted from supporting evidence as\\noperands. To assess calculation accuracy, we manu-\\nally identify the model’s instantiation and precision\\nerrors. Our EEDP prompt ensures that the model\\npredominantly outputs responses in the expected\\nformat, with exceptions being rare. However, since\\nwe manually analyze all outputs, we do not penal-\\nize the model for format deviations but rather for\\nincorrect outputs. Penalties are applied only when\\nthe model makes errors in extraction, reasoning,\\nand/or calculation. Below, we categorize the EEDP\\nresponse errors in detail based on their origins:\\nDataset Error Type Per.(%)\\nFinQA\\nExtraction E1 10.38\\nE2 25\\nReasoning R1 25\\nR2 15.57\\nCalculation C1/C2 24.06\\nConvFinQA\\nExtraction E1 8.45\\nE2 14.08\\nReasoning R1 19.72\\nR2 36.62\\nCalculation C1/C2 21.13\\nTATQA\\nExtraction E1 13.79\\nE2 31.03\\nReasoning R1 22.41\\nR2 5.17\\nCalculation C1/C2 27.59\\nMultihiertt\\nExtraction E1 20.5\\nE2 31.5\\nReasoning R1 15.5\\nR2 12\\nCalculation C1/C2 20.5\\nTable 3: Error Analysis on Various Datasets. In this table,\\nExtraction.E1: Missing Evidences, Extraction.E2: Wrong\\nEvidences, Reasoning.R1: Insufficient Domain Knowledge,\\nReasoning.R2: Question Misinterpretation, Calculation: In-\\nstantiation (C1) and Precision errors (C2)\\n1. Incorrect Extraction: This category encom-\\npasses errors where the model faces difficultiesin accurately identifying and extracting the perti-\\nnent information necessary for effective problem-\\nsolving. These errors point to challenges in retriev-\\ning precise information. These errors can further\\nbe subdivided into two categories\\n• Missing/Incomplete Evidences (E1): The\\nmodel fails to extract all the necessary evi-\\ndences which serve as ingredients to derive\\nthe final answer.\\n• Wrong Evidences (E2): The model extracts\\nwrong values for variables as supporting evi-\\ndences from the premise.\\n2. Incorrect Reasoning: Errors in reasoning oc-\\ncur when the model struggles to formulate an appro-\\npriate and contextually relevant approach to tackle\\na given problem. Possible reasons include a lack of\\ndomain knowledge or an inaccurate interpretation\\nof the posed question. Consequently, this error type\\ncan arise from two sources.\\n• Deficit in Domain Knowledge (R1): These\\nerrors occur when the model attempts to de-\\nrive an answer to the posed question using a\\nwrong formula for domain-specific measures,\\nfor eg. COGS, ROI etc.\\n• Question Misinterpretation (R2): These\\nerrors occur when the model interprets the\\nquestion differently and provides responses\\nthat are not aligned with the intended query.\\nOverall, the model’s outputs lack grounding\\nin the original question posed to it.\\n3. Incorrect Calculation: This variety of errors\\ninclude those where the model commits mistakes\\ndue to calculation mistakes. This can be of two\\ntypes as described below.\\n• Incorrect Instantiation (C1): These include\\ncases if the model extracts the right evidences,\\nuses the right derivation formula but instanti-\\nates the variables incorrectly with the values\\nresulting in an incorrect answer.\\n• Precision Error (C2): Language models em-\\nploy mathematical algorithms for arithmetic\\noperations, but their results may not always\\nbe perfectly accurate due to insufficient data\\npattern coverage or introduced biases during\\ntraining. Consequently, they can sometimes\\ngenerate outputs with slight inaccuracies or\\ndeviations from correct results. We show a\\ndetailed analysis in A.1.\\nAnalysis: The above categorization provides a\\nnuanced understanding of the diverse challenges\\nand shortcomings exhibited in different facets of\\nmathematical reasoning. We observe that in a lot of\\ncases, the error propagates because of a deficiency\\nin domain knowledge. It is critical for both evi-\\ndence extraction and reasoning. Despite possessing\\ngeneral domain knowledge owing to the massive\\namount of data these models have been pre-trained\\nupon, these models may require explicit prompts\\nto elicit the specific domain knowledge needed for\\na particular question. Furthermore, errors can arise\\ndue to the models’ limited proficiency in multi-step\\nreasoning, especially in tackling questions involv-\\ning multiple arithmetic operations in a sequence.\\nWe give a quantitative measure of each type of\\nerrors for each of the 4 datasets we consider for\\nour study in Table 3. We also provide examples\\ncorresponding to each error category in figures 12,\\n13, 14, 15, 16 and 17. Statistically, we find that\\nreasoning errors contribute a significant chunk to\\nthe total number of errors. In case of complex hier-\\narchical tables like that in Multihiertt, the model is\\nfound to struggle with extracting the right support-\\ning evidences from the premise for a given question.\\nCalculation errors can be taken care of if a third-\\nparty calculation tool (an external agent) is chained\\nto the language model.\\n5 Analysis on Reasoning Annotations\\nWe analyse model performance on the basis of fine-\\ngrained annotations as described in the section 4.\\n1. Performance vs Number of Reasoning Steps.\\nWe investigate model performance with increasing\\nmathematical reasoning steps, as shown in Figure 2.\\nThis analysis provides insights into models’ ability\\nto handle varying task complexities. As expected,\\nperformance decreases with more reasoning steps,\\nindicating LLMs’ challenges in retrieving informa-\\ntion and reasoning as complexity grows.to handle varying task complexities. As expected,\\nperformance decreases with more reasoning steps,\\nindicating LLMs’ challenges in retrieving informa-\\ntion and reasoning as complexity grows.\\nAnomalies are observed in ConvFinQA, where\\naccuracy improves after greater than or equal to\\ntwo reasoning steps, potentially due to questions\\nreferring to answers of prior conversation turns.\\nAnomalies like these warrant further investigation\\nbeyond this study’s scope.\\n2. Performance across Question Types. We\\nanalyze the performance trends across different\\nquestion categories, as defined in Table 1, to assess\\nthe models’ understanding of various mathematical1 2 3 >=4\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1 2 3 >=40.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n1 2 3 >=4\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n1 2 3 >=4\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\nGPT-3.5-Turbo+EEDP PaLM-2-540B+EEDPGPT-4+PoT GPT-3.5-Turbo+PoT GPT-4+EEDP\\nPaLM-2-540B+PoT\\nNumber of Steps Number of Steps\\nAccuracyAccuracy\\nTATQA FinQA\\nConvFinQA Multihiertt\\nFigure 2: A comparison showcasing the performance trends across various datasets with the increasing number of reasoning\\nsteps. The analysis contrasts the effectiveness of EEDP (our method) against PoT in addressing complex reasoning.\\nand financial concepts. Figure 3 shows that EEDP\\nconsistently performs better than or as well as PoT\\nacross all datasets. The improvement is particu-\\nlarly pronounced for PaLM-2-540B in all question\\ncategories.\\n3. Performance across Arithmetic Operations.\\nFigure 5 in Appendix A.1 shows that for relatively\\nsimpler arithmetic operations like addition and sub-\\ntraction, the effect of order of magnitude of the\\noperands is less profound as compared to harder\\narithmetic operations such as multiplication and\\ndivision. We observe the trend in the performance\\naccuracy with the growing and diminishing orders\\nof magnitude. We also observe bigger and more\\ncapable models such as GPT-4, GPT-3.5-TURBO\\nand PaLM 2-540B perform much better on simpler\\naddition, subtraction task in comparison to multi-\\nplication, division task. For more details on refer\\nto the Appendix A.1.\\n6 Other Related Works\\n6.1 LLMs on Mathematical Reasoning\\nPre-trained Language Models (PLMs) excel in\\nNLP tasks (Devlin et al., 2019; Zhuang et al., 2021)\\nby leveraging extensive textual corpora to acquire\\nworld knowledge (Guu et al., 2020). Expanding\\nPLMs for math-related tasks has been challeng-\\ning due to their non-specific training. Recent at-\\ntempts include MWP-BERT and Minerva (Liang\\net al., 2022; Lewkowycz et al., 2022), but curating\\nhigh-quality math data remains difficult. To bridge\\nthe gap, researchers fine-tune PLMs for specific\\nmath tasks. Notable works, like Bhaskara, Self-\\nsampler, Aristo, FinQANet, TAGOP, MT2Net, and\\nothers (Mishra et al., 2022; Ni et al., 2022; Clark\\net al., 2021; Chen et al., 2021b; Zhu et al., 2021;\\nZhao et al., 2022; Cao and Xiao, 2022; Welleck\\net al., 2022), employ PLMs such as GPT-Neo and\\nRoBERTa for math problem-solving.\\n6.2 Tabular Question Answering\\nHandling diverse input formats in question answer-\\ning, including structured tables and visual data,\\nposes challenges for language models. HybridQA\\n(Chen et al., 2020b) introduces questions requir-\\ning reasoning over tables and text. MultimodalQA\\n(Talmor et al., 2021) adds visual inference. Our fo-\\ncus is on multi-hop question answering over tables\\nand text. TAPAS (Herzig et al., 2020) tackles table-CHANGE RA\\nTIO\\nCOUNTINGAVERAGE DIFF SUM RATIO\\n0.2\\n0.4\\n0.6\\n0.8\\n1\\nCOMP\\nARE\\nSUM PRODUCTDOMAIN INFODIVISIONDIFF RATIO CHANGE RA\\nTIO\\nAVERAGE0.2\\n0.4\\n0.6\\n0.8\\n1\\nDIVISION CHANGE RA\\nTIO\\nAVERAGE SUM RATIO DIFF0.2\\n0.4\\n0.6\\n0.8\\n1\\nAVERAGE CHANGE RA\\nTIO\\nSUM RATIO DIFF0.2\\n0.4\\n0.6\\n0.8\\n1\\nGPT-3.5-Turbo+EEDP GPT-3.5-Turbo+PoT GPT-4+EEDP GPT-4+PoT PaLM-2-540B+EEDP\\nPaLM-2-540B+PoT\\nQuestion Type Question Type\\nAccuracyAccuracy\\nTATQA FinQA\\nConvFinQA Multihiertt\\nFigure 3: A comparison showcasing the performance trends observed in various datasets across different question types. The\\nanalysis contrasts the effectiveness of EEDP (our method) against Few-Shot PoT (PoT). Best viewed in color.\\nbased questions without logical forms, while Tapex\\n(Liu et al., 2022) empowers generative models with\\ntable reasoning.\\nModels like FinQANet, TagOP, and MT2Net\\n(Chen et al., 2021b; Zhu et al., 2021; Zhao et al.,\\n2022) employ a retriever module to extract sup-\\nporting facts from input financial reports, followed\\nby a reasoning module to derive the final answer.\\nRetrieving relevant evidence and conducting rea-\\nsoning both demand domain-specific knowledge,\\nsuch as understanding financial transactions, iden-\\ntifying revenue trends, and interpreting complex\\ninvestment statements. Thus, reliance on an exter-\\nnal knowledge base becomes crucial for addressing\\nthe challenges of domain-specific multi-hop ques-\\ntion answering.\\n6.3 Prompt Engineering\\nIn-context Learning (ICL) equips Language Mod-\\nels (LLMs) with task examples and queries, en-\\nabling them to perform target tasks without updat-\\ning model parameters (Brown et al., 2020; OpenAI,\\n2023). They excel in mathematical reasoning with\\nfew-shot prompts but struggle with more complex\\ntasks. Methods like chain-of-thoughts (CoT) (Wei\\net al., 2022) have improved LLM performance by\\nguiding them through intermediate reasoning steps.\\nEnhancing multi-step reasoning involves two main\\napproaches: improving in-context examples and\\nobtaining better reasoning steps. Some focus on\\nstable in-context example selection (Fu et al., 2023;\\nRubin et al., 2022; Lu et al., 2023). Others adopt a\\nmodular approach, using off-the-shelf tools (Schick\\net al., 2023), program of thoughts (PoT) (Chen\\net al., 2022a), or decomposition strategies (Zhou\\net al., 2023; Dua et al., 2022; Khot et al., 2023).\\nOur task requires complex multi-step reason-\\ning across diverse information sources. LLMs, as\\ndemonstrated by (Chen, 2023), can reason over\\nstructured tables without explicit encoding. They\\nalso serve as versatile decomposers, breaking down\\nextensive evidence and complex questions (Ye\\net al., 2023).7 Key Takeaways\\nOur Contributions. Our study aimed to delve\\ninto the mathematical reasoning abilities of LLMs\\nwithin the context of financial documents where\\nmodels are tasked with complex hybrid (table-text)\\nquestion answering. This presents a significant\\nchallenge, requiring models not only to provide ac-\\ncurate numerical analysis but also to retrieve right\\nsupporting evidence tailored to specific question\\nrequirement. Moreover, it necessitates the extrac-\\ntion of necessary knowledge from the model’s pre-\\ntrained parameters to address queries.\\nFirstly, we meticulously annotate popular finan-\\ncial datasets, such as FinQA, ConvFinQA, TATQA,\\nand Multihiertt, with detailed meta-information.\\nThis includes specifying mathematical operations,\\ntypes of reasoning involved, table dimensions,\\nquestion types, and the depth of table hierarchy.\\nFurthermore, we conduct a manual error analy-\\nsis to quantify error types across multiple LLMs.\\nThese detailed annotations are invaluable for an-\\nalyzing various dimensions where LLM models\\nencounter challenges. This, in turn, aids in the de-\\nvelopment of better prompting techniques such as\\nEEDP, aimed at enhancing LLMs’ mathematical\\nreasoning abilities. The resulting improvement in\\nperformance with EEDP across multiples datasets\\nserves as compelling evidence of the effectiveness\\nof this approach.\\nWhat did we learn? Our analysis revealed that\\nLLMs can accurately handle addition and subtrac-\\ntion tasks e.g. modle perform fairly when calcu-\\nlating total expenses or profits, but struggle with\\nmultiplication and division e.g. model performs\\npoorly with questions requiring reasoning oper-\\nations involving proportions, ratios, percentages,\\nand division. Moreover, as the complexity of the\\ndata increases either through a higher absolute or-\\nder scale or more decimal numbers, model per-\\nformance degrades. Model performance also de-\\ngrades with increasing number of reasoning steps\\nand lengthy complex hierarchical table structures.\\ne.g. in complex datasets with hierarchical struc-\\ntures such as Multiheirtt, TATQA, incorrect extrac-\\ntion leads to modeling errors. Similarly, on queries\\ninvolving multiple conversational turns, such as\\nthose in ConvFinQA, model perform poorly due\\nto reasoning failures, like misinterpreting multiple\\nqueries longer context. Across all models, incor-\\nrect reasoning and incorrect extraction consistently\\nemerge as common sources of errors. For smaller\\nmodels, even straightforward calculations, result in\\nerrors due to imprecise calculations.\\nEEDP vs other methods\\n(a.) EEDP vs PoT: PoT enhances LLM infer-\\nence with the use of variable names for the support-\\ning values extracted from the premise and prompts\\nthe LLM to express their thought process in the\\nform of programs. The model output is a program\\nwhich is executed externally to derive the final an-\\nswer. EEDP proposes to decompose a complex\\nreasoning task into simple atomic steps whose so-\\nlutions can be composed to give the final answer.\\nIn PoT, they don’t make the language model do the\\ncomputation while in our case the language model\\nnot only outputs the reason but also computes the\\nfinal answer. This distinction implies that PoT may\\nhave an inherent advantage over EEDP.\\n(b.) EEDP vs Decomposers: The prompting\\nstrategy proposed by (Ye et al., 2023) was orig-\\ninally designed for querying SQL tables, they\\nuse LLMs to break down evidence and ques-\\ntions for SQL interpreters. In contrast, our ap-\\nproach addresses more complex scenarios involv-\\ning both tables and text, requiring advanced reason-\\ning skills beyond the capability of standard SQL\\ninterpreters. Pruning a non-SQL table using this\\nmethod can lead to significant information loss\\nfrom the premise which can be a potential ingredi-\\nent required to derive the final answer. Addition-\\nally, this is an expensive method as it requires 3X\\nAPI calls as opposed to other prompting methods.\\nMoreover, EEDP is a unified prompting strategy\\nwhich integrates multiple solver elements into aally, this is an expensive method as it requires 3X\\nAPI calls as opposed to other prompting methods.\\nMoreover, EEDP is a unified prompting strategy\\nwhich integrates multiple solver elements into a\\nsingle unified prompt for elicitation, extraction, de-\\ncomposition and prediction.\\n8 Conclusion\\nIn conclusion, our study delved into LLMs’ mathe-\\nmatical reasoning in complex financial scenarios,\\nassessing their adaptability to mixed structured ta-\\nbles and unstructured text. Through rigorous ex-\\nperimentation, we uncovered insights into their\\nperformance and limitations, presenting a tailored\\nprompting technique that outperformed other base-\\nline methods. Our findings advance understanding\\nof LLMs’ abilities in tackling intricate mathemat-\\nical tasks within semi-structured documents, sug-\\ngesting directions for future research. Please refer\\nto appendix section A.3 for future work details.Limitations\\nThe scope of this work is limited by the following\\nchallenges:\\nDataset Scarcity. There are not many datasets\\ndealing with numerical reasoning over semi-\\nstructured data apart from the ones from financial\\ndomain. As a future work, it would be interesting\\nto similar analysis across various domains such as\\ne-commerce, healthcare, sports and scientific tables\\nfrom research papers, uncovering new challenges\\nand insights. This expansion will enhance the appli-\\ncability and impact of our research within the NLP\\ncommunity. However, creating tailored datasets for\\nthese domains presents a significant challenge.\\nFor now to ensure a comprehensive evaluation\\nof LLMs, we have integrated financial datasets that\\noffer diverse challenges. For instance, Multihiertt\\nevaluates model performance with intricate premise\\nstructures, providing insights into handling com-\\nplex data hierarchies. ConvFinQA delves into the\\nintricate chains of numerical reasoning within con-\\nversational question answering contexts, offering a\\nunique perspective on dynamic data interpretation.\\nMoreover, FinQA and TAT-QA encompass a wide\\narray of reasoning types, with a significant por-\\ntion requiring domain-specific knowledge, thereby\\nbroadening the evaluation spectrum.\\nFactors Isolation. It is essential to acknowledge\\nthat there may be multiple factors influencing the\\nperformance of large language models while deal-\\ning with numerical reasoning over semi-structured\\ndata. In our analysis, we have focused on specific\\nfactors and trends, but it is important to recognize\\nthat the overall performance is affected by a mul-\\ntitude of variables. Marginalizing i.e. observing\\nthe trend along one while keeping the rest as con-\\nstants or isolating a single factor is challenging and\\ncannot be done with real-world data. Additionally,\\nfuture investigations may benefit from simulating\\ncontrolled scenarios on synthetic and counterfac-\\ntual datasets to gain deeper insights into the impact\\nof individual factors on model performance.\\nModeling Improvement. We emphasize our\\nanalysis on prominent models such as GPT-4,\\nGPT-3.5-TURBO, and PaLM 2-540B due to their\\nsubstantial size and capabilities. Notably, other\\nopen-sourced large language models like LLaMA\\n2-13B, MAmmoTH-13B and Mistral-7B-Instruct\\ndid not exhibit satisfactory performance in numeri-\\ncal reasoning over semi-structured data. For more\\ndetail about the the model choices refer to Ap-\\npendix A.2. This accentuates the need for explor-\\ning computationally feasible and cheaper models\\nthat can deliver remarkable performance in tasks\\ninvolving numerical reasoning over heterogeneous\\nsources of information. Future experiments with\\nample computational resources may involve explor-\\ning larger open-source models like OLMo, Mixtral,\\nand DBRX, which have been recently released.\\nEthics Statement\\nWe, the authors of this work, affirm that our work\\ncomplies with the highest ethical standards in re-\\nsearch and publication. In conducting this research,\\nwe have considered and addressed various ethi-\\ncal considerations to ensure the responsible and\\nfair use of computational linguistics methodologies.\\nWe provide detailed information to facilitate the re-\\nproducibility of our results. This includes sharing\\ncode, datasets (in our case, we deal with publicly\\navailable datasets and comply to the ethical stan-\\ndards mentioned by the authors of the respective\\nworks.), and other relevant resources to enable the\\nresearch community to validate and build upon our\\nwork. The claims in the paper match the experi-\\nmentation results, however, with black-box large\\nlanguage models, a certain degree of stochastic-\\nity is expected which we attempt to minimize by\\nkeeping a fixed temperature. We describe in the\\nfullest details the annotations, dataset splits, mod-\\nels used and prompting methods tried, ensuring\\nreproducibility of our work.\\nAcknowledgements\\nResearch was sponsored by the Army Research\\nOffice and was accomplished under Grant Numberels used and prompting methods tried, ensuring\\nreproducibility of our work.\\nAcknowledgements\\nResearch was sponsored by the Army Research\\nOffice and was accomplished under Grant Number\\nW911NF-20-1-0080. The views and conclusions\\ncontained in this document are those of the au-\\nthors and should not be interpreted as representing\\nthe official policies, either expressed or implied,\\nof the Army Research Office or the U.S. Gov-\\nernment. The U.S. Government is authorized to\\nreproduce and distribute reprints for Government\\npurposes notwithstanding any copyright notation\\nherein. This work was partially funded by ONR\\nContract N00014-19-1-2620. Lastly, we extend\\nour appreciation to the reviewing team for their\\ninsightful comments.References\\nRami Aly, Zhijiang Guo, Michael Sejr Schlichtkrull,\\nJames Thorne, Andreas Vlachos, Christos\\nChristodoulopoulos, Oana Cocarascu, and Arpit\\nMittal. 2021. The fact extraction and VERification\\nover unstructured and structured information\\n(FEVEROUS) shared task. In Proceedings of the\\nFourth Workshop on Fact Extraction and VERifica-\\ntion (FEVER) , pages 1–13, Dominican Republic.\\nAssociation for Computational Linguistics.\\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik\\nKoncel-Kedziorski, Yejin Choi, and Hannaneh Ha-\\njishirzi. 2019. MathQA: Towards interpretable math\\nword problem solving with operation-based for-\\nmalisms. In Proceedings of the 2019 Conference\\nof the North American Chapter of the Association for\\nComputational Linguistics: Human Language Tech-\\nnologies, Volume 1 (Long and Short Papers), pages\\n2357–2367, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\\nGretchen Krueger, Tom Henighan, Rewon Child,\\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\\nClark, Christopher Berner, Sam McCandlish, Alec\\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\\nLanguage models are few-shot learners. In Ad-\\nvances in Neural Information Processing Systems ,\\nvolume 33, pages 1877–1901. Curran Associates,\\nInc.\\nJie Cao and Jing Xiao. 2022. An augmented benchmark\\ndataset for geometric question answering through\\ndual parallel text encoding. In Proceedings of the\\n29th International Conference on Computational Lin-\\nguistics, pages 1511–1520, Gyeongju, Republic of\\nKorea. International Committee on Computational\\nLinguistics.\\nWenhu Chen. 2023. Large language models are few(1)-\\nshot table reasoners. In Findings of the Associa-\\ntion for Computational Linguistics: EACL 2023 ,\\npages 1120–1130, Dubrovnik, Croatia. Association\\nfor Computational Linguistics.\\nWenhu Chen, Xueguang Ma, Xinyi Wang, and\\nWilliam W. Cohen. 2022a. Program of thoughts\\nprompting: Disentangling computation from reason-\\ning for numerical reasoning tasks. arXiv preprint\\narXiv:2211.12588.\\nWenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai\\nZhang, Hong Wang, Shiyang Li, Xiyou Zhou, and\\nWilliam Yang Wang. 2020a. Tabfact : A large-scale\\ndataset for table-based fact verification. In Inter-\\nnational Conference on Learning Representations\\n(ICLR), Addis Ababa, Ethiopia.\\nWenhu Chen, Ming wei Chang, Eva Schlinger, William\\nWang, and William Cohen. 2021a. Open question\\nanswering over tables and text. Proceedings of ICLR\\n2021.\\nWenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong,\\nHong Wang, and William Yang Wang. 2020b. Hy-\\nbridQA: A dataset of multi-hop question answering\\nover tabular and textual data. In Findings of the Asso-\\nciation for Computational Linguistics: EMNLP 2020,\\npages 1026–1036, Online. Association for Computa-\\ntional Linguistics.\\nZhiyu Chen, Wenhu Chen, Charese Smiley, Sameena\\nShah, Iana Borova, Dylan Langdon, Reema Moussa,\\nMatt Beane, Ting-Hao Huang, Bryan Routledge, and\\nWilliam Yang Wang. 2021b. FinQA: A dataset of nu-\\nmerical reasoning over financial data. In Proceedings\\nof the 2021 Conference on Empirical Methods in Nat-\\nural Language Processing, pages 3697–3711, Online\\nand Punta Cana, Dominican Republic. Association\\nfor Computational Linguistics.\\nZhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang\\nMa, Sameena Shah, and William Yang Wang. 2022b.\\nConvFinQA: Exploring the chain of numerical rea-\\nsoning in conversational finance question answering.\\nIn Proceedings of the 2022 Conference on Empiri-\\ncal Methods in Natural Language Processing, pages\\n6279–6292, Abu Dhabi, United Arab Emirates. As-\\nsociation for Computational Linguistics.\\nPeter Clark, Oren Etzioni, Daniel Khashabi, Tushar\\nKhot, Bhavana Dalvi Mishra, Kyle Richardson,\\nAshish Sabharwal, Carissa Schoenick, Oyvindsociation for Computational Linguistics.\\nPeter Clark, Oren Etzioni, Daniel Khashabi, Tushar\\nKhot, Bhavana Dalvi Mishra, Kyle Richardson,\\nAshish Sabharwal, Carissa Schoenick, Oyvind\\nTafjord, Niket Tandon, Sumithra Bhakthavatsalam,\\nDirk Groeneveld, Michal Guerquin, and Michael\\nSchmitz. 2021. From ’f’ to ’a’ on the n.y. regents\\nscience exams: An overview of the aristo project.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian,\\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro\\nNakano, Christopher Hesse, and John Schulman.\\n2021. Training verifiers to solve math word prob-\\nlems. arXiv preprint arXiv:2110.14168.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\\nKristina Toutanova. 2019. BERT: Pre-training of\\ndeep bidirectional transformers for language under-\\nstanding. In Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association for\\nComputational Linguistics: Human Language Tech-\\nnologies, Volume 1 (Long and Short Papers), pages\\n4171–4186, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\nDheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt\\nGardner. 2022. Successive prompting for decom-\\nposing complex questions. In Proceedings of the\\n2022 Conference on Empirical Methods in Natu-\\nral Language Processing , pages 1251–1265, Abu\\nDhabi, United Arab Emirates. Association for Com-\\nputational Linguistics.Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and\\nTushar Khot. 2023. Complexity-based prompting for\\nmulti-step reasoning.\\nVivek Gupta, Maitrey Mehta, Pegah Nokhiz, and Vivek\\nSrikumar. 2020. INFOTABS: Inference on tables\\nas semi-structured data. In Proceedings of the 58th\\nAnnual Meeting of the Association for Computational\\nLinguistics, pages 2309–2324, Online. Association\\nfor Computational Linguistics.\\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\\npat, and Ming-Wei Chang. 2020. Realm: Retrieval-\\naugmented language model pre-training. In Proceed-\\nings of the 37th International Conference on Machine\\nLearning, ICML’20. JMLR.org.\\nJonathan Herzig, Pawel Krzysztof Nowak, Thomas\\nMüller, Francesco Piccinno, and Julian Eisenschlos.\\n2020. TaPas: Weakly supervised table parsing via\\npre-training. In Proceedings of the 58th Annual Meet-\\ning of the Association for Computational Linguistics,\\npages 4320–4333, Online. Association for Computa-\\ntional Linguistics.\\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao\\nFu, Kyle Richardson, Peter Clark, and Ashish Sab-\\nharwal. 2023. Decomposed prompting: A modular\\napproach for solving complex tasks. In The Eleventh\\nInternational Conference on Learning Representa-\\ntions.\\nAitor Lewkowycz, Anders Andreassen, David Dohan,\\nEthan Dyer, Henryk Michalewski, Vinay Ramasesh,\\nAmbrose Slone, Cem Anil, Imanol Schlag, Theo\\nGutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy\\nGur-Ari, and Vedant Misra. 2022. Solving quantita-\\ntive reasoning problems with language models. In\\nAdvances in Neural Information Processing Systems,\\nvolume 35, pages 3843–3857. Curran Associates,\\nInc.\\nChenying Li, Wenbo Ye, and Yilun Zhao. 2022. Fin-\\nMath: Injecting a tree-structured solver for question\\nanswering over financial reports. In Proceedings of\\nthe Thirteenth Language Resources and Evaluation\\nConference, pages 6147–6152, Marseille, France. Eu-\\nropean Language Resources Association.\\nZhenwen Liang, Jipeng Zhang, Lei Wang, Wei Qin,\\nYunshi Lan, Jie Shao, and Xiangliang Zhang. 2022.\\nMWP-BERT: Numeracy-augmented pre-training for\\nmath word problem solving. In Findings of the Asso-\\nciation for Computational Linguistics: NAACL 2022,\\npages 997–1009, Seattle, United States. Association\\nfor Computational Linguistics.\\nQian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi\\nLin, Weizhu Chen, and Jian-Guang Lou. 2022.\\nTAPEX: Table pre-training via learning a neural SQL\\nexecutor. In International Conference on Learning\\nRepresentations.\\nPan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu,\\nSong-Chun Zhu, Tanmay Rajpurohit, Peter Clark,\\nand Ashwin Kalyan. 2023. Dynamic prompt learning\\nvia policy gradient for semi-structured mathematical\\nreasoning. In International Conference on Learning\\nRepresentations (ICLR).\\nSwaroop Mishra, Matthew Finlayson, Pan Lu, Leonard\\nTang, Sean Welleck, Chitta Baral, Tanmay Rajpuro-\\nhit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark,\\nand Ashwin Kalyan. 2022. LILA: A unified bench-\\nmark for mathematical reasoning. In Proceedings of\\nthe 2022 Conference on Empirical Methods in Nat-\\nural Language Processing, pages 5807–5832, Abu\\nDhabi, United Arab Emirates. Association for Com-\\nputational Linguistics.\\nAnsong Ni, Jeevana Priya Inala, Chenglong Wang, Alex\\nPolozov, Christopher Meek, Dragomir Radev, and\\nJianfeng Gao. 2022. Learning math reasoning from\\nself-sampled correct and partially-correct solutions.\\nIn The Eleventh International Conference on Learn-\\ning Representations.\\nOpenAI. 2023. Gpt-4 technical report.\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal.\\n2021. Are NLP models really able to solve simple\\nmath word problems? In Proceedings of the 2021\\nConference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human\\nLanguage Technologies, pages 2080–2094, Online.\\nAssociation for Computational Linguistics.\\nOhad Rubin, Jonathan Herzig, and Jonathan Berant.\\n2022. Learning to retrieve prompts for in-context\\nlearning. In Proceedings of the 2022 Conference of\\nthe North American Chapter of the Association for2022. Learning to retrieve prompts for in-context\\nlearning. In Proceedings of the 2022 Conference of\\nthe North American Chapter of the Association for\\nComputational Linguistics: Human Language Tech-\\nnologies, pages 2655–2671, Seattle, United States.\\nAssociation for Computational Linguistics.\\nTimo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta\\nRaileanu, Maria Lomeli, Luke Zettlemoyer, Nicola\\nCancedda, and Thomas Scialom. 2023. Toolformer:\\nLanguage models can teach themselves to use tools.\\narXiv preprint arXiv:2302.04761.\\nAlon Talmor, Ori Yoran, Amnon Catav, Dan Lahav,\\nYizhong Wang, Akari Asai, Gabriel Ilharco, Han-\\nnaneh Hajishirzi, and Jonathan Berant. 2021. Mul-\\ntimodalqa: Complex question answering over text,\\ntables and images.\\nShyam Upadhyay and Ming-Wei Chang. 2017. An-\\nnotating derivations: A new evaluation strategy and\\ndataset for algebra word problems. In Proceedings\\nof the 15th Conference of the European Chapter of\\nthe Association for Computational Linguistics: Vol-\\nume 1, Long Papers, pages 494–504, Valencia, Spain.\\nAssociation for Computational Linguistics.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\\nBosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,\\nand Denny Zhou. 2022. Chain-of-thought prompt-\\ning elicits reasoning in large language models. In\\nAdvances in Neural Information Processing Systems,volume 35, pages 24824–24837. Curran Associates,\\nInc.\\nSean Welleck, Jiacheng Liu, Ximing Lu, Hannaneh\\nHajishirzi, and Yejin Choi. 2022. Naturalprover:\\nGrounded mathematical proof generation with lan-\\nguage models. In Advances in Neural Information\\nProcessing Systems.\\nYunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei\\nHuang, and Yongbin Li. 2023. Large language mod-\\nels are versatile decomposers: Decomposing evi-\\ndence and questions for table-based reasoning. In\\nProceedings of the 46th International ACM SIGIR\\nConference on Research and Development in Infor-\\nmation Retrieval, SIGIR ’23, page 174–184, New\\nYork, NY , USA. Association for Computing Machin-\\nery.\\nXiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wen-\\nhao Huang, Huan Sun, Yu Su, and Wenhu Chen.\\n2024. MAmmoTH: Building math generalist models\\nthrough hybrid instruction tuning. In The Twelfth In-\\nternational Conference on Learning Representations.\\nYilun Zhao, Yunxiang Li, Chenying Li, and Rui Zhang.\\n2022. MultiHiertt: Numerical reasoning over multi\\nhierarchical tabular and textual data. In Proceedings\\nof the 60th Annual Meeting of the Association for\\nComputational Linguistics (Volume 1: Long Papers),\\npages 6588–6600, Dublin, Ireland. Association for\\nComputational Linguistics.\\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei,\\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\\nClaire Cui, Olivier Bousquet, Quoc Le, and Ed Chi.\\n2023. Least-to-most prompting enables complex rea-\\nsoning in large language models.\\nFengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao\\nWang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-\\nSeng Chua. 2021. TAT-QA: A question answering\\nbenchmark on a hybrid of tabular and textual con-\\ntent in finance. In Proceedings of the 59th Annual\\nMeeting of the Association for Computational Lin-\\nguistics and the 11th International Joint Conference\\non Natural Language Processing (Volume 1: Long\\nPapers), pages 3277–3287, Online. Association for\\nComputational Linguistics.\\nLiu Zhuang, Lin Wayne, Shi Ya, and Zhao Jun. 2021. A\\nrobustly optimized BERT pre-training approach with\\npost-training. In Proceedings of the 20th Chinese\\nNational Conference on Computational Linguistics,\\npages 1218–1227, Huhhot, China. Chinese Informa-\\ntion Processing Society of China.\\nA Appendix\\nA.1 How proficient are LLMs in performing\\nsimple arithmetic operations?\\nTo assess the effectiveness of Large Language Mod-\\nels in handling fundamental arithmetic tasks (ad-\\ndition (+), subtraction (-), multiplication (*), and\\ndivision (/)) across operands of varying magnitudes,\\nwe generate a set of 2600 synthetic arithmetic ex-\\npressions using GPT-4. This set includes 650 prob-\\nlems for each arithmetic operation. Within each\\noperation category, we categorize tasks into groups\\nbased on a parameter denoted as τ:\\nτ = OOM( arg max\\nop\\n∥OOM(op)∥ )\\nwhere, arg maxselects the operand op with the\\ngreater absolute value of the order of magnitude,\\nand OOM represents the order of magnitude.\\nThis approach is motivated by cognitive chal-\\nlenges commonly faced by humans, as they often\\nencounter difficulties with both high and low or-\\nders of magnitude. Essentially, captures the order\\nof magnitude of the operand with the larger ab-\\nsolute value among the two. For each arithmetic\\noperation, we establish groups withτ, ranging from\\n-6 to 6. Within each group, there are 50 arithmetic\\nexpressions. This systematic grouping provides a\\ncomprehensive assessment across various difficulty\\nlevels based on operand magnitudes.\\nAnalysis. Figure 5 illustrates that for simpler\\narithmetic operations like addition and subtrac-\\ntion, the impact of the order of magnitude of the\\noperands is less significant compared to harder op-\\nerations like multiplication and division. We ob-\\nserve a trend in performance accuracy with increas-\\ning and decreasing orders of magnitude. Larger\\nmodels such as GPT-4, GPT-3.5-TURBO, and PaLM\\n2-540B perform significantly better on addition and\\nsubtraction tasks as compared to the multiplication\\nand division tasks.models such as GPT-4, GPT-3.5-TURBO, and PaLM\\n2-540B perform significantly better on addition and\\nsubtraction tasks as compared to the multiplication\\nand division tasks.\\nA.2 Model Selection Criteria\\nOur model selection process was guided primarily\\nby resource constraints and the timeframe of our\\nresearch endeavor. We aimed to identify models\\nthat represented the state-of-the-art (SOTA), such\\nas GPT-4, or those with a specific focus on mathe-\\nmatical reasoning, such as MAmmoTH, aligning with\\nthe parameters of our project. Here’s a breakdown:\\n1. Resource and Budget Constraints: Given\\nour limited computing resources and budget,\\nwe meticulously selected models that could\\nprovide valuable insights within the confines\\nof our project. Incorporating additional mod-\\nels would have been impractical given our\\nresource limitations.\\nThe number of shots, indicated by shots = k,\\nwas tailored to the context length of the model.Figure 4: Our EEDP Approach (a.) Instructions, and (b.) Demonstration.0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\n1.1\\n−6 −4 −2 0 2 4 60\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\n1.1\\n−6 −4 −2 0 2 4 6\\nGPT-3.5-Turbo GPT-4 MAmmoTH-13B Mistral-7B PaLM-2-540B\\nOrder of Magnitude Order of Magnitude\\nAccuracyAccuracy\\nAddition Division\\nMultiplication Subtraction\\nFigure 5: Accuracy of different arithmetic operations across different orders of magnitude.\\nFigure 6: Sample distribution of Multihiertt & FinQA datasets partitioned by number of rows in the supporting table.(a) Hierarchical Complexity\\n (b) Empty Cells\\nFigure 7: Sample distribution of Multihiertt Dataset partitioned by (a) hierarchical complexity of the gold evidence.\\n(b) the percentage of empty cells in the supporting table.\\nSpecifically, for models with a context length\\nexceeding the input length, we standardized\\nk to 4. For instance, we allocated 2 shots\\nfor models like LLaMA and MammoTH due\\nto their constrained context length. However,\\nfor other models capable of accommodating\\nlarger contexts, we increased the number of\\nshots to 4. Additionally, we used a tempera-\\nture of 0 and topp = 1 for our experiments.\\n2. Models with Mathematical Capabilities:\\nWe prioritized models renowned for their\\nadvanced mathematical prowess, such as\\nMAmmoTH, alongside state-of-the-art Large\\nLanguage Models (LLMs) like GPT-4. Our\\ngoal was to gain deeper insights into the math-\\nematical reasoning capabilities of cutting-\\nedge models within the context of financial\\ndocuments.\\n3. Better Prompting Approaches: Rather than\\nfocusing solely on model diversity, we con-\\ncentrated on exploring a variety of prompting\\nmethods, particularly those aimed at enhanc-\\ning mathematical reasoning. We believed this\\napproach would yield more valuable insights\\ninto the performance of both LLMs and their\\nassociated prompting techniques in real-world\\nfinancial tasks.\\n4. Excluding Underperforming Models:\\nWhile we experimented with various models,\\nsuch as Falcon-7B-Instruct and MPT-7B-\\nInstruct, we found them to underperform\\nsignificantly compared to models like LLaMA\\nand Mistral. Consequently, we excluded them\\nfrom detailed analysis. Future experiments\\nwith ample computational resources may\\ninvolve exploring additional open-source\\nmodels like OLMo, Mixtral, and DBRX,\\nwhich have been recently released.\\nA.3 Other Modeling Techniques\\nBased on our research and the results obtained\\nfrom our proposed method ’EEDP’, we do have\\nseveral insights that could guide future model de-\\nvelopment:\\n1. Domain-Specific Pre-training: Our method\\n\"EEDP\" suggests that LLMs could benefit\\nfrom pre-training that focuses on extracting\\ndomain-specific knowledge. In the context of\\nfinancial documents, for instance, this could\\ninvolve training models on a corpus of finan-\\ncial texts, thereby enabling them to better un-\\nderstand and reason about financial concepts\\nand terminology.\\n2. Knowledge Elicitation: The elicitation step\\nin \"EEDP\" indicates the potential for design-\\ning LLMs that can elicit or extract relevant\\ninformation from a given context more effec-\\ntively. This could involve developing mod-\\nels that are better at identifying and focusing\\non key pieces of information in a document,\\nwhich is crucial for accurately answering ques-\\ntions about the document.\\n3. Modular Modeling: Our research introduce\\na novel approach to the reasoning process,\\nwherein it’s broken down into modular steps.\\nIn this methodology, Large Language Models(LLMs) handle different aspects of a task in\\ndistinct stages. This division potentially en-\\nhances the overall accuracy and efficiency of\\nthe model.\\nFor instance, the model might begin by elic-\\niting domain-specific knowledge, then pro-\\nceed to extract relevant information from the\\npremise. Following this, it engages in reason-\\ning about this information to answer a ques-\\ntion and finally derives the answer, using the\\noutput from the preceding reasoning steps as\\na reference point.\\nBy potentially training individual expert mod-\\nels to handle each specific stage, we could\\noptimize performance for each distinct task.\\nThis modular approach allows for specialized\\nprocessing of each step, thereby improving\\nthe overall performance and interpretability of\\nthe final output.\\n4. Hierarchical Structure Understanding:\\nRepresenting the input structure of the table\\nin a better format to the LLM could be benefi-\\ncial. One can also explore introducing special\\npositional encodings, similar to those used in\\nTAPAS, to serve as row and column IDs for\\neach cell. This approach would differ from\\ntraditional positional encodings, which are de-\\nsigned to capture the inherently linear struc-\\nture of textual data. TThis integration would\\nfacilitate the extraction of relvant information\\nfrom the table correctly, considering its struc-\\nture more effectively, avoiding information ex-\\ntraction errors. Another idea could be convert-\\ning the premise containing the complex table\\nand text into a common representation such\\nas a knowledge graph. Furthermore, models\\nspecifically tuned to answer to human queries\\nover complex documents in multiple conversa-\\ntional turns (like that in ConvFinQA) should\\nalso be considered, as it’s a challenge for lan-\\nguage model’s to backtrack to their decisions\\nthat were made previously in the conversation.\\nA.4 Metadata Annotations Dataset Coverage\\nFigure 6 displays the dataset distribution for Mul-\\ntihiertt and FinQA based on table length (number\\nof rows). Figure 7 (a) shows how we calculate hi-\\nerarchical complexity for examples with multiple\\nrelevant rows at various hierarchical depths. For\\nthe distribution of missing information (empty cell\\nproportions) across datasets, refer to Figure 7 (b).\\nFigure 8 for the distribution of questions by rea-\\nsoning steps. We define 12 mathematical concept\\ncategories, see Table 1) and annotate each ques-\\ntion accordingly. The dataset coverage for these\\ncategories is shown in Figure 9. Our method for\\nestimating hierarchy depth is shown in Figure 10.\\nFigure 11 shows a example for EEDP strategy with\\none shot. Figure 11 shows a example for EEDP\\nstrategy with one shot.Figure 8: Sample distribution of examples in numerical reasoning on tabular datasets partitioned by the number of reasoning\\nsteps involved. Clockwise (from top-left) : FinQA, ConvFinQA, TATQA, Multihiertt.\\nFigure 9: Sample distribution of Numerical & Tabular Reasoning Datasets partitioned by Question Concept Category types.\\nClockwise (from top-left): FinQA, ConvFinQA, Multihiertt, TATQA.Years Ended December 31, 2009 2008\\n(in millions, except percentages)\\nRevenues\\nManagement and financial advice fees $1,234 $1,339\\nDistribution fees $1,733 $1,912\\nNet investment income $297 $-43\\nOther revenues $85 $80\\nTotal revenues $3,349 $3,288\\nBanking and deposit interest expense $133 $178\\nTotal net revenues $3,216 $3,110\\nExpenses\\nDistribution expenses $1,968 $2,121\\nGeneral and administrative expense $1,282 $1,138\\nTotal expenses $3,250 $3,259\\nPretax loss $-34 $-149\\nQuestion: What will Distribution fees reach in 2010 if it continues to grow at its current rate? (in millions)?\\nGold Evidences:\\n• Table shows Distribution fees of Years Ended December 31, 2009 (in millions, except percentages) is\\n$1,733 .\\n• Table shows Distribution fees of Years Ended December 31, 2008 (in millions, except percentages) is\\n$1,912 .\\nHierarchical Complexity: max(4, 4) = 4\\nFigure 10: This illustration demonstrates how the \"hierarchical complexity\" is determined for each supporting piece of evidence.\\nThe hierarchical complexity corresponds to the number of levels or tiers of information structure within the table. The top\\nlevel (1) encompasses the table itself, which contains information about the results of operations in a firm’s Advice & Wealth\\nManagement segment. The second level (2) includes columns specifying the years (2009, 2008), creating a substructure within\\nthe table. The third level (3) involves the column \"(in millions, except percentages),\" and the fourth level (4) encompasses the\\nrows under categories like \"Revenues,\" \"Distribution fees,\" \"Net investment income,\" and so on. To locate specific values like\\n\"$1733\" and \"$1912\", a retriever module needs to navigate through these four levels.Instruction: Please carefully analyze the provided information, perform necessary numerical calculations, and\\nprovide accurate answers to the given question using the provided data. Take into account the pre-text, table, and\\npost-text when formulating your response.\\nWhen performing numerical calculations, ensure you gather the required information and follow a step-by-step\\napproach.\\n1. Elicit the most relevant domain fact or knowledge that might be useful for you to extract the right operands and\\nforming the right approach to the problem.\\n2. Translate table data into sentences and identify gold evidence for answering the question.\\n3. Define a sequence of atomic operations (Add, Subtract, Divide, Multiply, Greater, Min, Max, Exp) which take\\ninto account only two operands at a time. Divide a complex task into a sequence of atomic operations defined\\nabove.\\n4. Finally, conclude as: The final answer is <answer>.\\nDemonstration: “Effective Income Tax Rate”: A reconciliation of the United States federal statutory income tax rate\\nto our effective income tax rate is as follows: In 2019 and 2018 we had pre-tax losses of $19,573 and $25,403,\\nrespectively, which are available for carry forward to offset future taxable income.\\nYear Ended Year Ended\\nDecember 31, 2018 December 31, 2019\\nUnited States federal statutory rate 21.00% 21.00%\\nEffective income tax rate 1.99% -0.01%\\nQuestion: What was the 2019 percentage change in pre-tax losses?\\nResponse #:\\nDomain Knowledge: Pre-tax losses, or operating losses, refer to financial losses that a company incurs before\\nconsidering the effects of income taxes. To find the 2019 percentage change in pre-tax losses, we need to find the\\ndifference between the new and the old value of the pre-tax losses, then divide the obtained difference by the old value\\nand multiply this value by 100.\\nGold Evidences:\\n• The pre-tax losses in 2019 are $19,573.\\n• The pre-tax losses in 2018 are $25,403.\\nSteps:\\n1. Subtract 25403 from 19573.\\n• Response 1: 19573 - 25403 = -5830\\n2. Divide #1 by 25403.\\n• Response 2: −5830\\n25403 = −0.2295\\n3. Multiply #2 by 100.\\n• Response 3: −0.2295 × 100 =−22.95\\nThe final answer is -22.95%.\\nFigure 11: A Template for our proposed prompting strategy, EEDP with 1-shot demonstration.Regulatory capital, assets, and risk-based capital ratios for JPMorgan Chase and its significant IDI\\nsubsidiaries under Basel III Standardized Transitional and Basel III Advanced Transitional at December\\n31, 2017, and 2016.\\nBasel III Standardized Transitional Basel III Advanced Transitional\\n(in millions) Dec 31, 2017 Dec 31, 2016 Dec 31, 2017 Dec 31, 2016\\nRegulatory capital\\nCET1 capital $184,375 $179,319 $184,375 $179,319\\nTier 1 capital(a) $184,375 $179,341 $184,375 $179,341\\nTotal capital $195,839 $191,662 $189,419 $184,637\\nAssets\\nCapital ratios(c)\\nCET1 13.8% 13.7% (e) 15.0%\\nTier 1(a) 13.8% 13.7% (e) 15.0%\\nTotal 14.7% 14.6% (e) 15.4%\\nTier 1 leverage(d) 8.7% 8.6% 8.7%\\nQuestion: What is the sum of CET1 capital, Tier 1 capital, and Total capital in 2017? (in million)\\nResponse #:\\nDomain Knowledge: In banking, CET1 capital, Tier 1 capital, and Total capital are used to measure a bank’s\\nfinancial health and stability. CET1 (Common Equity Tier 1) capital consists mainly of common shares and retained\\nearnings. Tier 1 capital is the core capital mainly comprising shareholders’ equity and disclosed reserves. Total capital\\nincludes both Tier 1 capital and Tier 2 capital, which consists of hybrid capital instruments and subordinated debt.\\nGold Evidences:\\n• Table shows JPMorgan Chase Bank, N.A. Basel III Standardized Transitional CET1 capital on Dec 31, 2017 as\\n$184,375 million.\\n• Table shows JPMorgan Chase Bank, N.A. Basel III Standardized Transitional Tier 1 capital on Dec 31, 2017 as\\n$184,375 million.\\n• Table shows JPMorgan Chase Bank, N.A. Basel III Standardized Transitional Total capital on Dec 31, 2017 as\\n$195,839 million.\\nSteps:\\n1. Add CET1 capital and Tier 1 capital.\\n• Response 1: $184,375 + $184,375 = $368,750\\n2. Add #1 and Total capital.\\n• Response 2: #1 + $195,839 = $564,589\\nThe final answer is $564,589 million.\\nGround-Truth Steps: $184,375 + $184,375 + $195,839 + $184,375 + $184,375 + $189,419 = $1,122,758\\nReason: The model missed adding JPMorgan Chase Bank, N.A. Basel III Advanced Transitional CET1 capital\\n($184,375), Tier 1 ($184,375), and Total Capital ($189,419) in 2017.\\nFigure 12: Error due to missing evidencesYear Life/Fin. Gen. Rtd. Fin. Asset Total\\nIns. Ins. Services Services Mngmt\\n2006\\nFixed Maturities:\\nBonds available for sale $67,994 $288,018 $1,357 $29,500 — $386,869\\nBonds held to maturity $21,437 — — — — $21,437\\nBond trading securities $1 $10,835 — — — $10,836\\nEquity Securities:\\nCommon stocks $4,245 $8,705 — $226 $80 $13,256\\nPreferred stocks $1,884 $650 $5 — — $2,539\\nOther Assets:\\nMortgage and other loans $17 $21,043 $2,398 $4,884 $76 $28,418\\nFlight equipment — — $39,875 — — $39,875\\nTotal Invested Assets $116,059 $428,825 $185,404 $68,280 $3,373 $801,941\\nQuestion: What is the proportion of Asset Management to the total Mortgage and other loans receivable, net of\\nallowance in 2006?\\nResponse #:\\nDomain Knowledge: Proportion refers to the relationship between two quantities, where one quantity is considered\\nin relation to the other. To find the proportion of Asset Management to the total Mortgage and other loans receivable,\\nnet of allowance in 2006, we need to divide the value of Asset Management by the total value of Mortgage and other\\nloans receivable, net of allowance in 2006.\\nGold Evidences:\\n• Table shows Asset Management of Total invested assets in 2006 is $68,280.\\n• Table shows Mortgage and other loans receivable, net of allowance (in millions) in 2006 is $28,418.\\nSteps:\\n1. Divide Asset Management by the total Mortgage and other loans receivable, net of allowance in 2006.\\n• Response 1: 68280\\n28418 = 2.4024\\nThe final answer is 2.4024.\\nGround-truth steps: 4884.0\\n28418.0 = 0.172\\nReason: Asset Management in 2006 is taken as $68,280.0 by the model instead of $4,884.0 due to error in the\\nextraction of the ground-truth.\\nFigure 13: Error due to wrong evidences2013 2014 2015 2016 2017\\nMasco $138.48 $155.26 $200.79 $227.08 $318.46\\nS&P 500 Index $132.04 $149.89 $151.94 $169.82 $206.49\\nS&P Industrials Index $140.18 $153.73 $149.83 $177.65 $214.55\\nS&P Consumer Durables & Apparel Index $135.84 $148.31 $147.23 $138.82 $164.39\\nQuestion: What was the difference in percentage cumulative total shareholder return on Masco common stock versus\\nthe S&P 500 Index for the five-year period ended 2017?\\nResponse #:\\nDomain Knowledge: Cumulative total shareholder return is a measure of the overall performance of a stock over a\\ngiven period of time. It includes the change in the stock’s price as well as any dividends paid to shareholders during\\nthat time.\\nGold Evidences:\\n• The cumulative total shareholder return for Masco in 2017 is $318.46.\\n• The cumulative total shareholder return for the S&P 500 Index in 2017 is $206.49.\\nSteps:\\n1. Divide the cumulative total shareholder return for Masco in 2017 (318.46) by the cumulative total shareholder\\nreturn for the S&P 500 index in 2017 (206.49)\\n• Response 1: 318.46 / 206.49 = 1.5422\\n2. Subtract 1 from the quotient obtained in #1\\n• Response 2: 1.5422 - 1 = 0.5422\\n3. Multiply the value obtained in #2 with 100 to find the percentage difference\\n• Response 3: 0.5422 * 100 = 54.22\\nThe final answer is 54.22%.\\nGround-truth steps: [((318.46 - 100.0)/100.0)*100.0 - ((206.49 - 100.0)/100.0)*100.0] = 111.97\\nReason: Wrong formula for return on investment\\nFigure 14: Example of an error caused due to insufficient domain knowledgeAccr. Yield Carrying Amt. Allowance\\n(Beginning) (Beginning) (Beginning)\\nBeginning Balance $27 $920 $95\\nPurchases $1 $130 $0\\nDisposals/Payments Received $-11 $-594 $0\\nAccretion $-44 $44 $0\\nBuilds (Reductions) to the Allowance $0 $0 $-18\\nIncrease to Expected Cash Flows $-2 $19 $0\\nFX/Other $17 $-50 $0\\nBalance at December 31, 2010 $116 $469 $77\\nQuestion: What percentage did this total represent in relation to the carrying amount?\\nResponse #:\\nDomain Knowledge: To find the percentage of a value (A) in relation to another value (B), divide the first value (A)\\nby the second value (B) and multiply it by 100. To find the combined total, add the two values.\\nGold Evidences:\\n• The carrying amount of the company’s purchased distressed loan portfolio at December 31, 2010, was $392\\nmillion.\\n• The net allowance was $77 million as of December 31, 2010.\\nSteps:\\n1. Find the combined total of net allowance and the carrying amount.\\n• Response 1: 392 + 77 = 469\\n2. Calculate the percentage of net allowance in relation to the carrying amount.\\n• Response 2: 77\\n392 × 100 = 19.64\\n3. Calculate the percentage of the combined total in relation to the carrying amount.\\n• Response 3:\\n\\x00469\\n392\\n\\x01\\n× 100 = 119.64\\nThe final answer is 119.64%.\\nGround-truth steps: [(77/(392 + 77))*100] = 16.42%\\nReason: By the phrase in relation to the question expected a ratio of quantity1/quantity2 but the model returned\\nquantity2/quantity1\\nFigure 15: Example of an error caused due to question misinterpretation2001 2000\\nGain on Sales of Depreciable Properties $45428 $52067\\nGain on Land Sales $5080 $9165\\nImpairment Adjustment $-4800 (4800) $-540 (540)\\nTotal $45708 $60692\\nQuestion: What is the percent change in general and administrative expense from 2000 to 2001?\\nResponse #:\\nDomain Knowledge: To find the percent change between two values, we need to find the difference between the new\\nand old values, divide the difference by the old value, and multiply the result by 100.\\nGold Evidences:\\n• General and administrative expense decreased from $21.1 million in 2000 to $15.6 million for the year ended\\nDecember 31, 2001.\\nSteps:\\n1. Calculate the change in general and administrative expense by subtracting the 2001 value ($15.6 million) from\\nthe 2000 value ($21.1 million).\\n• Response 1: 21.1 - 15.6 = 5.5\\n2. Divide the difference obtained in Step 1 by the general and administrative expense in 2000 ($21.1 million).\\n• Response 2: 5.5\\n21.1 = 0.2607\\n3. Multiply the result obtained in Step 2 by 100 to get the percent change.\\n• Response 3: 0.2607 × 100 = 26.07\\nThe final answer is 26.07%.\\nGround-truth steps: [((15.6 - 21.1)/21.31)*100] = -26.07%\\nReason: Incorrect Instantiation of variables resulting in a value with a flipped sign\\nFigure 16: Example of an error caused due to incorrect instantiation of variables2013 2014 2015 2016 2017\\nCME Group Inc. $164.01 $194.06 $208.95 $279.85 $370.32\\nS&P 500 $132.39 $150.51 $152.59 $170.84 $208.14\\nPeer Group $176.61 $187.48 $219.99 $249.31 $323.23\\nQuestion: What is the annualized return for s&p 500 from 2012 to 2017?\\nResponse #:\\nDomain Knowledge: The annualized return refers to the average rate of return over a given period for an investment,\\nwhich has been adjusted for compounding. To find the annualized return for the S&P 500 from 2012 to 2017, we need\\nto use the formula:\\nAnnualized return =\\n \\x12 Ending value\\nStarting value\\n\\x13 1\\nNumber of years\\n− 1\\n!\\nGold Evidences:\\n• Investment was $100 on December 31, 2012;Value of S&P 500 investment on December 31, 2017 is $208.14.\\nSteps:\\n1. Divide the ending value (208.14) by the starting value (100)\\n• Response 1: 208.14\\n100 = 2.0814\\n2. Calculate the number of years elapsed (2017 - 2012)\\n• Response 2: 2017 - 2012 = 5\\n3. Raise the value obtained in #1 to the power of (1/number of years)\\n• Response 3: (2.0814)\\n1\\n5 = 1.1606\\n4. Subtract 1 from the value obtained in #3\\n• Response 4: 1.1606 - 1 = 0.1606\\n5. Multiply the value obtained in #4 by 100 to get the annualized return in percentage\\n• Response 5: 0.1606 * 100 = 16.06\\nThe final answer is 16.06%.\\nGround-truth steps: [(208.14/100)(1/(2017 − 2012)) - 1] = 0.1577 * 100 = 15.77\\nReason: Inaccurate calculation\\nFigure 17: Example of an error caused due to imprecise calculationsFigure 4: Our EEDP Approach (a.) Instructions, and (b.) Demonstration.\\nThe image provides instructions and a demonstration of accounting theory in relation to the effects of changes in foreign exchange rates.\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\n1.1\\n−6\\n−4\\n−2\\n0\\n2\\n4\\n6\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1\\n1.1\\n−6\\n−4\\n−2\\n0\\n2\\n4\\n6\\nGPT-3.5-Turbo\\nGPT-4\\nMAmmoTH-13B\\nMistral-7B\\nPaLM-2-540B\\nOrder of Magnitude\\nOrder of Magnitude\\nAccuracy\\nAccuracy\\nAddition\\nDivision\\nMultiplication\\nSubtraction\\nFigure 5: Accuracy of different arithmetic operations across different orders of magnitude.\\nFigure 6: Sample distribution of Multihiertt & FinQA datasets partitioned by number of rows in the supporting table.\\n**This image displays two pie charts.**\\n\\nThe first pie chart is labeled \"RSpec\" and the second is labeled \"Minitest\". Additionally, there is a legend of colors called \"number of tests\". The number of tests are unreasonable and used for examples.\\n(a) Hierarchical Complexity (b) Empty Cells Figure 7: Sample distribution of Multihiertt Dataset partitioned by (a) hierarchical complexity of the gold evidence. (b) the percentage of empty cells in the supporting table. Specifically, for models with a context length exceeding the input length, we standardized k to 4. For instance, we allocated 2 shots for models like LLaMA and MammoTH due to their constrained context length. However, for other models capable of accommodating larger contexts, we increased the number of shots to 4. Additionally, we used a tempera- ture of 0 and topp = 1 for our experiments. 2. ModelsThe image displays a pie chart with six sections, each representing a different percentage. The chart is divided into six equal parts, with each section labeled with a number from 1 to 6 in the key on the right side of the chart. The percentages are represented by different colors, ranging from dark orange (29.795%) to light blue (7.736%). The background of the chart is white, providing a clean and simple visual representation of the data.\\n(a) Hierarchical Complexity (b) Empty Cells Figure 7: Sample distribution of Multihiertt Dataset partitioned by (a) hierarchical complexity of the gold evidence. (b) the percentage of empty cells in the supporting table. Specifically, for models with a context length exceeding the input length, we standardized k to 4. For instance, we allocated 2 shots for models like LLaMA and MammoTH due to their constrained context length. However, for other models capable of accommodating larger contexts, we increased the number of shots to 4. Additionally, we used a tempera- ture of 0 and topp = 1 for our experiments. 2. ModelsThis image is a pie chart displaying the percentage of empty cells, categorized by the number of empty cells. The chart is divided into four sections:\\n\\n- 0 empty cells: 27.989%\\n- 10 empty cells: 42.757%\\n- 20 empty cells: 19.550%\\n- >30 empty cells: 9.705%\\n\\nThe percentages are represented by different colors in the chart. The background of the image is white.\\nFigure 8: Sample distribution of examples in numerical reasoning on tabular datasets partitioned by the number of reasoning\\nsteps involved. Clockwise (from top-left) : FinQA, ConvFinQA, TATQA, Multihiertt.\\nFigure 9: Sample distribution of Numerical & Tabular Reasoning Datasets partitioned by Question Concept Category types.\\nClockwise (from top-left): FinQA, ConvFinQA, Multihiertt, TATQA.\\n**Image Analysis: Pie Charts for Assuring Steps**\\n\\nThe image presents a collection of four pie charts, each displaying a unique distribution of data related to managing steps. The charts are arranged in a 2x2 grid, with two charts per row.\\n\\n**Pie Chart Labels and Corresponding Data**\\n\\n* **FinQA:**\\n\\t+ Orange: 12.19%\\n\\t+ Purple: 78.19%\\n\\t+ Green (light green) with a pink triangle: 9.62%\\n* **ConvFinQA:**\\n\\t+ Orange: 44.12%\\n\\t+ Purple: 55.88%\\n* **Multitask:**\\n\\t+ Orange: 41.14%\\n\\t+ Purple: 53.88%\\n\\t+ Green (light green): 5.00%\\n* **TATQA:**\\n\\t+ Orange: 43.23%\\n\\t+ Purple: 56.77%\\n\\n**Key Findings**\\n\\n* The data ranges from 5% to 78.19% across all charts.\\n* Each chart has a distinct color scheme, with orange, purple, and green (light green) being the primary colors used.\\n* The presence of a pink triangle in the FinQA chart suggests that it may represent an additional category or subgroup within the data.\\n\\n**Conclusion**\\n\\nIn conclusion, this image presents a visual representation of data related to managing steps, as depicted through four pie charts. The charts display varying distributions of data, with each chart showcasing a unique set of percentages. The use of different colors and the inclusion of a pink triangle in one chart add complexity to the data, inviting further analysis and interpretation.\\nFigure 8: Sample distribution of examples in numerical reasoning on tabular datasets partitioned by the number of reasoning\\nsteps involved. Clockwise (from top-left) : FinQA, ConvFinQA, TATQA, Multihiertt.\\nFigure 9: Sample distribution of Numerical & Tabular Reasoning Datasets partitioned by Question Concept Category types.\\nClockwise (from top-left): FinQA, ConvFinQA, Multihiertt, TATQA.\\nThis image shows four pie charts related to categorical data for purchase types and frequency, named \"FinQA\", \"CoswFinQA\", \"TaToQA\", and \"Multivent\". THe charts are color coded along a legend. The pies are sectioned by different percentages. There is a title for each pie chart, and the background is white.$15,395 + $\\n equations: $4 = $\\n equations: $1,234 $\\n equations: $1,733 $\\n equations: $297 $\\n equations: $85 $\\n equations: $3,349 $\\n equations: $133 $\\n equations: $3,216 $\\n equations: $1,968 $\\n equations: $1,282 $\\n equations: $3,250 $\\n equations: $-34 $\\n equations: $1733\" and \"$\\n equations: $19,573 and $\\n equations: $184,375 $\\n equations: $184,375 $\\n equations: $184,375 $\\n equations: $184,375 $\\n equations: $195,839 $\\n equations: $189,419 $\\n equations: $184,375 + $\\n equations: $195,839 = $\\n equations: $184,375 + $\\n equations: $195,839 + $\\n equations: $184,375 + $\\n equations: $184,375), Tier 1 ($\\n equations: $67,994 $\\n equations: $1,357 $\\n equations: $21,437 — — — — $\\n equations: $1 $\\n equations: $4,245 $\\n equations: $226 $\\n equations: $1,884 $\\n equations: $5 — — $\\n equations: $17 $\\n equations: $2,398 $\\n equations: $76 $\\n equations: $39,875 — — $\\n equations: $116,059 $\\n equations: $185,404 $\\n equations: $3,373 $\\n equations: $68,280.0 by the model instead of $\\n equations: $138.48 $\\n equations: $200.79 $\\n equations: $132.04 $\\n equations: $151.94 $\\n equations: $140.18 $\\n equations: $149.83 $\\n equations: $135.84 $\\n equations: $147.23 $\\n equations: $27 $\\n equations: $1 $\\n equations: $-11 $\\n equations: $-44 $\\n equations: $0 $\\n equations: $-2 $\\n equations: $17 $\\n equations: $116 $\\n equations: $45428 $\\n equations: $5080 $\\n equations: $-4800 (4800) $\\n equations: $45708 $\\n equations: $21.1 million in 2000 to $\\n equations: $164.01 $\\n equations: $208.95 $\\n equations: $132.39 $\\n equations: $152.59 $\\n equations: $176.61 $\\n equations: $219.99 $\\n equations: $100 on December 31, 2012;Value of S&P 500 investment on December 31, 2017 is $')]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking"
      ],
      "metadata": {
        "id": "4aAETq2ogdcU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "j5gzu5nEoo-O"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=20000, chunk_overlap=5000)\n",
        "chunked_docs = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn7u6mI8mNre",
        "outputId": "8d932e30-bf5c-417e-fe54-a3fa154a9e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunked doc 1 length: 19995\n",
            "Chunked doc 2 length: 19996\n",
            "Chunked doc 3 length: 19949\n",
            "Chunked doc 4 length: 19879\n",
            "Chunked doc 5 length: 17722\n",
            "Chunked doc 6 length: 6293\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(chunked_docs):\n",
        "    print(f\"Chunked doc {i+1} length: {len(doc.page_content)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5qWhiOBiUJbq"
      },
      "outputs": [],
      "source": [
        "# print(chunked_docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "YA6luh_Bgb3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "oLMKR3vIo-RH"
      },
      "outputs": [],
      "source": [
        "os.environ['HF_KEY']=userdata.get('HF_TOKEN')\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n",
        "faiss_db = FAISS.from_documents(chunked_docs, embeddings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retriever\n"
      ],
      "metadata": {
        "id": "ORethYsMgM8W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Kxxo4OvupGCg"
      },
      "outputs": [],
      "source": [
        "retriever = faiss_db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={'k': 5}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM"
      ],
      "metadata": {
        "id": "neq6_9JrgL-O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "bdHWur55h--0"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "# model=ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "llm = ChatNVIDIA(\n",
        "  model=\"meta/llama-3.1-405b-instruct\",\n",
        "\n",
        "  temperature=0.2,\n",
        "  top_p=0.7,\n",
        "  max_tokens=1024,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retriever + LLM Chain"
      ],
      "metadata": {
        "id": "V-ZPpAtwgGhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dphDUqYwpI6h"
      },
      "outputs": [],
      "source": [
        "text_chain = ConversationalRetrievalChain.from_llm(llm, retriever,return_source_documents=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "2ogj4jUFgEMk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "iHHcF1xCCb6X"
      },
      "outputs": [],
      "source": [
        "def image_upload():\n",
        "  answer = input(\"Do you want to use an image? (yes/no): \")\n",
        "  if answer.lower() == \"no\":\n",
        "    return None\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "  return fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "cdNitLna-z1I"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "from PIL import Image\n",
        "import io\n",
        "def image2base64(image_path):\n",
        "  img = Image.open(image_path)\n",
        "  image = img.resize((200, 200))\n",
        "  buffered = io.BytesIO()\n",
        "  image.save(buffered, format=\"PNG\")\n",
        "  img_bytes = buffered.getvalue()\n",
        "  img_base64 = base64.b64encode(img_bytes).decode('utf-8')\n",
        "  return img_base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mnI8kVIJCKWM"
      },
      "outputs": [],
      "source": [
        "def ipimage2caption(img_base64):\n",
        "  response=caption(img_base64)\n",
        "  while(response.status_code==500):\n",
        "    response=caption(img_base64)\n",
        "  response=output_caption(response)\n",
        "  return response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG\n"
      ],
      "metadata": {
        "id": "66gxmEiLgCSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "f_cG5ilgpKlE",
        "outputId": "81ed1906-adfe-4426-ddfb-f6b7ce0e144a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you want to use an image? (yes/no): yes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e464584-0a7b-48e7-b93f-d71d59825f80\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5e464584-0a7b-48e7-b93f-d71d59825f80\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving image.png to image.png\n",
            "User uploaded file \"image.png\" with length 62491 bytes\n",
            "Prompt: Describe the image\n",
            "response\n",
            "describe the image\n",
            "Caption:**Image Description:**\n",
            "\n",
            "This image presents a statistical representation of two distinct sets of data, each comprising a collection of numbers. The data is visually organized into two pie charts, which are accompanied by a table titled **\"Figure 4: Sample distribution of Multilabel & FnQA datasets portioned by number of rows in the supporting table.\"**\n",
            "\n",
            "**Pie Chart 1 (Left):**\n",
            "\n",
            "The first pie chart, positioned on the left side of the image, is divided into four sections, each representing a different dataset:\n",
            "\n",
            "*   **57.96%**: This section is colored orange and accounts for the largest proportion of the data.\n",
            "*   **25.12%**: This section is colored green and represents a significant portion of the data.\n",
            "*   **16.87%**: This section is colored pink and constitutes a smaller but still notable part of the data.\n",
            "*   **0.04%**: This section is colored purple and represents a very small fraction of the data.\n",
            "\n",
            "**Pie Chart 2 (Right):**\n",
            "\n",
            "The second pie chart, located on the right side of the image, is also divided into four sections, each representing a different dataset:\n",
            "\n",
            "*   **31.33%**: This section is colored orange and accounts for the largest proportion of the data.\n",
            "*   **24.23%**: This section is colored pink and represents a significant portion of the data.\n",
            "*   **26.46%**: This section is colored purple and constitutes a substantial part of the data.\n",
            "*   **17.96%**: This section is colored green and represents a smaller but still notable part of the data.\n",
            "\n",
            "**Table:**\n",
            "\n",
            "To the right of each pie chart, a small table is provided with the title **\"Number of Rows\"**. This table lists four rows, each corresponding to a different dataset, along with their respective values:\n",
            "\n",
            "*   **>>c**: 4\n",
            "*   **>>c**, **<d**: 20\n",
            "*   **>>c**, **<d**, **<e**: 61\n",
            "*   **>>c**, **<d**, **<e**, **<f**: 8\n",
            "\n",
            "Overall, this image effectively illustrates the distribution of two sets of data, providing a clear and concise visual representation of the proportions of each dataset.\n",
            "Answer: The image is a statistical representation of two sets of data, each consisting of a collection of numbers. The data is organized into two pie charts, accompanied by a table titled \"Figure 4: Sample distribution of Multilabel & FnQA datasets portioned by number of rows in the supporting table.\" \n",
            "\n",
            "The first pie chart is divided into four sections, representing different datasets, with the largest proportion being 57.96% (orange), followed by 25.12% (green), 16.87% (pink), and 0.04% (purple). \n",
            "\n",
            "The second pie chart is also divided into four sections, representing different datasets, with the largest proportion being 31.33% (orange), followed by 24.23% (pink), 26.46% (purple), and 17.96% (green). \n",
            "\n",
            "To the right of each pie chart, a small table lists four rows, each corresponding to a different dataset, along with their respective values. The table is titled \"Number of Rows\" and lists the values as 4, 20, 61, and 8. \n",
            "\n",
            "Overall, the image provides a clear visual representation of the distribution of the two sets of data, showing the proportions of each dataset.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from google.colab import files\n",
        "chat_history = []\n",
        "def get_user_input():\n",
        "    return input('Prompt: ').lower()\n",
        "\n",
        "def main(chat_history):\n",
        "    fn=image_upload()\n",
        "    # print(\"Input the prompt\")\n",
        "    query =  get_user_input()\n",
        "    if(fn!=None):\n",
        "      image_path=fn\n",
        "      img_base64=image2base64(image_path)\n",
        "      response=ipimage2caption(img_base64)\n",
        "      print(\"response\")\n",
        "      response=\"Caption:\"+response\n",
        "      query+='\\n'+response\n",
        "      print(query)\n",
        "\n",
        "    result = text_chain.invoke({'question': query, 'chat_history': chat_history})\n",
        "    print(f'Answer: {result[\"answer\"]}\\n')\n",
        "    chat_history.append((query, result['answer']))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(chat_history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}